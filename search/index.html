













































































































































































































































































































































































































































































































































































































































































































































































































































































[{"content":"Get ready: Great International Developer Summit is re-scheduled from 17-21st Aug, in Bangalore.\nCome and talk about the life beyond keyboard and screens, spatial web is taking over get ready\u0026hellip;\n The talk is about Spatial Web is an umbrella term for the next generation web technologies that will transform every aspect of our life. It will connect the human and machines seamlessly such that the difference between physical and virtual will disappear.\nIn this session, we will discuss how user interactions have evolved with time, why it is the time to go beyond keyboard and 2D screens and interact smartly with the upcoming smarter devices such as IOT wearables, NLP, CV and ARVR.\nHere are the key highlights of this talk:\n Evolutions - Web 1.0 to Spatial Web Thinking beyond keyboard and 2D screen - Technologies, devices, and the use cases Facts and Figures - where are we heading? Impact on life of software development and developers - expected future skills  Find the details here\nStay tunes, see you there hopefully\u0026hellip;\n","id":0,"tag":"xr ; spatialweb ; developer-summit ; talk","title":"Spatial Web - Life beyond Keyboard and Screen","type":"talk","url":"https://thinkuldeep.github.io/talk/gids_2020_blr_spatialweb/"},{"content":"The Operating System of XR (AR VR) devices is mostly customized to the hardware of the device, and not just that the OS level customizations are needed to meet the enterprise needs such as integration with Enterprise MDM (Mobile Device Management) solutions (such as Intune, MobileIron and Airwatch), 3D lock screen, idle-timeout, custom home screen, custom settings, security, as so on.\nMost organizations currently using traditional hardware and software assets such as mobile devices, laptops, and desktops, and the processes and policies for managing these devices are quite stable and straightforward by now. Now the expectation is to follow the same/similar process for managing the organization’s XR devices. Most enterprise MDM supports standard OS (Windows, Mac, Linux, and Android), but mostly these are not well aligned to 3D user experience.\nThere are a number of XR devices based on Android, eg Oculus,Google Glass, Vuzix, and ARCore/VR supported Smart Phones. This article is a first step toward building a custom Android OS and small customizations. We will use the Android Open Source Project (AOSP) to build the custom image as per our needs.\nTake a deep breath, this will be a lengthy task, you need to wait for hours and hours to finish the steps, and plan your time ahead.\nLet\u0026rsquo;s start …\nBefore you start Wait, before you start. It needs 230GB plus free disk space, and a decent Linux based environment. I was able to get a spare Mac Book Pro with 230 GB available space, I thought of setting the environment following the guide building-android-o-with-a-mac.\nBut later, I found that after basic build software installations and IDE setup, space available is less than 220 GB. Luckily I was in touch with an Android expert Ashish Pathak, he suggested not to take a risk and find other PC.\nAnd here we go, found a Windows 10 PC with 380GB free space.\nLet’s first set up a Linux environment from scratch. Remember Virtual Box etc are not the option here, let\u0026rsquo;s not complicate things.\nOk, let’s start now…\nSetup a Linux based Development Environment Follow the steps below to set up a Linux environment from scratch on a Windows PC.\n  Free up the memory space — Open Disk Manager and choose the Shrink disk/delete an unused drive, and let space comes as unallocated, no need to format it, while installation the unallocated space will be formatted as per the Linux OS.\n  Download Ubuntu Desktop OS Image — https://releases.ubuntu.com/16.04/\n  Create a Bootable image — Download Rufus from https://rufus.ie/, insert a USB pen drive (I used one of size 8GB), select the downloaded Ubuntu ISO image, and start creating the image bootable image.   It will some minutes and once you see “Ready” eject the USB safely.\n  Boot from the Pen Drive — On windows OS, choose restart, and press F9 while starting (for me it worked, try to look at what does your PC support to see boot menu), it will show a boot menu, choose the pen drive option. It will start the Ubuntu installation. Go with the default options.\n  Setup Ubuntu — During installation, it will reboot, and choose Ubuntu option from the boot menu, and then choose the timezone, language, and set up a user account (remember credentials please for later login). You will see the Ubuntu home screen, and see keyboard shortcuts. Remember these.   Congratulations! it\u0026rsquo;s ready now.\nSetup Android Build Environment Follow the below steps to set up a build environment for AOSP. Detailed steps are here\n Install Git — https://git-scm.com/downloads — Linux version Install Repo Tool — https://gerrit.googlesource.com/git-repo/+/refs/heads/master/README.md $ sudo apt-get install repo  Install Java 8 — $ sudo apt-get install openjdk-8-jdk  Create a working directory arvr@arvr-pc:/$ cd ~ arvr@arvr-pc:~$ mkdir aosp arvr@arvr-pc:~$ cd aosp arvr@arvr-pc:~/aosp$   Download AOSP Source Code  Initialize the AOSP repository source code (the default is master): I fetched from the android-8.1.0_r18 branch to build for my old Android device, You may want to go for the latest. arvr@arvr-pc:~/aosp$ repo init -u https://android.googlesource.com/platform/manifest -b android-8.1.0_r18 --depth=1  You need to set the correct username and email in git config, to make the above succeed. git config --global user.name \u0026#34;FIRST_NAME LAST_NAME\u0026#34; git config --global user.email \u0026#34;MY_NAME@example.com\u0026#34;  Sync the Repo arvr@arvr-pc:~/aosp$ repo sync -cdj16 --no-tags ... ... Checking out files: 100% (9633/9633), done. Checking out files: 100% (777/777), done.tform/system/coreChecking out files: 23% (181/777) Checking out files: 100% (34/34), done.latform/test/vts-testcase/performanceChecking out files: 32% (11/34) Checking out projects: 100% (592/592), done. repo sync has finished successfully. arvr@arvr-pc:~/aosp$ It takes a couple of hours to complete, I let it run in the night, with caffeine ON.\n  Parallel to this, I have also started downloading Android Studio, with SDK, emulators or so. — Follow the steps\nGood night!\nBuild the source code Good morning, source code is downloaded, the Android Studio is also ready.\nLet’s do another big chunk, building the source code\n  Set the environment\narvr@arvr-pc:~/aosp$ source build/envsetup.sh including device/asus/fugu/vendorsetup.sh including device/generic/car/vendorsetup.sh including device/generic/mini-emulator-arm64/vendorsetup.sh including device/generic/mini-emulator-armv7-a-neon/vendorsetup.sh including device/generic/mini-emulator-mips64/vendorsetup.sh including device/generic/mini-emulator-mips/vendorsetup.sh including device/generic/mini-emulator-x86_64/vendorsetup.sh including device/generic/mini-emulator-x86/vendorsetup.sh including device/generic/uml/vendorsetup.sh including device/google/dragon/vendorsetup.sh including device/google/marlin/vendorsetup.sh including device/google/muskie/vendorsetup.sh including device/google/taimen/vendorsetup.sh including device/huawei/angler/vendorsetup.sh including device/lge/bullhead/vendorsetup.sh including device/linaro/hikey/vendorsetup.sh including sdk/bash_completion/adb.bash   Now lunch command is available for you, pass an x86 target to it, arm ones are quite slow. lunch command without any parameter lists the options, choose one of them.\narvr@arvr-pc:~/aosp$ lunch You\u0026#39;re building on Linux Lunch menu... pick a combo: 1. aosp_arm-eng 2. aosp_arm64-eng 3. aosp_mips-eng 4. aosp_mips64-eng 5. aosp_x86-eng 6. aosp_x86_64-eng 7. full_fugu-userdebug arvr@arvr-pc:~/aosp$ lunch 5 ============================================ PLATFORM_VERSION_CODENAME=REL PLATFORM_VERSION=8.1.0 TARGET_PRODUCT=aosp_x86 TARGET_BUILD_VARIANT=eng TARGET_BUILD_TYPE=release TARGET_PLATFORM_VERSION=OPM1 TARGET_BUILD_APPS= ... OUT_DIR=out AUX_OS_VARIANT_LIST= ============================================   Run make command — “make” or “m” with parallelization 16.\narvr@arvr-pc:~/aosp$ make -j16 ... REALLY setting name! Warning: The kernel is still using the old partition table. The new table will be used at the next reboot. The operation has completed successfully. #### build completed successfully (01:43:31 (hh:mm:ss)) #### This command took good 2 hours, and your emulator is ready now. Good noon!\n  Run the emulator\nNow the emulator is ready, let\u0026rsquo;s run it.\narvr@arvr-pc:~/aosp$ emulator \u0026amp; [1] 11121 arvr@arvr-pc:~/aosp$ emulator: WARNING: system partition size adjusted to match image file (2562 MB \u0026gt; 200 MB) emulator: WARNING: cannot read adb public key file: /home/arvr/.android/adbkey.pub qemu-system-i386: -device goldfish_pstore,addr=0xff018000,size=0x10000,file=/home/arvr/aosp/out/target/product/generic_x86/data/misc/pstore/pstore.bin: Unable to open /home/arvr/aosp/out/target/product/generic_x86/data/misc/pstore/pstore.bin: No such file or directory Your emulator is out of date, please update by launching Android Studio: - Start Android Studio - Select menu \u0026#34;Tools \u0026gt; Android \u0026gt; SDK Manager\u0026#34; - Click \u0026#34;SDK Tools\u0026#34; tab - Check \u0026#34;Android Emulator\u0026#34; checkbox - Click \u0026#34;OK\u0026#34; Your fresh android image is running. Congratulations. You should see it in the list of connected devices in ADB.\narvr@arvr-pc:~/aosp$ adb devices List of devices attached emulator-5554 device You can install applications on this emulator just like any other.\n  Customizing the Settings App Let\u0026rsquo;s assume, we want to customize the Settings app for our XR need. Let\u0026rsquo;s open the settings I wanted to customize a settings app.\nOops! the settings app is failing to load. Logcat tied to look through the logs using logcat.\narvr@arvr-pc:~/aosp$ adb logcat 05–10 11:21:10.091 1640 1651 I ActivityManager: START u0 {act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] flg=0x10200000 cmp=com.android.settings/.Settings (has extras)} from uid 10015 05–10 11:21:10.092 1604 2569 W audio_hw_generic: Not supplying enough data to HAL, expected position 895044 , only wrote 894994 05–10 11:21:10.126 1383 1383 D gralloc_ranchu: gralloc_alloc: Creating ashmem region of size 1540096 05–10 11:21:10.130 2782 2782 W zygote : Unexpected CPU variant for X86 using defaults: x86 05–10 11:21:10.132 1640 1759 I ActivityManager: Start proc 2782:com.android.settings/1000 for activity com.android.settings/.Settings ... This issue may be related to the branch Android 8.1 that I checked out, I tried to rebuild “m clean” and “m” but no luck.\nGood evening!\nLuckily I am not the only one facing this, I found this.\n Android 8 Settings app crashes on emulator with clean AOSP build stackoverflow.com\n Now I got two suggestions, change WifiDisplaySettings.java in the AOSP packages or just clean build with the user-debug target. I will go with the first option.\nOpen the Settings App in Android Studio Locate the settings in /packages/apps/Settings and open in Android Studio. Open class - /src/com/android/settings/wfd/WifiDisplaySettings.java and Change the code snippet\npublic static boolean isAvailable(Context context) { return context.getSystemService(Context.DISPLAY_SERVICE) != null \u0026amp;\u0026amp; context.getSystemService(Context.WIFI_P2P_SERVICE) != null; } To\npublic static boolean isAvailable(Context context) { return false; } Let’s build again, another few hours? No, don\u0026rsquo;t worry this time it won’t take long, it will build just what you have changed. Run the make command again.\narvr@arvr-pc:~/aosp$ m -j16 The operation has completed successfully. [1]+ Done emulator (wd: ~/aosp) (wd now: ~/aosp/packages/apps/Settings/src/com/android/settings/wfd) #### build completed successfully (02:44 (mm:ss)) #### arvr@arvr-pc:~/aosp$ emulator \u0026amp; The emulator is now built with changes, run the emulator now. And here you go, Settings app is working! Customize the Settings App Hay! you know, you have already customized the android image. Not excited enough, let\u0026rsquo;s do one more exercise to customize the Settings Menu options.\nOpen /res/values/strings.xml and change some menu titles eg. change “Battery” title to “Kuldeep Power” and “Network \u0026amp; Internet” to “K Network \u0026amp; Internet”.\n\u0026lt;string name=\u0026#34;power_usage_summary_title\u0026#34;\u0026gt;Kuldeep Power\u0026lt;/string\u0026gt; \u0026lt;string name=\u0026#34;network_dashboard_title\u0026#34;\u0026gt;K Network \u0026amp;amp; Internet\u0026lt;/string\u0026gt; Build the image (remember the m command) and run the emulator as described in the last step, wait for a few minutes and you have your customized android menu. With this, your custom settings app is ready and available in the Andorid Image, and now I would like to close the article, and say you good Night.\nI will write about flashing this image to a device later, the spare phone for which I am building this image, is now not working, looks like my son has experimented with that old phone.\nIn the future, we will also discuss how to customize native users managements in android based XR devices, and also how to handle device-specific options that are not supported in the regular phone.\nGood Night, keep learning! keep sharing!\nThis article is original published on XR Practices Publication\n","id":1,"tag":"xr ; customization ; enterprise ; android ; aosp ; os","title":"OS Customization for XR Device","type":"post","url":"https://thinkuldeep.github.io/post/os-customization-for-xr-devices/"},{"content":"Change is the only constant, it requires continuous effort from humankind to understand the change that leads to success, and make us even more successful. In my earlier article, I talked about the success mantra, and also wrote about accepting the change when required. Sometimes the way we perceive our success becomes a blocker for becoming more successful. We accumulate some habits knowingly or unknowingly along the path of being successful, and mostly we never realize that those habits start blocking our way forward.\nToday, in the time of the Covid19 pandemic, even nature wants us to change the way work, the way we eat, the way we use natural resources, and other words the way we live. We will get over this pandemic, with a lot of learning and change. We need to change for humankind, and ourselves, after all, what got you here, won’t get you there.\nI penned down an article for the successful people and want to become more successful. Know the changes that are required to reach there. We might have achieved many goals and crossed milestones, but with all this, we may not reach there, as it requires constant monitoring and change in us.\nThe article is highly influenced by the book What Got You Here Won’t Get You There by Marshall Goldsmith Marshal is one of the world’s preeminent executive coaches, and this book is his experience of coaching successful people to become more successful. I recommend this book to everyone who thinks that they are successful, and they don’t need or need advice for being more successful. This book covers 20 habits that hold you back from the top, honestly, you may link many of them with your habits.\nMy takeaway from the book here -\nSuccess Myths The book starts nicely, directly hitting the critical point in the very first chapters with nice examples. Being a successful person, we are in the delusion of success,\n We too much believe in our skills that made us successful, This gives us confidence that we can succeed in the same way, Which adds another myth that we will succeed in the future, Why not we, as with all this, we are committed to the goals and beliefs. in fact, they are obsessed with the goal.  Successful people are the ones who want to become more successful, but the change required to become more successful is hard to finds, it is hard for us to believe why to change.\nAccumulated hold back habits Successful people with strong success myths described in the last section generally accumulates some of the following habits that hold them here, and don’t let them there. The higher we go, the more we prone to behavioral issues.\nSome of them holdback habits are -\nToo much me We the successful people, accumulate some habits where we value too much of being “me”. With this, wining becomes necessary for us in all situations even if it is not important,\n We argue too much and go at the level of putting down other people, or sometimes we withhold important information to stay important and disclose when the time to the limelight. We also try to add unnecessary value to other’s ideas, to remain in the light. When we listen to other’s ideas, even if it is of great importance, rather than saying “Thank you” to the person, we may suggest some un-valuable.  With such a state of mind, it is hard to value other’s ideas, and consequences might be that other people stop giving their opinion, which boosts this habit. We gain the habit expressing our opinion, no matter how hard hurtful or non-useful it is, just to realize our rights of “Too much me”. It blocks our way We can’t be masters of everything, but with a habit of putting “too much me” keep telling the world how smart are we, and this can some times lead to embarrassment when we arguing with other people with that expertise, we also tend to not value other’s expertise.\nDefend and Oppose With this holdback habit, we tend to defend what we say and oppose each and everything that others say. We tend to use words like “if”, “No”, “But” and “However” a lot in our conversation.\nWhen someone comes with an idea, our first reaction is “Let me tell you why it won’t work”. No matter what the idea is, our mind, first starts finding negatives from the idea.\nSuccess Bias We are so biased of the success that we feel we can make fun of anyone, pass judgment, or make even some descriptive comments, and they would ignore them in respect to our success. It is not true. The damage by our word is irreversible, it doesn\u0026rsquo;t matter how hard we apologize later.\nSome have a bias for some people, and they play favoritism.\nFailed to recognize others or eat up their credit Even some successful people have this habit of not recognizing others well and encourage them for their work. Even worse, some leader eats up the credit of others, and use their idea as their own idea.\nGeneral interpersonal holdback issues  Always making excuses, and blaming others to the issues Failed to express regret or gratitude when it is needed most Speak more and listen less. Talking in anger Not ready to listen to bad news React more and respond less  Know your holdback Habits The only way to know about your habits that hold you back is feedback. ThoughtWorks has a great culture of feedback, everyone gives feedback frequently, and it is advised to get feedback from all the diverse roles, and across teams.\nThe ‘self’ we think, and the ‘self’ rest of the world sees in us is mostly different. The only way to fill the gap is by getting right feedback.\nSome organizations also have 360-degree feedback and encourage people for one-on-one feedback with peers. We should know the art of taking feedback, and share a vision and agenda for asking the feedback. Consume the feedback peacefully. This is just one way of feedback, there are other ways to get feedback from others.\n Observe others, if we find some problem with them, try to see that problem in ourselves. It\u0026rsquo;s hard but, but be honest, we will get immediate feedback without really talking to anyone. Observe others, and see how they react when we talk to them or talk in general in the meeting. Note down their physical expressions, physical movement, ignorance, or so. Note down all of these, you will see some pattern.  The Change Begins The right time to start the change is now, identify the right thing you want to change and start it now. Make a plan, and tell the world that you are improving, yes, in fact, publicize to the world, that you are changing, and ask for a favor. Remember, and convey the message, that you can’t change the past but from today are trying to improve. Leave the past behind and move forward.\nGenerally, change begins with apologizing, the author calls it a magic move. Please mean it when you apologize to someone.\nImprove your listening skill, My friend Gary Butters says -\n You have two ears and one mouth\u0026hellip; use them in that proposition\u0026hellip;\nand in that order!\n If your statement not adding any value then don’t just say anything other than ‘thank you’. and yet this is the next key thing you do. Starting thanking people in your life, have gratitude towards them.\nAnd so on, identify that change that you want to make, and be clear why you want to do that change. eg. Complete the statement\n if you get rid of this holdback habit then ……………\n Measure the change The change becomes easy when we can measure it, if we can measure it then we can achieve it. and the best technique to measure is follow up. Once we declare that we are changing, just set up the follow ups with your peers, and people who signed up to favor us in our journey of change. Ask them about how much have we changed, what next they expect etc.\nYou are here, define your there and let the journey begins\nConclusion Let the change continue till the last bread, and keep improving every day for humankind and self, and be better you.\nIt is originally published at XR Practices Medium Publication\n","id":2,"tag":"general ; selfhelp ; success ; covid19 ; book-review ; takeaways ; change","title":"Change to become more successful!","type":"post","url":"https://thinkuldeep.github.io/post/change_to_become_more_successful_/"},{"content":"In the previous article, we described the importance of interoperability in while building Enterprise XR solutions, In the article, we will discuss how to manage user accounts in the XR device, and implement single sign-on across the XR apps. We will use Android’s AccountManger approach to login into active directory and integrated it into Unity. Please read my earlier article on setting up the app in active directory, log in using android webview, considering a web-based company login form should appear for login, and no custom login form is allowed to capture the credentials. \nImplement Android Library with custom AccountAuthenticator We will continue from the last section of the previous article, which has WebViewActivity which launch webview for logon.\nWebview Login Activity Let’s add a method to launch a webview activity.\npublic class WebViewActivity extends AppCompatActivity { ... private WebView webView; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); final String interceptScheme = getIntent().getStringExtra(INTENT_INPUT_INTERCEPT_SCHEME); final String url = getIntent().getStringExtra(INTENT_INPUT_URL); webView = new WebView(this); ... } public static void launchActivity(Activity activity, String url, String redirectURI, IResponseCallBack callBack){ Intent intent = new Intent(activity, WebViewActivity.class); intent.putExtra(WebViewActivity.INTENT_INPUT_INTERCEPT_SCHEME, redirectURI); intent.putExtra(WebViewActivity.INTENT_INPUT_URL, url); intent.putExtra(WebViewActivity.INTENT_RESPONSE_CALLBACK, new CustomReceiver(callBack)); activity.startActivity(intent); } private static class CustomReceiver extends ResultReceiver{ ... @Override protected void onReceiveResult(int resultCode, Bundle resultData) { if(WebViewActivity.INTENT_RESULT_CODE == resultCode){ String code = resultData.getString(WebViewActivity.INTENT_RESULT_PARAM_NAME); callBack.OnSuccess(code); } else { callBack.OnFailure(\u0026#34;Not a valid code\u0026#34;); } } } Create binding service for custom Account Type  Create a custom authenticator, extending AbstractAccountAuthenticator, implement all abstract methods as follows.  public class AccountAuthenticator extends AbstractAccountAuthenticator { public AccountAuthenticator(Context context){ super(context); } @Override public Bundle addAccount(AccountAuthenticatorResponse accountAuthenticatorResponse, String s, String s1, String[] strings, Bundle bundle) throws NetworkErrorException { // do all the validations, call AccountAuthenticatorResponse for  //any failures.  return bundle; } ... @Override public Bundle getAuthToken(AccountAuthenticatorResponse accountAuthenticatorResponse, Account account, String s, Bundle bundle) throws NetworkErrorException { return bundle; } ... }  Create a service to bind the custom authenticator  public class AccountAuthenticatorService extends Service { @Override public IBinder onBind(Intent intent) { AccountAuthenticator authenticator = new AccountAuthenticator(this); return authenticator.getIBinder(); } }  Add the service in Android Manifest in the application tag  \u0026lt;service android:name=\u0026#34;com.tw.userauthenticator.AccountAuthenticatorService\u0026#34;\u0026gt; \u0026lt;intent-filter\u0026gt; \u0026lt;action android:name=\u0026#34;android.accounts.AccountAuthenticator\u0026#34; /\u0026gt; \u0026lt;/intent-filter\u0026gt; \u0026lt;meta-data android:name=\u0026#34;android.accounts.AccountAuthenticator\u0026#34; android:resource=\u0026#34;@xml/authenticator\u0026#34; /\u0026gt; \u0026lt;/service\u0026gt;  It refers to an XML file that defines the type of account the authenticator service will bind.  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;account-authenticator xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; android:accountType=\u0026#34;com.tw.user\u0026#34; android:label=\u0026#34;MyAccount\u0026#34; android:icon=\u0026#34;@drawable/ic_launcher\u0026#34; android:smallIcon=\u0026#34;@drawable/ic_launcher\u0026#34; /\u0026gt; This adds support for account type “com.tw.user”. The app which includes this library will intercept the request for this type.\nManage Accounts of Custom Type Let\u0026rsquo;s add class to manage user accounts.\npublic class UserAccountManager { public static final String KEY_ACCOUNT_TYPE = AccountManager.KEY_ACCOUNT_TYPE; public static final String KEY_ACCOUNT_NAME = AccountManager.KEY_ACCOUNT_NAME; public static final String KEY_USER_NAME = \u0026#34;userName\u0026#34;; ... public static final String KEY_AUTH_TOKEN = \u0026#34;authToken\u0026#34;; public static final String ACCOUNT_TYPE = \u0026#34;com.tw.user\u0026#34;; ... } Now let\u0026rsquo;s add methods to this class, to manage account\n Add User Account — This method adds an account to android AccountManager. Since we are trying to add an account of type “com.tw.user”, binder service will call our AccountAuthenticator.addAccount. We may do data validation there, however, we are currently returning the same bundle there. After this, it will call AccountManagerCallback which we have provided in the addAccount call below.  public static void addAccount(Context context, String bundleData, final IResponseCallBack callback) { final AccountManager accountManager = AccountManager.get(context); Bundle bundle = new Bundle(); try { JSONObject jsonObject = new JSONObject(bundleData); bundle.putString(KEY_ACCOUNT_TYPE, ACCOUNT_TYPE); bundle.putString(KEY_ACCOUNT_NAME, \u0026#34;MyAccount\u0026#34;); ... //prepare bundle  accountManager.addAccount(ACCOUNT_TYPE, authTokenType, null, bundle, (Activity) context, new AccountManagerCallback\u0026lt;Bundle\u0026gt;() { @Override public void run(AccountManagerFuture\u0026lt;Bundle\u0026gt; future) { Bundle udata = null; try { udata = future != null ? future.getResult() : null; if (udata != null) { String accountName =udata.getString(KEY_ACCOUNT_NAME); String accountType= udata.getString(KEY_ACCOUNT_TYPE); Account account= new Account(accountName,accountType); boolean result= accountManager.addAccountExplicitly( account, null, udata); if(result){ callback.OnSuccess(\u0026#34;Account Added Successfully\u0026#34;); } else { callback.OnFailure(\u0026#34;Account can not be added\u0026#34;); } } else { callback.OnFailure(\u0026#34;Error! No user added\u0026#34;); } } catch (Exception e) { callback.OnFailure(\u0026#34;Error! \u0026#34; + e.getMessage()); } } }, new Handler(Looper.getMainLooper())); } catch (Exception e) { callback.OnFailure(\u0026#34;Error! \u0026#34; + e.getMessage()); } }\n Remove User Account — This method removes an account from android AccountManager.  public static void removeAccount(Context context, final IResponseCallBack callnack) { final AccountManager accountManager = AccountManager.get(context); Account[] accounts = accountManager.getAccountsByType(ACCOUNT_TYPE); if(accounts.length \u0026gt; 0) { Account account = accounts[0]; try { boolean result = accountManager.removeAccountExplicitly( account); if(result){ callnack.OnSuccess(\u0026#34;Account removed successfully!\u0026#34;); } else { callnack.OnFailure(\u0026#34;Error! Could not remove account\u0026#34;); } } catch (Exception e) { callnack.OnFailure(\u0026#34;Error! +\u0026#34; + e.getMessage()); } } else { callnack.OnFailure(\u0026#34;Error! No account found\u0026#34;); } }  Get Login In User Account — This method fetches logged in user data.  public static void getLoggedInUser(Context context, final IResponseCallBack responseCallBack) { final AccountManager accountManager = AccountManager.get(context); Account[] accounts = accountManager.getAccountsByType(ACCOUNT_TYPE); try { if(accounts.length \u0026gt; 0) { Account account = accounts[0]; final JSONObject jsonObject = new JSONObject(); jsonObject.put(KEY_USER_NAME, accountManager.getUserData(account, KEY_USER_NAME)); ... prepare the response. responseCallBack.OnSuccess(jsonObject.toString()); } else { responseCallBack.OnFailure(\u0026#34;Error! No logged user of the type\u0026#34; + ACCOUNT_TYPE); } } catch (Exception e) { responseCallBack.OnFailure(\u0026#34;Error!\u0026#34; + e); } } Source code for android library can be found at https://github.com/thinkuldeep/xr-user-authentication\nUnity Authenticator App Let’s customize the unity app that we have created in the last article, as follows, build the android library and include it in the unity project.\nAdd methods to ButtonController.cs\nLogin — Launch WebView for Login On clicking Login button, the following logic opens the WebViewActivity implemented in the Android library and load the provided URL.\nprivate void OnLoginClicked() { AndroidJavaClass WebViewActivity = new AndroidJavaClass(\u0026#34;com.tw.userauthenticator.WebViewActivity\u0026#34;); _statusLabel = \u0026#34;\u0026#34;; AndroidJavaObject context = getUnityContext(); WebViewActivity.CallStatic(\u0026#34;launchActivity\u0026#34;, context, authUri, redirectUri, new LoginResponseCallback( this)); } make sure of the redirectURI. The webview will intercept this redirectURI and return code, which we use for getting the access_token.\nprivate class LoginResponseCallback : AndroidJavaProxy { private ButtonController _controller; public LoginResponseCallback(ButtonController controller) : base(\u0026#34;com.tw.userauthenticator.IResponseCallBack\u0026#34;) { _controller = controller; } public void OnSuccess(string result) { _statusLabel = \u0026#34;Code received\u0026#34;; _statusColor = Color.black; _controller.startCoroutineGetToken(result); } public void OnFailure(string errorMessage) { _statusLabel = errorMessage; _statusColor = Color.red; } } Login — Fetch the Access Token Once we receive the authorization code, we need to fetch access_token by the HTTP token URL.\nvoid startCoroutineGetToken(string code) { StartCoroutine(getToken(code)); } IEnumerator getToken(string code) { WWWForm form = new WWWForm(); form.headers[\u0026#34;Content-Type\u0026#34;] = \u0026#34;application/x-www-form-urlencoded\u0026#34;; form.AddField(\u0026#34;code\u0026#34;, code); form.AddField(\u0026#34;client_id\u0026#34;, clientId); form.AddField(\u0026#34;grant_type\u0026#34;, \u0026#34;authorization_code\u0026#34;); form.AddField(\u0026#34;redirect_uri\u0026#34;, redirectUri); var tokenRequest = UnityWebRequest.Post(tokenUri, form); yield return tokenRequest.SendWebRequest(); if (tokenRequest.isNetworkError || tokenRequest.isHttpError) { _statusLabel = \u0026#34;Login failed - \u0026#34; + tokenRequest.error; _statusColor = Color.red; } else { var response = JsonUtility.FromJson\u0026lt;TokenResponse\u0026gt;(tokenRequest.downloadHandler.text); _statusLabel = \u0026#34;Login successful! \u0026#34;; _statusColor = Color.black; TokenUserData userData = decodeToken(response.access_token); AddAccount(userData, tokenResponse); } } Login — Add Account to Android Accounts Once we get the access_token, we can decode access_token get some user details from it.\nprivate class TokenUserData { public string name; public string given_name; public string family_name; public string subscriptionId; } private TokenUserData decodeToken(String token) { AndroidJavaClass Base64 = new AndroidJavaClass(\u0026#34;java.util.Base64\u0026#34;); AndroidJavaObject decoder = Base64.CallStatic\u0026lt;AndroidJavaObject\u0026gt;(\u0026#34;getUrlDecoder\u0026#34;); var splitString = token.Split(\u0026#39;.\u0026#39;); var base64EncodedBody = splitString[1]; string body = System.Text.Encoding.UTF8.GetString(decoder.Call\u0026lt;byte[]\u0026gt;(\u0026#34;decode\u0026#34;, base64EncodedBody)); return JsonUtility.FromJson\u0026lt;TokenUserData\u0026gt;(body); } Once we have all the detail for the account, we call the add account to android accounts using the library APIs.\nprivate void AddAccount(TokenUserData userData, TokenResponse tokenResponse) { AndroidJavaClass AccountManager = new AndroidJavaClass(\u0026#34;com.tw.userauthenticator.UserAccountManager\u0026#34;); UserAccountData accountData = new UserAccountData(); accountData.userName = userData.given_name +\u0026#34; \u0026#34; + userData.family_name ; accountData.subscriptionId = userData.subscriptionId; accountData.tokenType = tokenResponse.token_type; accountData.authToken = tokenResponse.access_token; AccountManager.CallStatic(\u0026#34;addAccount\u0026#34;, getUnityContext(), JsonUtility.ToJson(accountData), new AddAccountResponseCallback( this)); } Get Logged-in User On Get LoggedIn User, call a respective method from the android library.\nprivate void OnGetLoggedUserClicked() { AndroidJavaClass AccountManager = new AndroidJavaClass(\u0026#34;com.tw.userauthenticator.UserAccountManager\u0026#34;); AccountManager.CallStatic(\u0026#34;getLoggedInUser\u0026#34;, getUnityContext(), new LoginResponseCallback(false, this)); } Logout — Remove Account to Android Accounts On logout, call remove the account.\nprivate void OnLogoutClicked() { AndroidJavaClass AccountManager = new AndroidJavaClass(\u0026#34;com.tw.userauthenticator.UserAccountManager\u0026#34;); AccountManager.CallStatic(\u0026#34;removeAccount\u0026#34;, getUnityContext(), new LogoutResponseCallback()); } Run and test Lets now test all this. Export the unity project/run in the device. Try login, get logged in user, and logout API. In the next section, we will try to access the logged-in user outside of this authenticator app.\nSharing Account with other XR apps Once you logged into the XR Authenticator App and added an account in android accounts, it can be accessed in any other app using Android APIs. Let\u0026rsquo;s create another unity project on similar lines. AccountViewer XR App.\nThe cube is supposed to rotate only if a user is logged in the android system, and see the logged-in user details.\nGet User Account from Android Accounts It does not require any native plugin to be included. you can get the shared account directly via android APIs - accountManager.getAccountsByType(“com.tw.user”)\nprivate UserAccountData getLoggedInAccount() { UserAccountData userAccountData = null; var AccountManager = new AndroidJavaClass(\u0026#34;android.accounts.AccountManager\u0026#34;); var accountManager = AccountManager.CallStatic\u0026lt;AndroidJavaObject\u0026gt; (\u0026#34;get\u0026#34;, getUnityContext()); var accounts = accountManager.Call\u0026lt;AndroidJavaObject\u0026gt; (\u0026#34;getAccountsByType\u0026#34;, \u0026#34;com.tw.user\u0026#34;); var accountArray = AndroidJNIHelper.ConvertFromJNIArray\u0026lt;AndroidJavaObject[]\u0026gt; (accounts.GetRawObject()); if (accountArray.Length \u0026gt; 0) { userAccountData = new UserAccountData(); userAccountData.userName = accountManager.Call\u0026lt;string\u0026gt; (\u0026#34;getUserData\u0026#34;, accountArray[0], \u0026#34;userName\u0026#34;); ... userAccountData.tokenType = accountManager.Call\u0026lt;string\u0026gt; (\u0026#34;getUserData\u0026#34;, accountArray[0], \u0026#34;tokenType\u0026#34;); userAccountData.authToken = accountManager.Call\u0026lt;string \\. (\u0026#34;getUserData\u0026#34;, accountArray[0], \u0026#34;authToken\u0026#34;); } return userAccountData; } Get profile using logged in user’s token Read the token and get the profile data from the HTTP URL https://graph.microsoft.com/beta/me/profile/names with JWT token.\nIEnumerator getProfile(UserAccountData data) { UnityWebRequest request = UnityWebRequest.Get(getProfileUri); request.SetRequestHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;); request.SetRequestHeader(\u0026#34;Authorization\u0026#34;, data.tokenType + \u0026#34; \u0026#34; + data.authToken); yield return request.SendWebRequest(); if (request.isNetworkError || request.isHttpError) { _labels[indexGetProfile] = \u0026#34;Failed to get profile\u0026#34; + request.error; _colors[indexGetProfile] = Color.red; } else { var userProfile = JsonUtility.FromJson\u0026lt;UserProfileData\u0026gt;(request.downloadHandler.text); _labels[indexGetProfile] = \u0026#34;DisplayName: \u0026#34; + userProfile.displayName + \u0026#34;\\nMail: \u0026#34; + userProfile.mail + \u0026#34;\\nDepartment: \u0026#34; + userProfile.department + \u0026#34;\\nCreated Date: \u0026#34; + userProfile.createdDateTime; _colors[indexGetProfile] = Color.black; } } Check if a user is logged Even application focus, check if a user exists in android accounts. if the user exists then load the profile data.\nprivate void OnApplicationFocus(bool hasFocus) { if (hasFocus) { CheckIfUserIsLoggedIn(); } } private void CheckIfUserIsLoggedIn() { UserAccountData data = GetLoggedInAccount(); if (data == null) { _isUserLoggedIn = false; _labels[indexWelcome] = \u0026#34;Welcome Guest!\u0026#34;; _labels[indexGetProfile] = \u0026#34;\u0026#34;; } else { _isUserLoggedIn = true; _labels[indexWelcome] = \u0026#34;Welcome \u0026#34; + data.userName + \u0026#34;!\u0026#34;; StartCoroutine(getProfile(data)); } } On update make sure you rotate the cube only if a user is logged in.\nprivate void Update() { if (_isUserLoggedIn) { cube.transform.Rotate(Time.deltaTime * 2 * _rotateAmount); } requestLoginButton.gameObject.SetActive(!_isUserLoggedIn); welcomeText.text = _labels[indexWelcome]; getProfileResponse.text = _labels[indexGetProfile]; getProfileResponse.color = _colors[indexGetProfile]; } Run and test Login on the Account Authenticator XR App, as in the last step. Open the Account Viewer XR App, you should see the Cube Rotating and Profile details of the logged-in user.\nRequest Login from external XR app Let’s implement the request login from the external unity app\nAdd Request Login Add button for request login in the Account Viewer app. It will find an intent for the Account Authenticator app running in package com.tw.threed.authenticator. If the intent is available, means the XR authenticator app is installed in the device, then it will start the intent with a string parameter external_request.\nprivate void OnRequestLoginClicked() { AndroidJavaObject currentActivity = getUnityContext(); AndroidJavaObject pm = currentActivity.Call\u0026lt;AndroidJavaObject\u0026gt;(\u0026#34;getPackageManager\u0026#34;); AndroidJavaObject intent = pm.Call\u0026lt;AndroidJavaObject\u0026gt;(\u0026#34;getLaunchIntentForPackage\u0026#34;, \u0026#34;com.tw.threed.authenticator\u0026#34;); if (intent != null) { intent.Call\u0026lt;AndroidJavaObject\u0026gt;(\u0026#34;putExtra\u0026#34;,\u0026#34;external_request\u0026#34;, \u0026#34;true\u0026#34;); currentActivity.Call(\u0026#34;startActivity\u0026#34;, intent); labels[requestlogin] = \u0026#34;Send Intent\u0026#34;; colors[requestlogin] = Color.black; } else { labels[requestlogin] = \u0026#34;No Intent found\u0026#34;; colors[requestlogin] = Color.red; } } Handle external login request in the Account Authenticator App There are multiple ways to receive externally initiated intent in Unity, but most of them need a native plugin to extend UnityPlayerActivity class. Here is another way, handle on focus event of any GameObject and access the current activity and check if intent has the external_request parameter. Call the OnLoginClicked action if it found the parameter.\nprivate bool inProcessExternalLogin = false; private void OnApplicationFocus(bool hasFocus) { if (hasFocus) { AndroidJavaObject ca = getUnityContext(); AndroidJavaObject intent = ca.Call\u0026lt;AndroidJavaObject\u0026gt;(\u0026#34;getIntent\u0026#34;); String text = intent.Call\u0026lt;String\u0026gt;(\u0026#34;getStringExtra\u0026#34;, \u0026#34;external_request\u0026#34;); if (text != null \u0026amp;\u0026amp; !inProcessExternalLogin) { _statusLabel = \u0026#34;Login action received externally\u0026#34;; _statusColor = Color.black; inProcessExternalLogin = true; OnLoginClicked(); } } } We need to quit the app after successfully adding the account, so it can go in. background.\nprivate class AddAccountResponseCallback : AndroidJavaProxy { ... void OnSuccess(string result) { _statusLabel = result; _statusColor = Color.black; if (_controller.inProcessExternalLogin) { Application.Quit(); } } ... } Run and test  Open Account Viewer App and request login (it will be visible only if the user is not logged in) It will open the Account Authenticator XR app and invoke web login. Once you log in it will add a user account in accounts, and close the Account Authenticator XR app. On returning to the Account Viewer app, you will the rotating cube rotating and user profile details. Now go back to the Account Authenticator app, and logout (ie remove the account). On the Account Viewer app, the cube is no more rotating, and no user profile data is shown.  This completes the tests. You can found complete source code here :\n Android Library: https://github.com/thinkuldeep/xr-user-authentication Account Authenticator App: https://github.com/thinkuldeep/3DUserAuthenticator Account Viewer App: https://github.com/thinkuldeep/3DAccountViewer  Conclusion In this article, we have learned how to do single sign-on in the android based XR device, and share the user context with other XR applications. Single sign-on is one of the key requirements for the enterprise-ready XR device and applications.\nIt was originally published at XR Practices Medium Publication\n","id":3,"tag":"xr ; enterprise ; android ; unity ; tutorial","title":"User Account Management In XR","type":"post","url":"https://thinkuldeep.github.io/post/user-account-management-in-xr/"},{"content":"The web has grown from a read-only web (Web 1.0) to interactive web (Web 2.0) and then moved into the semantic web which is more connected and more immersive. 3D content on the web is there for quite some time, the most web-browsers support rendering 3D content natively. The rise for XR technologies and advancements in devices and the internet is leading the demand for Web-based XR. It will be a norm for web-based development.\nWe are going through the Covid19 time, and most of us are working from home. These days, one message is quite popular on social media, asking to keep your kids engaged, and let them bring Google 3D animals in your bedroom\nHowever, this feature was there for some time now. Google search pages have provision to show models in 3D in your space, you need a compatible phone for making it work.\nThis is WebXR. Experiencing XR directly on a website without a need for special apps, or downloads. Generally, XR application development needs a good amount of effort and cost on platforms such as Unity 3D, Vuforia, Wikitude. The content is delivered in the form of an app for XR enabled smartphones or head-mounted devices such as Hololens, Oculus, NReal, or similar. With WebXR technology, we can build applications directly with our favorite web technology (HTML, JavaScript) and deliver the content on our website.\nThere are few WebXR libraries popular these days such as babylon.js, three.js, and A-frame. WebVR is quite stable but WebXR is experimental at this stage in most of the libraries. In addition to Google and Mozilla, organizations like 8th Wall, XR+ are also putting great effort into making the WebXR stable. At ThoughtWorks, we have built some cool projects for our clients utilizing available WebXR libraries.\nIn this post, we will say hello to WebXR, and also takes you through the classic XR development in Unity 3D. The first part of the article is for people who are new to Unity 3D, so they need to say hello to the Unity 3D platform, then we will go to the WebXR world, and understand how we can co-relate both the world.\nNote: — We will discuss the WebAR part for android here, you may relate it to WebVR and for other devices, the concept is more or less the same. Follow the respective libraries documentation if you are more interested in the WebVR part or for other devices.\nHello XR World! If you haven’t yet gone through Unity 3D, please read below a cool article by my colleague Neelarghya Mondal -\n Well let me tell you this won’t be the end all be all… This is just the beginning of a series of Journal log styled… Let’s get started with Unity…\n Then set up the first XR project using AR Core — [the google guidelines](the google guidelines), Import the ARCore SDK package into Unity.\n Remove the main camera, light and the add prefabs “ARCore Device” and “Environment Light” available in ARCore SDK. Create a prefab of Cube with rotating script  public class RotateCube : MonoBehaviour { private Vector3 rotation = new Vector3(20, 30, 0); void Update() { transform.Rotate(rotation * Time.deltaTime); } }  Create an InputManager class that instantiates the cube prefab at the touch position.  public class InputManager : MonoBehaviour { public Camera camera; public GameObject cubePrefab; // Update is called once per frame  void Update() { Touch touch; if (Input.touchCount \u0026gt; 0 \u0026amp;\u0026amp; (touch = Input.GetTouch(0)).phase == TouchPhase.Began) { CreateCube(touch.position); } else if (Input.GetMouseButtonDown(0)) { CreateCube(Input.mousePosition); } } void CreateCube(Vector2 position) { Ray ray = camera.ScreenPointToRay(position); Instantiate(cubePrefab, (ray.origin + ray.direction), Quaternion.identity); } }  You can test it directly on an Android Phone (ARCore compatible). Connect the phone via USB, and test it with ARCore Instant preview. It needs some extra services running on the device. Alternatively, you can just build and run the project for android, and it will install the app to the device, and you can play with your XR app. This completes the first part, and now we know how a typical AR app is built and delivered. Find the source code here  Hello Web XR! Let’s say hello to Web XR. We will try to implement a similar example that we have implemented in the last section, but this time without the Unity 3D platform and without building an app for the device. We will implement a simple web page that can do the same, using WebXR library https://threejs.org\nCreate a web page  Create a work folder and open it in the editor — I use Intellij but you may use any text editor. Create an HTML file and host it in web-server — index.html, Intellij has built it web-server which is just a click away, but you may use other easy ways You may download three.js dependencies on your own or just download via some package manager — npm install three Follow the steps described by three.js and update the index.html page — Creating-a-scene For XR enabled scene keep renderer.xr.enabled = true; Now, index.html looks like below with an On Touch logic which adds a cube on touching the screen.  \u0026lt;script type=\u0026#34;module\u0026#34;\u0026gt; import * as THREE from \u0026#39;./node_modules/three/build/three.module.js\u0026#39;; import { ARButton } from \u0026#39;./node_modules/three/examples/jsm/webxr/ARButton.js\u0026#39;; var container; var camera, scene, renderer, lastmesh; var controller; init(); animate(); function init() { container = document.createElement( \u0026#39;div\u0026#39; ); document.body.appendChild( container ); scene = new THREE.Scene(); camera = new THREE.PerspectiveCamera( 70, window.innerWidth / window.innerHeight, 0.01, 20 ); var light = new THREE.HemisphereLight( 0xffffff, 0xbbbbff, 1 ); light.position.set( 0.5, 1, 0.25 ); scene.add( light ); renderer = new THREE.WebGLRenderer( { antialias: true, alpha: true } ); renderer.setPixelRatio( window.devicePixelRatio ); renderer.setSize( window.innerWidth, window.innerHeight ); renderer.xr.enabled = true; container.appendChild( renderer.domElement ); document.body.appendChild( ARButton.createButton( renderer ) ); var geometry = new THREE.BoxGeometry( 0.1, 0.1, 0.1 ); function onSelect() { var material = new THREE.MeshNormalMaterial(); var mesh = new THREE.Mesh( geometry, material ); mesh.position.set( 0, 0, - 0.3 ).applyMatrix4( controller.matrixWorld ); mesh.quaternion.setFromRotationMatrix( controller.matrixWorld ); scene.add(mesh); lastmesh = mesh; } controller = renderer.xr.getController( 0 ); controller.addEventListener( \u0026#39;select\u0026#39;, onSelect ); scene.add( controller ); window.addEventListener( \u0026#39;resize\u0026#39;, onWindowResize, false ); } function onWindowResize() { camera.aspect = window.innerWidth / window.innerHeight; camera.updateProjectionMatrix(); renderer.setSize( window.innerWidth, window.innerHeight ); } function animate() { renderer.setAnimationLoop( render ); } function render() { if(lastmesh){ lastmesh.rotation.x += 0.1; lastmesh.rotation.y += 0.2; } renderer.render(scene, camera ); } \u0026lt;/script\u0026gt; Host and test the web page Publish the page in the web-server and test it. The page is now hosted in the inbuilt web-server of IntelliJ, make sure external access is enabled. http://localhost:8001/hello-webxr/index.html. It is still not ready to be used on browsers, we need to do some customizations on the browsers to make it work.\nOn PC, we need to install WebXR emulators in the browser to make it work. VR emulator is great but the AR emulator still doesn’t work well.\nOn Mobile, open chrome browser and open chrome://flags page. Search for XR and enable all the experimental features. Make sure The device must have ARCore support. Now we want to test the page which is running on PC/Laptop in the chrome browser on the android phone. There are multiple ways to do that (port forwarding, hotspot, etc). Simplest is, come on the same wifi network and access the page via IP instead of localhost. Type in http://192.168.0.6:8001/hello-webxr/index.html\nOnce the web page is loaded, it will ask to start XR experience, and also ask for the user consent for accessing the camera.\nOnce approved, it scans the area and you can start placing the cubes.\nSource code is available here\nTry this link in your android phone right now, and experience the WebXR. https://thinkuldeep.github.io/hello-webxr/\nI tried, a similar implementation can be done with Babylon JS but “immersive-ar” mode is not stable there when we host webpage, however, “immersive-vr” mode works great. So these webpages can be opened in any supported browser on the XR devices, you get all advantage of Web, and server the XR content simply from your website. This completes our introduction with WebXR.\nConclusion We have got an introduction to XR as well as WebXR. There are some features in XR which may not be achieved by WebXR but it is still a great option to take the technology to a wider audience. There are already great examples at the respective sites of these libraries, the community is also submitting some good projects samples and games. Try those, and stay tuned to WebXR, it is coming.\nIt is originally published at XR Practices Medium Publication\n","id":4,"tag":"xr ; unity ; webxr ; immersive-web ; spatial web ; general ; tutorial","title":"WebXR - the new Web","type":"post","url":"https://thinkuldeep.github.io/post/webxr-the-new-web/"},{"content":"In Part I of the article, we summarized our observations of eXtended reality’s foundational blocks - AR, VR and MR. We also discussed the popular and most relevant tools and implementations of the new technology. In Part II of the article, we will be looking at a few accessible and novel implementations of the tech.\nAt ThoughtWorks, we have delivered both XR solutions and components of XR SDK (Software Development Kit) on the back of which XR solutions are built. We have explored Unity 3D technology beyond the gaming bucket. Infact, ThoughtWorks’ Technology Radar states,\n “\u0026hellip;Unity has become the platform of choice for VR and AR application development because it provides the abstractions and tooling of a mature platform\u0026hellip;Yet, we feel that many teams, especially those without deep experience in building games, will benefit from using an abstraction such as Unity\u0026hellip; it offers a solution for the huge number of devices.”\n We have also built an XR incubation center that lets us experiment with XR experiments while collaborating on agile development practices like TDD and CI/CD for XR.\nAll this work with XR tech has helped us understand the space that much better. And, I have taken this opportunity to round up some really interesting use cases for the tech that will be ‘good-to-know’ for business leaders who want to explore the tech’s potential.\nUse case 1: training and maintenance XR tech has a direct impact on the improved efficiency and effectiveness of training, and maintenance and repair use cases.\nVR tech can generate and simulate environments that are either hard to reproduce or involve huge costs and/or risk. Examples of such scenarios are factory training sessions or those on fire safety or ‘piloting’ an aircraft.\nAR, on the other hand, is a great way to provide technicians with contextual support in a work environment. For instance, a technician wearing a pair of AR-enabled smart glasses can view digital content that’s superimposed on their work environment. This could be in the form of step-by-step instructions for a task or to sift through relevant manuals and videos while they are on the assembly line/or on field performing a task or it could be used to issue a voice command. The AR device is enabled to also take a snapshot of the work environment for compliance checks. Additional features include the technician being able to stream the experience to a remote expert, who can annotate the live environment and review the work.\nHere’s an interesting case study from ThoughtWorks of how XR tech is transforming airline operations.\nUse case 2: locate and map Autonomous vehicles leverage techniques like Simultaneous Localization and Mapping (SLAM) to build virtual maps and locate objects in an environment. Similar technology empowers XR-enabled devices to detect unique environments and track device positions within.\nThis Virtual Positioning System can help build indoor positioning applications for large premises like airports, train stations, warehouses, factories and more. Such a system also allows users to mark, locate and navigate to specific target points.\nAt ThoughtWorks, we recently implemented a concept for indoor positioning at our offices. It’s a mobile app called Office Explorer, and when used with an AR-enabled smartphone or tablet, configures the entire office on a 2D map that visitors can use to explore the space.\nThis usecase was also quoted at Google DevFest\nWe have built office-explorer #DevFest2019 pic.twitter.com/0yRz7Euo8J\n\u0026mdash; Kuldeep Singh (@thinkuldeep) September 10, 2019  Visitors or new ThoughtWorkers can follow the augmented path on the app to reach meeting rooms and work stations. This app was built using Unity 3D, ARCore and ARKit. The backend services and web portal were built on React, Kotlin, MongoDB and Micronaut.\nUse case 3: product customization and demonstration Virtual, CAD models or paper-drawn prototypes usually precede final physical products. What’s more, the former also allows for affordable customizations in an XR environment. Consumers have an opportunity to try 3D models of products before they buy it.\nBelow is a quick concept that was created at ThoughtWorks, where one could customize a particular virtual model of a vehicle with respect to colour, interiors and fabrics. They could also step inside the virtual car and experience the personalizations, evaluate how their car looks and fits in their garage or in front of the house.\nThoughtWorkers experimenting with AR-enabled customization of a vehicle. Our app used Unity 3D and ARCore to detect the plane surface and place the product’s 3D model before commencing customizations. The same technology can be used to build an entire driving experience - a great sales tool! An additional benefit of this approach is one of the most popular features when demonstrating a product; the complete 360° visualization of it.\nHere is how Thoughtworks helped Daimler build innovative tools to support the latters’ futuristic sales experience.\nUse case 4: contextual experiences Gartner states that 46% of global retailers planned to deploy either AR or VR solutions to meet customer service experience requirements. The global research and advisory firm also foretells that no less than 100 million consumers will use AR to shop both online and in-store in the future.\nBusinesses are being disrupted by both the sheer amount of data they have at their disposal and the way they engage with that date. This data is in the form of buying history, product reviews, product-health, recommendations, usages statistics, features level analysis, comparative studies, social sentiment analysis for the product and more.\nA lot of customers look to such data as they make decisions they can trust and be confident in. This gives businesses to present (hopefully unbiased) data within the right context, empowering consumers to make their decisions quickly.\nThoughtWorks’ TellMeMore app displays relevant data for a book An implementation called TellMeMore is an app that we designed at ThoughtWorks. It aims at providing a better in-store product experience by overlaying information like book reviews, number of pages and comparative prices on/beside the product. This app was created using Vuforia and Unity3D.\nThis is illustrative of opportunities to enhance customer experiences to the extent that without opening a product, customers have access to product insights and even experience detailed 3D models of the same. Add to this, the option of amplifying seemingly boring static objects such as event posters or product advertisements when viewed through an AR companion app.\nThoughtWorks XR day’s paper poster turned into an AR experience: Use case 5: customer engagement 2016’s fad, Pokémon GO is perhaps AR’s most famous champion. Historically, gamification and VR have proven to better engage users. Today, shopping malls and business conferences leverage VR experience studios to engage kids and customers alike. Today, we have kids riding a roller coaster without even sitting on the actual structure.\nThoughtWorkers have implemented a smartphone-based AR concept called LookARound that can involve visitors at expos and events. The flow of activity is this -\n Users scan a visual cue (like a QR code) within the event area Users have to find a 3D goodie that\u0026rsquo;s hidden close to the visual cue. It will be superimposed (Pokémon GO style) on the 3D environment around the user. The app appraises users of the distance between them and the 3D goodie Users can collect the goodie and compete with other players.  LookARound was a huge hit at a two day internal office-wide event, ‘India Away Day 2019.’ 1700 ThoughtWorkers explored different points of interests at the venue, such as break-out sessions, tech stalls and event areas while engaging with AR.\nSnapshot of the LookAround App at ThoughtWorks India Away Day 2019 At the Away Day, 500 ThoughtWorkers competed with each other at a time. They were encouraged by 3D leaderboards showcased on Microsoft Hololens and Oculus Quest.\nConclusion XR tech is evolving at such a rate that the untapped potential boggles the mind. And, we believe the software’s evolution should be matched by the hardware. The latter needs to be user-friendly in terms of field of view and lightweight with immense processing and battery power.\nThe software on the other hand, needs to take a more informed advantage of AI and ML to better estimate diverse environments, making it accessible to any and every possible scenario. Businesses also need to proactively build as many use cases as possible, fix shortcomings and contribute to XR development practices. VR is a reality and has us primed for the pronounced impact of AR and MR tech in the future.\nThis article was originally published on ThoughtWorks Insights and XR Practices Publication\n","id":5,"tag":"xr ; usecases ; thoughtworks","title":"eXtending reality with AR and VR - Part 2","type":"post","url":"https://thinkuldeep.github.io/post/extending_reality_with_ar_and_vr-2/"},{"content":"The way we interact with technology today is not too far from what was predicted by futuristic, sci-fi pop culture. We are living in a world where sophisticated touch and gesture based interactions are collaborating with state of the art wearables, sensors, Augmented Reality (AR), Virtual Reality (VR) and Mixed Reality (MR). And, this is eXtending user experiences to be extremely immersive.\nAdd to this, Gartner’s expectation that 5G and AR/VR implementation will transform not only customer engagement but brands’ entire product management cycles as well. Infact, according to IDC, spending on AR and VR is expected to reach $18.8 billion US dollars this year apart from enjoying more than a 75% compound annual growth rate through to 2023.\nEven world famous tech conferences like CES 2020 are not immune to the allure of AR/VR products. Infact, CES recognized Human Capable’s AR Norm Glasses as the best of innovation at the event. We are also seeing a rise in several new players and devices like NReal,RealMax and North.\nThe Seismic Shifts For over two decades, ThoughtWorks has been steering organizations through the dynamic world of tech innovation, right from AI to ML to the above mentioned AR and VR. The Seismic Shifts report is the company’s broad round up of upcoming tech trends and a ‘how-to’ playbook.\nFor the purpose of this article, I’d like to draw your attention to one particular shift, Evolving Interactions. ThoughtWorks’ report on the Seismic Shifts states,\n “We must evolve our thinking—and our capabilities—beyond the keyboard and the screen. Mixed reality (MR) will become the norm.”\n If nothing else, this is indicative of the radical evolution of people’s interaction with technology.\nTypes of Reality To get a better handle of what ‘beyond the keyboard and the screen’ means, let’s look at the different terms used when discussing reality tech -\nAugmented reality AR overlays digital content on to a real environment. Here is a list of the multiple tools that enhance AR implementation in the market today -\nSmart glasses project digital content right in front of the user\u0026rsquo;s eye. The last 5 years have seen the progress of small glasses from bulky gadgets to lightweight glasses packed with more processing power, better battery life, a wider field of view and consistent connectivity. Google Glass, Vuzix, Epson, NReal are some of the popular devices in this segment.\nAR capable smartphones and tablets that run AR applications are the most affordable link to augmented reality use cases. The eco-system that supports AR application development for Android and iOS devices is rich with several tools and techniques like ARCore, ARKit, Unity AR Foundation. Smartphone manufacturers are also powering their more recent phones with AR-compatible hardware. For example, here is the ever growing list of ARCore supported devices from Google.\nProjection-based display devices allow digital content to be projected onto a glass surface. For example, Mercedes’ Head-Up Display, HUD casts content onto the vehicle’s windshield glass. Drivers can view augmented information like maps, acceptable speed limits and more.\nVirtual Reality VR is an immersive experience that shuts out the physical world and takes one into a virtual or computer-generated world.\nHead Mounted Display (HMD) devices on the market include Oculus Quest, Oculus Go, HTC Vive, Sony Playstation, Samsung GearVR etc. Our bi-annual report that provides nuanced advice around technologies, tools, techniques, platforms and languages, also called the Technology Radar puts a spotlight on Oculus Quest stating,\n “\u0026hellip;changes the game, becoming one of the first consumer mass-market standalone VR headsets that requires no tethering or support outside a smartphone”. Furthermore, Oculus has recently come up with a hand-tracking solution on Oculus Quest which is a great market differentiator for the device.\n Smartphone based VR is an economical choice to experience VR tech. Google Cardboard, and similar variants are quite popular in this segment. All one needs is a smartphone to fit into a virtual box. Media players and media content providers like YouTube have adapted and introduced the capability of consuming content in a 360-degree VR environment.\nMixed Reality MR is a combination of both AR and VR, where the physical world and digital content interact. Users can interact with the content in 3D. Besides, MR devices recognize and remember environments for later, while also keeps track of the device’s specific location within an environment.\neXtended Reality, XR The familiarity with the foundational blocks allows us to move on to the bigger trend that businesses have an opportunity to explore - eXtended Reality. It’s an umbrella term for scenarios where AR, VR, and MR devices interact with peripheral devices such as ambient sensors, actuators, 3D printers and internet enabled smart-devices such as home appliances, industrial connected machines, connected vehicles and more.\nThe term XR is soon becoming common parlance thanks to the synergy of AR, VR and MR tech to create 3D content, and cutting edge development tools and practices. The industry is examining investment opportunities in XR platforms that allow shared services across devices, development platforms and enterprise systems like ERP, CRM, IAM etc.\nFor instance, Lenovo ThinkReality Platform and HoloOne Sphere are providing device independent services, SDK (Software Development Kit) and cloud based central portal, which further integrates with enterprise systems. WebVR, a web browser-based XR experience has also been mentioned in ThoughtWorks Technology Radar,\n “WebVR is an experimental JavaScript API that enables you to access VR devices through your browser. If you are looking to build VR experiences in your browser, then this is a great place to start.”\n Additionally, Immersive Web from Google and WebXR from Mozilla are other prominent examples.\nDevelopment platforms like Unity 3D have gone ahead and crafted cross-device features. This is evident in how Unity AR Foundation supports both platforms - Android devices that use Google ARCore and iOS devices that use ARKit to build AR experiences.\nConclusion An overview of the foundational blocks give us a small insight into the myriad possibilities of how we might interact with the world around us. In Part II of this series on eXtended reality, we will be deep diving into interesting use cases of the tech and explore realities that were only once possible in the movies.\nThis article was originally published on ThoughtWorks Insights and XR Practices Publication\n","id":6,"tag":"xr ; fundamentals ; thoughtworks","title":"eXtending reality with AR and VR - Part 1","type":"post","url":"https://thinkuldeep.github.io/post/extending_reality_with_ar_and_vr-1/"},{"content":"Covid19 has challenged the way we eat, the way we commute, the way we socialize, and the way we work. In short, it impacted the way we live. More than a million people got infected and the number is growing exponentially, it has impacted the whole world. We need to find new ways of life and change our focus and priorities to save nature and humanity. Technology can play a great role in coping with it. eLearning, eCommerce, robots in healthcare and contactless technologies are already helping.\nRemote working is the new normal, it is getting accepted by many industries and institutions beyond IT and consulting firms. Even traditional educational institutions started live classes. My 8-year-old son Lakshya’s new academic session started yesterday, I and my wife joined the orientation session and he met all his classmates over video conferencing, and today onward he will attend his school from home.\nI am part of an XR development team at ThoughtWorks, we develop software for a couple of XR devices. The government of India has to lock-down the whole country to strictly implement social distancing, and we all are working from home now. In this article, I am sharing, how the 100% remote working impacted me and my team and how it has impacted the business continuity.\nDo read the tips of working from home by ThoughtWorkers\n https://medium.com/@leovikrant78/the-positive-side-how-work-from-home-can-improve-quality-of-life-b08ab1f981df https://www.thoughtworks.com/remote-work-playbook https://martinfowler.com/articles/effective-video-calls.html  My Day like This section describes how does my day look like, and how much it is different and how much is the same in comparison to earlier.\nMorning Energiser Workout The day now does not start with a morning walk but an indoor workout session with colleagues. ThoughtWorks, Gurgaon office colleagues have started morning energizer workout session, with a basic workout of stretching and yoga. Earlier, at this time, we used to start getting ourselves prepared for office and kids for school, and some of us may be in the traffic during this period or in the next two hours. Earlier, all the effort need to put into dropping kids at the school bus stop and reach office in time.\nSupport my kid to attend school from home He got a schedule from school to join sessions starting at 9 am.\nHe did a rehearsal with me on video conferencing tool Zoom and now equipped with doing zoom on his own. He is super happy to meet his teachers and students today. He has not seen his friends since the last school session which got completed in first week of March. He got promoted 4th standard. Earlier, I could not support my wife in all such activities after reaching to office. But now, I have some more flexibility and more time to plan things. While she prepares a delicious breakfast, I get my son ready for the school from home.\nTeam Standup and Tech Huddles My team is working from home from different parts of India and distributed across 3 offices in India (Gurgaon, Pune, Coimbatore). There are multiple projects running in this team, and I am shared in a few projects, so attending multiple standups and tech huddles.\nXR Development Standup, with a virtual background :) The day generally starts with standup where we discuss what has been done yesterday, what is the plan for today and if there are any impediments. Then team signup for the task they want to do today, and callout things which they think the team needs to know. Since everyone is working from home, we generally have a full house, no ice-cream meters these days for joining late or stuck in traffic excuses.\nToday many of the team members called out that they are canceling their planned leaves due to Covid19 situations and also looking at the criticality of the work we have signed up. Today we have signed up an interesting piece of work with the client. The team wants to deliver the signed work at all the cost. What a commitment team!\nRemote Pair Development Pair development is very core to ThoughtWorkers, we do things in pairs, and get first-hand feedback immediately and fix things then and there. It helps us producing better quality products and reduce the burden from a single human mind.\nXR development has device dependency, and remote pair development is another challenge, but we have been doing remote pair development from couple of months between team located at Gurgaon and Coimbatore offices, and now we are getting better in remote pair development. Some of my time goes in active development pairing, here is how we solved some of the challenges\n A limited number of devices — Developers use emulators to test the functionality and have written automation functional tests that run on CI environments to further confirm that development build has the right set of functionality. We make sure our QA team is well equipped with real devices to test it further. We follow a concept called “Dev-Box” (aka volleyball test, shoulder check), where a developer pair invites the QA and few team members to check the developed functionality on the developer’s machine before committing the code in the repository. So the developer has a chance to try functionality in real XR device before pushing the code. Showing XR functionality remotely — Some devices support Mixed Reality Capture natively, and some need external tools to stream device experience remotely. We have also build a custom experience streamer to share device experience.  Developers sharing the XR streams on video calls  Integrations with multiple tools and technologies — Since teams are distributed, it is very important to call out dependencies, and we need to make sure we are not doing duplicate work and duplicate spikes to uncover unknowns. We focus on defining contracts first and then share mock implementation to the dependent team to resolve the dependency well early. Some of my time goes into pairing with different technology leads in defining project architecture.  Pairing with UX Designer: User experience is key things in XR development and today some of my time also gone in discussing user experience design for the upcoming product. We discussed, how we can make the design completely hands-free, and the user can control the 3D app just by head movement and gaze. Distance between intractable items and field of view of the device is a big consideration while designing the user experience. I am happy that I am able to share my experience with multiple XR devices with the UX designer of my team.\nDiscussing the concept of the field of view and user interactions on video conferencing was not easy. We figured out an easy way, we created an FoV box with a gaze pointer at the center, then we grouped them, now moving the FoV box also move gaze pointer and it gives similar behavior of how the XR device shows things within FOV.\nPairing with UX designer and business analyst Pairing for Planning and Showcases: Being part of multiple projects, I need to be in sync with project planning and requirements across the projects and I can be helpful for project iteration managers to define dependencies and plan the sprint accordingly. So, some of my time goes into discussing the project plan and planing out the showcases.\n Get buy-in from the client — we have taken buy-in from the client to take the XR devices at home for remote development. Internet availability at home — Every ThoughtWorker got Rs. 5000/- reimbursements to make arrangements at home and can get things like internet routers, inverters, headphones. It helped team members who don’t have good internet speed and prepare for remote work. Trying its best to enable all of us to work from home.  MD Townhall Joined Townhall from MD’s office and Head of Techs — Overview on how Covid19 is impacting us and industries, our plan to cope up with uncertainties, and what new coming up in India, new office spaces, projects, and some less painful actions. We have discussed some interesting social initiates going in ThoughtWorks to support the people of india in this Codiv19 situation. Working from home when kids are around My 2.5 year younger son Lovyansh, has never seen me at home every day, and that too working for the whole day (sometimes night ;). He expects more attention from me after seeing me more. He just wants to press keys on the keypad, and touch the laptop, but I just can’t afford to do that in this situation. He has started controlling his curiosity now, sometimes he is happy just by watching what I am doing. I hope you have noticed matching dress, he is learning colors these days :) Spend good time in completing few spikes on integrating Unity Application on Android native application and interoperability around these technologies.\nIntegrated the client’s enterprise Active Directory with the XR app, that we are building for the client. This is a step toward making the XR devices enterprise-ready.\nSome of the spikes I have done are already published at Enterprise XR\nPick up Grocery and Essentials There are online groceries and essential delivery vendors around my house, but none of them can deliver at home due to Covid19, but they are allowed to deliver in the community center following all the hygiene and Govt protocols. The society staff allows people with masks and sensitized hands to pick the delivery. The community center is 10 mins walk in the same society area. I need to get out of my house for some time, depending on the delivery time. Today it was afternoon.\nEvening Energiser Pune team organizes evening energizer to have fun and stretching, and break together. Energizers are important to stay active and focused, going together on a video call to share/show what is happening around- kids, pets are really connecting us better as a team.\nNew Joiner Induction One XR expert joined our team on 31st March, and it is not the best time to join or leave any organization. But at ThoughtWorks, we have taken this challenge and now the new joiners getting all the joining formality done digitally. ThoughtWorks has planned 100% remote induction, immersion workshops and hands-on dev boot-camp for the new joiners. I am his remote buddy, and we keep in touch remotely.\nEvening meetings The client team is primarily distributed in the US and China. We generally have some evening meetings with the client or with our ThoughtWorkers in other timezones. Earlier, these evening meetings were most problematic for me to attend, as if I accept a meeting at 5:30 pm and try to leave between 6–8 pm then I have to pass through a lot of traffic, in that case I may opt to stay in office till 8 pm, and that means everything (dinner, evening walk, sleep time) get delayed.\nNow working from home has the flexibility to attend evening calls, and even attending a late evening is also fine. So we are now more accessible to other timezones.\nAlso earlier, it was a struggle to schedule a meeting in office hours, as we need to check the availability of meeting rooms for the participants across the offices and book them. Most of the ThoughtWorks offices in India are preparing additional spaces, as existing ones are getting crowded, finding a meeting room is a nightmare until we get more spaces.\nKeep multiple video conferencing software ready on your PC. Different clients and users have different preferences. Get hands-on these tools on sharing screen, content, chat while on a video call.\nBreak Time is Family Time I noticed that kids are just waiting for me to come out of the room, and they always have a lot of things to show, and talk. Each break time is now family time. I keep getting instructions from my wife to drink water and walk after some time :)\nWriting this article And of course, after all of the above, spending some time writing this article. I am planning to do some indoor walk after completing it. This covers my day.\nImpact of Full Remote Working In the last section, I have explained how does my day look like, it is not much different than my day in office, and it is also not the same as my day in office. Let’s now see, how does full remote working or work from home has impacted us, the projects, the businesses, and the organization. This is applicable to non-XR projects as well.\nSocial Connect Social distancing is a must to protect ourselves and others from Covid19 infections. As a result, social connect is reducing, and we do miss office working hours and the energetic office environment. We are trying to fill it with virtual meetings, but it has its own pros and cons. Global connect is improving though.\nFamily Connect Family connect is improving, and we have more time for family, and also more time to work.\nAgility Now we have more flexible hours than earlier. The hours we spend preparing to go office and reach office are now added flexible hours which can plan to keep our priority in mind. We now have more control on time, we can plan our meetings in extended hours, and spend quality time with family as well. We are becoming location independent and distributed agile practices are growing naturally. Global-first is coming naturally at org level.\nBusiness Continuity Before going to 100% work from home, we have rehearsed it for couple of days, and we have measured that there is almost no impact on the business deliveries. Now we are 100% working from home, and we have been delivering on all the commitments on time. There is almost no reduction in productive hours and people have also canceled planned leaves, which adds effective productive hours.\nOrganization At the organization level, there needs to be multiple initiates to be planned in addition to move operations, people support and people enablement remotely. The future will soon be here with teleportation meetings, where we can be ported virtually to other locations.\n New security policies may be required The idea of having big office space may not be the future The location-independent global first organization New leave policies Meeting infra for virtual meetings Remote working charter Cost optimizations Measures to face another economic slowdown. Ops 10:30 pm, probably update this section later.  Conclusion Covid19 has impacted the world from all the side and forced us to work from home. We are observing a lot of positive sides of working from home without any major impact on business commitments. We hope we will rid of covid19 soon and wish speedy recovery of the ecosystem.\nIt is originally published at XR Practices Medium Publication\n","id":7,"tag":"xr ; work from home ; covid19 ; thoughtworks ; pair-programming ; xp ; agile","title":"XR development from home","type":"post","url":"https://thinkuldeep.github.io/post/xr-development-from-home/"},{"content":"In the previous article, we discussed implementing multi-factor authentication for an andorid application, and in the article we will cover another enterprise aspect, Interoperability.\nInteroperability is key aspect when we build enterprise solutions using XR technologies. The enterprises have digital assets in form of mobile apps, libraries, system APIs, and they can’t just throw away these existing investments, in fact, the XR apps must be implemented in such a way that it is interoperable with them seamlessly. This article describes interoperability between XR apps and other native apps. It takes Unity as the XR app development platform and explains how a Unity-based app can be interoperable with the existing Java-based android libraries.\nRead the below article by Raju Kandaswamy, it describes steps to integrate the XR app built using Unity into any android app.\n Embedding Unity App inside Native Android application While unity provides android build out of the box, there are scenarios where we would like to do a part unity and part… medium.com\n The article below describes interoperability in the opposite of what Raju has described, we will try to integrate an existing Android Library into the Unity-based XR App.\nBuild an Android Library In the last article, we have implemented a user authenticator. Let’s now expose a simple user authenticator implementation as an android library.\n  goto File \u0026gt; New \u0026gt; New Module \u0026gt; Select Android Library   Implement a UserAuthenticator with simple authentication logic. Each method is accepting an argument context, but currently, it is not being used so you may ignore it for now.\n  public class UserAuthenticator { private static UserAuthenticator instance = new UserAuthenticator(); private String loggedInUserName; private UserAuthenticator(){ } public static UserAuthenticator getInstance(){ return instance; } public String login(String name, Context context){ if(loggedInUserName == null || loggedInUserName.isEmpty()){ loggedInUserName = name; return name + \u0026#34; Logged-In successfully \u0026#34;; } return \u0026#34;A user is already logged in\u0026#34;; } public String logout(Context context){ if(loggedInUserName != null \u0026amp;\u0026amp; !loggedInUserName.isEmpty()){ loggedInUserName = \u0026#34;\u0026#34;; return \u0026#34;Logged-Out successfully \u0026#34;; } return \u0026#34;No user is logged in!\u0026#34;; } public String getLoggedInUser(Context context){ return loggedInUserName; } }  Go to Build \u0026gt; Make Module “userauthenticator” — It will generate aar file. under build/outputs/aar   This is the library that can be integrated with Unity in C#. The next section describes how it can be used in Unity.\nBuild an XR app in Unity Let’s now build the XR app in unity to access the API exposed by the android library implemented in the last step. Unity refers to the external libraries as a plugin.\n  Create unity project   We have 3 APIs in UserAuthenticator of the android library, let\u0026rsquo;s build a 3D UI layout with buttons, text elements. as follows. The source code is shared at the end of the article.   Add a script ButtonController. This script describes the ways to access java classes.\n `UnityEngine.AndroidJavaClass` - Load a given class in Unity, using reflection we may invoke any static method of the class. `UnityEngine.AndroidJavaObject` - Keep the java object and automatically dispose of it once it's done. Using reflection we can invoke any method of the object.    public class ButtonController : MonoBehaviour { private AndroidJavaObject _userAuthenticator; [SerializeField] private InputField inputFieldUserName; [SerializeField] private Button loginButton; [SerializeField] private Text loginResponse; [SerializeField] private Button logoutButton; [SerializeField] private Text logoutResponse; [SerializeField] private Button getLoggedInUserButton; [SerializeField] private Text getLoggerInUserResponse; void Start() { AndroidJavaClass userAuthenticatorClass = new AndroidJavaClass(\u0026#34;com.tw.userauthenticator.UserAuthenticator\u0026#34;); _userAuthenticator = userAuthenticatorClass.CallStatic\u0026lt;AndroidJavaObject\u0026gt;(\u0026#34;getInstance\u0026#34;); loginButton.onClick.AddListener(OnLoginClicked); logoutButton.onClick.AddListener(OnLogoutClicked); getLoggedInUserButton.onClick.AddListener( OnGetLoggedUserClicked); } private void OnLoginClicked() { loginResponse.text = _userAuthenticator.Call\u0026lt;string\u0026gt;(\u0026#34;login\u0026#34;, inputFieldUserName.text, getUnityContext()); } private void OnLogoutClicked() { logoutResponse.text = _userAuthenticator.Call\u0026lt;string\u0026gt;(\u0026#34;logout\u0026#34;, getUnityContext()); } private void OnGetLoggedUserClicked() { getLoggerInUserResponse.text = _userAuthenticator.Call\u0026lt;string\u0026gt;(\u0026#34;getLoggedInUser\u0026#34;, getUnityContext()); } private AndroidJavaObject getUnityContext() { AndroidJavaClass unityClass = new AndroidJavaClass(\u0026#34;com.unity3d.player.UnityPlayer\u0026#34;); AndroidJavaObject unityActivity = unityClass.GetStatic\u0026lt;AndroidJavaObject\u0026gt;(\u0026#34;currentActivity\u0026#34;); return unityActivity; } }   Attached the ButtonController script to an empty game object. Link all the buttons, texts, and input field components.   Copy the android library in /Assets/Plugins/Android folder.   Switch to Android as a Platform if not already done. — Go to File \u0026gt; Build Settings \u0026gt; Select Android as a Platform \u0026gt; Click of Switch Platform.\n  Update the player settings — Go to File \u0026gt; Build Settings \u0026gt; Player Settings correct the package name and min API level in “Other Settings”\n  Connect your android device, and click on Build and Run. or export the project and test it in Android studio.\n  Here is a demo. Type in the user name, and click on login, it will call the Android API from the library and show the value returned by the library in the text next to the button.\nSave way button works, test the logic you have written in the library. \nWith this, we are done with basic integration. The next section describes an approach with callback methods.\nIntegration using Callbacks. Callbacks are important, as the android system may not be always running result synchronously, there are multiple event and listeners which works on callbacks.\n Let’s implement a callback interface in the android library.  public interface IResponseCallBack { void OnSuccess(String result); void OnFailure(String erorrmessage); }  Update the UserAuthenticator implementation to call the OnSuccess and OnFailure Callbacks.  public class UserAuthenticator { ... public void login(String name, IResponseCallBack callBack, Context context){ if(loggedInUserName == null || loggedInUserName.isEmpty()){ loggedInUserName = name; callBack.OnSuccess (loggedInUserName + \u0026#34; Logged-In successfully \u0026#34;); } else { callBack.OnFailure(\u0026#34;A user is already logged in\u0026#34;); } } public void logout(IResponseCallBack callBack, Context context){ if(loggedInUserName != null \u0026amp;\u0026amp; !loggedInUserName.isEmpty()){ loggedInUserName = \u0026#34;\u0026#34;; callBack.OnSuccess (\u0026#34;Logged-Out successfully \u0026#34;); } else { callBack.OnFailure(\u0026#34;No user is logged in!\u0026#34;); } } ... }  Build the Android library again and replace it in Unity project Assets/Plugins/Android Update corresponding in ButtonController of Unity. Implement the Java interface using UnityEngine.AndroidJavaProxy.  private AuthResponseCallback _loginCallback; private AuthResponseCallback _logoutCallback; void Start() { ... _loginCallback = new AuthResponseCallback(loginResponse); _logoutCallback = new AuthResponseCallback(logoutResponse); } private class AuthResponseCallback : AndroidJavaProxy { private Text _reponseText; public AuthResponseCallback(Text _reponseText) : base(\u0026#34;com.tw.userauthenticator.IResponseCallBack\u0026#34;) { } void OnSuccess(string result) { _reponseText.text = result; _reponseText.color = Color.black; } void OnFailure(string errorMessage) { _reponseText.text = errorMessage; _reponseText.color = Color.red; } } private void OnLoginClicked() { _userAuthenticator.Call(\u0026#34;login\u0026#34;, _loginCallback, inputFieldUserName.text, getUnityContext()); } private void OnLogoutClicked() { _userAuthenticator.Call(\u0026#34;logout\u0026#34;, _logoutCallback, getUnityContext()); } here is the demo to show the failure response in red color.\nThe response callback implementation sets the color in the text fields.\nCode Branch till this point is added here — Android Library, Unity App\n\nIn the next section, we will discuss more complex integration with native components and intents.\nSingle Sign-On Integration using device native WebView In this section, we will integrate the android\u0026rsquo;s web view with the unity app, and also see invocation using Intents.\nRefactor Android Library Let’s refactor the android app we have implemented the last article, and use it as a library. Also, learn to pass the arguments to Intent and gets the response from it.\n Wrap the WebView invocation in an activity — It takes URL, returnURI as input. It intercepts the returnURI and parse the “code” from it and returns in a ResultReceiver callback.  public class WebViewActivity extends AppCompatActivity { ... @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); final String interceptScheme = getIntent().getStringExtra(INTENT_INPUT_INTERCEPT_SCHEME); final String url = getIntent().getStringExtra(INTENT_INPUT_URL); webView = new WebView(this); webView.setWebViewClient(new WebViewClient() { public boolean shouldOverrideUrlLoading(WebView view, String url) { Uri uri = Uri.parse(url); if (interceptScheme !=null \u0026amp;\u0026amp; interceptScheme.equalsIgnoreCase(uri.getScheme() +\u0026#34;://\u0026#34; +uri.getHost())) { String code = uri.getQueryParameter(\u0026#34;code\u0026#34;); ResultReceiver resultReceiver = getIntent().getParcelableExtra(INTENT_RESPONSE_CALLBACK); if(resultReceiver!=null) { Bundle bundle = new Bundle(); bundle.putString(\u0026#34;code\u0026#34;, code); resultReceiver.send(INTENT_RESULT_CODE, bundle); } finish(); return true; } view.loadUrl(url); return true; } }); WebSettings settings = webView.getSettings(); settings.setJavaScriptEnabled(true); setContentView(webView); webView.loadUrl(url); } ... }  User Authenticators Login method invokes the web-view activity with an SSO URL, and callback.  public void login(IResponseCallBack callBack, Context context){ Log.d(\u0026#34;@@UserAuthenticator\u0026#34;, \u0026#34;Login called\u0026#34;); if(accessToken == null || accessToken.isEmpty()){ Intent intent = new Intent(context, WebViewActivity.class); intent.putExtra(WebViewActivity.INTENT_INPUT_INTERCEPT_SCHEME, HttpAuth.REDIRECT_URI); intent.putExtra(WebViewActivity.INTENT_INPUT_URL, HttpAuth.AD_AUTH_URL); intent.putExtra(WebViewActivity.INTENT_RESPONSE_CALLBACK, new CustomReceiver(callBack)); context.startActivity(intent); } else { callBack.OnFailure(\u0026#34;A user is already signed in\u0026#34;); } }  CustomReceiver.OnReceivedResult gets an access_token using the code returned by the web-view activity. access_token is then saved in the UserAuthenticator.  public class CustomReceiver extends ResultReceiver{ private IResponseCallBack callBack; CustomReceiver(IResponseCallBack responseCallBack){ super(null); callBack = responseCallBack; } @Override protected void onReceiveResult(int resultCode, Bundle resultData) { if(WebViewActivity.INTENT_RESULT_CODE == resultCode){ String code = resultData.getString(WebViewActivity.INTENT_RESULT_PARAM_NAME); AsyncTask\u0026lt;String, Void, String\u0026gt; getToken = new GetTokenAsyncTask(callBack); getToken.execute(code); } else { callBack.OnFailure(\u0026#34;Not a valid code\u0026#34;); } } }  The access_token is used in getting the user name from the Azure Graph API. This completes the refactoring. The source code is attached at the end.  public void getLoggedInUser(IResponseCallBack callBack){ if(loggedInUserName == null || loggedInUserName.isEmpty()){ if(accessToken != null \u0026amp;\u0026amp; !accessToken.isEmpty()){ try { new GetProfileAsyncTask(callBack).execute(accessToken).get(); } catch (Exception e) { callBack.OnFailure(\u0026#34;Failure:\u0026#34; + e.getMessage()); } } else { callBack.OnFailure(\u0026#34;No active user!\u0026#34;); } } else { callBack.OnSuccess(loggedInUserName); } } All the HTTP communications are wrapped in a utility class HttpAuth, this completes the refactoring of the android library. Since we have added a new activity don’t forget to add it in the android manifest.\nUnity App Invoking Native WebView in Android Libary This example is now doing SSO with the organization’s active directory (AD), the username and password will be accepted at the organization’s AD page.\n  Let’s change the layout a bit. We don’t need an input field now.   There is no major change in ButtonContoller, expect the signature change for the library APIs. Now android handles the intent in a separate thread, and callback in unity may not access the game object elements as they may be disabled when another activity spawned on. Status of unity element may be checked in the main thread. The callbacks now updating few helper variables and the update method updates the unity elements in main there whenever there is any change in the state.\n  private void Update() { loginResponse.text = labels[login]; loginResponse.color = colors[login]; logoutResponse.text = labels[logout]; logoutResponse.color = colors[logout]; getLoggerInUserResponse.text = labels[getuser]; getLoggerInUserResponse.color = colors[getuser]; } private class AuthResponseCallback : AndroidJavaProxy { private int index; public AuthResponseCallback(int index) : base(\u0026#34;com.tw.userauthenticator.IResponseCallBack\u0026#34;) { this.index = index; } void OnSuccess(string result) { labels[index] = result; colors[index] = Color.black; } void OnFailure(string errorMessage) { labels[index] = errorMessage; colors[index] = Color.red; } }  Since the Android library now have an Activity, and it requires a dependency “androidx.appcompat:appcompat:1.1.0” in Gradle build. We need to use a custom Gradle template in Unity, Go to File \u0026gt; Build Settings \u0026gt; Player Settings \u0026gt; Publishing Settings. Choose Custom Gradle Template. It will generate a template file in Plugins. Add the following dependency in the Gradle template. Make sure don’t change **DEPS** Build/Export the project and run on Android. You have completed the native integration. Here is a demo of integrated SSO in Unity. Logs :  @@@@TAG: shouldOverrideUrlLoading https://login.microsoftonline.com/c... D/@@@@TAG: shouldOverrideUrlLoading xrapp://auth-response/?code=OAQABAAIAAAAm- ... D/@@@@TAG: sent response: -\u0026gt; OAQABAAIAAAAm-06blBE1TpVMil8KPQ41w8xt2ZjP8RCWskix73dMwtoNalVsN2KdR5mm4bnq D/@@UserAuthenticator: doInBackgroud: access_token=eyJ0eXAiOiJKV1QiLCJub25jZSI6Imo1ZWRrRF9lM0dUU3VBe \nSource code can be found at following git repo — Android Library, Unity App\nConclusion This article describes the basics of interoperability between XR apps and android native libraries. In the next article, we will how to share the user context across XR apps.\nThis article was original published on XR Practices Publication\n","id":8,"tag":"xr ; integration ; enterprise ; android ; unity ; tutorial","title":"Enterprise XR - Interoperability","type":"post","url":"https://thinkuldeep.github.io/post/enterprise-xr-interoperability/"},{"content":"XR use cases are growing with advancements in the devices, internet and development technologies. There is an ever-growing demand to build enterprise use cases using ARVR technology. Most enterprise use cases eventually require integration with an enterprise ecosystem such as IAM (Identity and Access Management), ERP, CRM, and single sign-on with other systems.\nMost organizations protect digital assets with a single sign-on using Multiple Factor Authentication (MFA). The MFA is generally a web-browser based authentication where the browser redirects to tenant’s authentication page where the user provides their credentials and then the user confirms another factor (PIN, OTP, SMS or mobile notifications), once it succeeds, it gets redirected back to the protected resource. The users generally trust the organization’s AD page to provide credentials. So it is important to include this web-based flow in the XR app development.\nThis series of posts covers end to end flow for building XR application integrated with the organization\u0026rsquo;s web-based authentication flow.\nSetup Active Directory This section describes the AD setup on Microsoft Azure. A similar setup is available on other active directories. Here are the steps you need to follow to configure AD for a mobile app.\n Open Azure Portal with valid credentials, please signup if you don’t have that, https://portal.azure.com (currently there is 28 days free subscription to try out, go and “Add subscription” choose Free Trial)  Search for Azure Active Directory  Go to App Registration \u0026gt; New Registration — Fill in the details for a new app.  Note down the client id and other parameters.   Ref [4] in references for more details.\nBuild an Android App integrated with Organization AD There are multiple ways to integrate and build an android app that can communicate with an organization’s AD for authentication. There are proprietary libraries (from Google, Microsoft, Facebook etc.) that can be included in the project and you can directly communicate with respective AD, but it is helpful when Basic Authentication is enabled. Below steps cover OAuth 2 type MFA and web-browser based flow for authentication, it doesn\u0026rsquo;t require any specific library dependency.\nAndroid Project Setup Build your first app if you haven\u0026rsquo;t build any yet — https://developer.android.com/training/basics/firstapp Understand the MainActivity and Android Manifest file.\nOpen Web View In Android App Open authorization URL in a web-view. For the above Azure AD configuration following is the authorization URL. Ref [1]\nhttps://login.microsoftonline.com/common/oauth2/v2.0/authorize?client_id=86501f6d-0498-40ab-b3c9-81ab8ffef1ac\u0026amp;scope=openid\u0026amp;response_type=code  Refer to the code below to open a web-view at the start of the main-activity.\npublic class MainActivity extends AppCompatActivity { private static final String TAG = \u0026#34;MainActivity\u0026#34;; //xrapp://auth-response  private final String REDIRECT_URL_SCHEME = \u0026#34;xrapp\u0026#34;; private final String REDIRECT_URL_HOST = \u0026#34;auth-response\u0026#34;; private final String AD_AUTH_URL = \u0026#34;https://login.microsoftonline.com/common/oauth2/v2.0/authorize?client_id=86501f6d-0498-40ab-b3c9-81ab8ffef1ac\u0026amp;scope=openid\u0026amp;response_type=code\u0026#34;; private WebView myWebView; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); myWebView = new WebView(this); myWebView.setLayoutParams(new ViewGroup.LayoutParams(ViewGroup.LayoutParams.MATCH_PARENT, ViewGroup.LayoutParams.FILL_PARENT)); WebSettings settings = myWebView.getSettings(); settings.setJavaScriptEnabled(true); settings.setDomStorageEnabled(true); getWindow().requestFeature(Window.FEATURE_NO_TITLE); getWindow().setFlags(WindowManager.LayoutParams.FLAG_FULLSCREEN, WindowManager.LayoutParams.FLAG_FULLSCREEN); setContentView(myWebView); myWebView.loadUrl(AD_AUTH_URL); } } The android-manifest looks like this. Make sure you have the Internet permission\n\u0026lt;manifest xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; package=\u0026#34;com.tw.userauthenticator\u0026#34;\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.INTERNET\u0026#34; /\u0026gt; \u0026lt;application android:allowBackup=\u0026#34;true\u0026#34; android:icon=\u0026#34;@mipmap/ic_launcher\u0026#34; android:label=\u0026#34;@string/app_name\u0026#34; android:roundIcon=\u0026#34;@mipmap/ic_launcher_round\u0026#34; android:supportsRtl=\u0026#34;true\u0026#34; android:theme=\u0026#34;@style/AppTheme\u0026#34;\u0026gt; \u0026lt;activity android:name=\u0026#34;.MainActivity\u0026#34;\u0026gt; \u0026lt;intent-filter\u0026gt; \u0026lt;action android:name=\u0026#34;android.intent.action.MAIN\u0026#34; /\u0026gt; \u0026lt;category android:name=\u0026#34;android.intent.category.LAUNCHER\u0026#34; /\u0026gt; \u0026lt;/intent-filter\u0026gt; \u0026lt;/activity\u0026gt; \u0026lt;/application\u0026gt; \u0026lt;/manifest\u0026gt; Demo here - Intercept the Redirect URL While configuring AD, we have provided a redirect URL — xrapp://auth-response. Clicking on “Continue” in the last step will redirect to “xrapp://auth-response?code=\u0026lt;value of code\u0026gt;”\nThe android app needs to intercept this URL to read code parameter from it. Following code checks for any URL loading and see if any URL starts with xrapp://auth-response and then fetch code from it.\n... myWebView = new WebView(this); myWebView.setWebViewClient(new WebViewClient() { public boolean shouldOverrideUrlLoading(WebView view, String url) { Uri uri = Uri.parse(url); if (REDIRECT_URL_SCHEME.equalsIgnoreCase(uri.getScheme()) \u0026amp;\u0026amp; REDIRECT_URL_HOST.equalsIgnoreCase(uri.getHost())) { String code = uri.getQueryParameter(\u0026#34;code\u0026#34;); Log.e(TAG, \u0026#34;shouldOverrideUrlLoading: -\u0026gt; \u0026#34; + code); return true; } view.loadUrl(url); return true; } }); ... Fetch the access token In the last step, we read the authorization code, lets now fetch an access-token from AD. Here is the URL to fetch the token for above AD setup https://login.microsoftonline.com/common/oauth2/v2.0/token Ref[2]\nAdd an Async Task to fetch a token once the Authentication code is fetched.\n... Log.e(TAG, \u0026#34;shouldOverrideUrlLoading: -\u0026gt; \u0026#34; + code); AsyncTask\u0026lt;String, Void, String\u0026gt; getToken = new GetTokenAsyncTask(); getToken.execute(code); return true; ... Here is the GetTokenAsyncTask\nprivate class GetTokenAsyncTask extends AsyncTask\u0026lt;String, Void, String\u0026gt; { @Override protected String doInBackground(String... strings) { String code = strings[0]; HashMap\u0026lt;String, String\u0026gt; postParams = new HashMap\u0026lt;\u0026gt;(); postParams.put(\u0026#34;client_id\u0026#34;, CLIENT_ID); postParams.put(\u0026#34;grant_type\u0026#34;, \u0026#34;authorization_code\u0026#34;); postParams.put(\u0026#34;code\u0026#34;, code); return performPostCall(AD_TOKEN_URL, postParams); } protected void onPostExecute(String response) { super.onPostExecute(response); String access_token = getValueFromJSONString(response, \u0026#34;access_token\u0026#34;); finish(); } } Fetch the User Profile Using the Access token Once the access token is fetched, get the user profile data. Microsoft has graph APIs to fetch the profile data Ref [3] eg. https://graph.microsoft.com/beta/me/profile/ It would return whole JSON data for the profile.\n... String access_token = getValueFromJSONString(response, \u0026#34;access_token\u0026#34;); result = new GetProfileAsyncTask().execute(access_token).get(); ... The GetProfileAsyncTask fetches the profile data in the background.\nprivate class GetProfileAsyncTask extends AsyncTask\u0026lt;String, Void, String\u0026gt; { @Override protected String doInBackground(String... strings) { String access_token = strings[0]; Log.d(TAG, \u0026#34;doInBackgroud: access_token=\u0026#34; + access_token); return performGetCall(GET_PROFILE_URL, access_token); } } Show the Username from the profile Let\u0026rsquo;s show the user name from the profile data. For this, we may create another intent to display the text and call the intent after getting the user name from the response. Don’t forget to add intent in the android manifest file.\n... result = new GetProfileAsyncTask().execute(access_token).get(); String displayName = getValueFromJSONString(result, \u0026#34;displayName\u0026#34;); displayName = \u0026#34;Welcome \u0026#34; + displayName + \u0026#34;!\u0026#34;; Intent intent = new Intent(MainActivity.this, DisplayResponseActivity.class); intent.putExtra(\u0026#34;response\u0026#34;, displayName); startActivity(intent); finish(); ... \nConclusion This article describes the end to end steps to configure an app on Active Directory and build an integrated android app without any proprietary dependencies. In the next few articles, we will discuss how to handle interoperability and build integrate ARVR app. Next \u0026raquo; Enterprise XR — Interoperability Source code can be found at https://github.com/thinkuldeep/xr-user-authentication/tree/part1\nThis article was original published on XR Practices Publication\nReferences :  Oauth2 Authorization EndPoint OAuth2 Token End Point Using Microsoft Graph APIs https://docs.microsoft.com/en-us/azure/app-service/configure-authentication-provider-aad#register  ","id":9,"tag":"xr ; cloud ; integration ; enterprise ; android ; mfa ; tutorial","title":"Enterprise XR - Multi-Factor Authentication","type":"post","url":"https://thinkuldeep.github.io/post/enterprise-xr-multi-factor-authentication/"},{"content":"The XR Day Organized XR Days at ThoughtWorks, India in different cities and conducted awareness sessions and ideation workshop and more..\nThe talks are about  How the User interactions evolved with time? Why is it important to think beyond the tradition keyboard and screen? Where is the industry heading? How will it impact us?  Detailed Slides   Think beyond keyboard and screen xr day 2019  from Kuldeep Singh  Event Summary It was well recevied the participats. Here is the event Summary\nCoimbatore Pune ","id":10,"tag":"xr ; ar ; vr ; mr ; fundamentals ; thoughtworks ; event","title":"XR Day - ThoughtWorks India","type":"talk","url":"https://thinkuldeep.github.io/talk/thougthworks_xrday/"},{"content":"Everyone in India is talking about Jeff Bezos, the richest of the world, who was on India\u0026rsquo;s visit recently. People are talking about the investments he is making in India, talking about his prediction about India\u0026rsquo;s \u0026ldquo;21st Century is going to be the Indian century\u0026rdquo;, and discussing the impact on small businesses. We have seen disruptions lead by Amazon in multiple sectors, now people have a fear that whatever Amazon touch, it becomes Amazon\u0026rsquo;s. This fear may be true, as Amazon always stays ahead of the curve. How could Amazon always be true? what makes Amazon or Jeff Bezos? What is the success mantra of the company like Amazon?\nThe book \u0026ldquo;Success Secrets of Amazon by Steve Anderson\u0026rdquo; talks about 14 principles that lead to amazon\u0026rsquo;s success. Not all the steps Amazon takes are successful or infact Amazon doesn\u0026rsquo;t take a step but takes a journey, which means continuous effort to make the way ahead.\nHere are my top 5 takeaways from the book:\nReturn on Risk (RoR) Evaluate RoR instead of RoI, invest on Risks. The process of evaluating return on a risk improves the risk-taking capability, which is a key factor of the success of a company like Amazon.\nNot doing a thing is equality riskier than the risk of doing that. So it is always better to act and know if that works.\nExperiment more and celebrate the failure Celebrate your failures and come out of them, make them the successful failure. Failure is the bigger teacher of life, learn from them. Plan for the failures, and make the mindset shift. Amazon\u0026rsquo;s failed in the first place ideas like Amazon Auctions as eBay competitor, zShops and Fire Phone but all these failures turned into a business of billions of $ now - amazon shopping, Alexa and more.\nBet small but on the big idea, and follow closely and progressively. Free shipping, AWS, and Kindle are examples of the same. They started small but with a big aim in mind.\nDon\u0026rsquo;t afraid of failures, but focus on making them successful failures. Have a dedicated investment in experimentation, and indulge it part of the culture.\nSpeed up decision making by decentralizing the authority especially for the decisions which can be changed or reversed. It is worth trying them instead of delaying them for multi-layer approvals, and if they don\u0026rsquo;t work then also you have learned from it. Trust your guts and keep trying.\nMove from customer-focused to customer-obsessed business Amazon is not a customer-focused business but it is actually a customer-obsessed business. Understand your customer well, and stay ahead of what they need. Use technology to solve traditional barriers/ways of working, and improve efficiency and effectiveness. Reach beyond the expected.\nThink long-term and own the future To stay ahead of the curve, one needs to think in the long-term and build the businesses for future stakeholders. Align your short-term goals with the long-term plan. People will connect with your long-term goal if you promote ownership with them. Promote ownership as a culture, sharing the long-term benefits with people, make them decision owners, let them be open and collaborative, after all, they are the future business owners.\nSet the bar high Save your belief and organization culture, no matter what, keep the high standards and don\u0026rsquo;t dilute the culture on the name of the scale. Organic growth is not always viable, thus we need to go and include people from outside, so hire best or develop the best. Measure what make sense, financial data is not only the measurement of success.\nConclusion Here I talked about my top 5 takeaway from Amazon\u0026rsquo;s success stories. Read out the book, letters of Bezos to understand more about the success mantra of Amazon.\nIt is was originally published at My Linked Profile\n","id":11,"tag":"general ; selfhelp ; success ; book-review ; takeaways","title":"Success Mantra","type":"post","url":"https://thinkuldeep.github.io/post/success_mantra_amazon/"},{"content":"Travel and transportation have faced and continue facing disruptions. Many of the traditional ways are no more in the choice. Earlier our parents used to warn us for taking rides with strangers, but now Uber/Ola/Lyft/Didi, etc are the preferred ways. Owning a car may be an absurd idea now. We are now dreaming of Autonomous vehicles, Flying Cars, Hyperloop, and Space travel in the near future. Do read, how the user interactions have been evolved with time in my earlier post.\nFaster travel vs transportation without travel Disruption from faster travel is not the only thing, but what if we don’t need to travel at all, instead a virtual model of us get ported at the destination and serves the purpose of travel. Possibilities of virtual model transportation are not too far, Ref: Microsoft Holoportation, Ref: Teleportation Conferences, so the travel industries will not just get disrupted by faster, convenient and eco-friendly mode of travel but also by the No-Travel or Virtual Travel mode. It will just be like what (electronic/mobile)-shopping did to the window-shopping. However, window-shopping still co-exists, and a lot of investment is being done into the user experience and solutions which makes a smoother transition across e/m/w-shopping. In this post, we will discuss some ARVR use-cases for the travel and transportation industry which may exist in the coming future as disruptors or enablers. but before that let’s take a look at the tools available in this space.\nTools for Extending the Reality: Heads Up Display (HUD) It extended information in front of the drivers/workers as per the context, so that they can make quick decisions and stay aware of the situations. Other vehicle sensors (GPS, Camera, Speed, IMU) helps in building the context environment. HUD is there in the industry for long, and due to its presence and it has the potential to augment more information. HUD — Photo Credit: Amazon.in\nHead-Mounted Displays and Smart Glasses Smart glasses and head-mounted displays can help the workers while their hands are busy performing the job. Smart glasses by Google Glass, Vuzix, Epson, and etc are good for displaying multimedia information right in front of the user’s eye, however, Head Mounted Devices like Microsoft Hololens, Magic Leap and Lenovo ThinkReality A6 are more capable devices and they detect and interact with the environment and provide the immersive experience to the users. Normal looking glasses are being built, and soon we have smart glasses in the normal form factor. Photo Credit: https://www.lenovo.com/ww/en/solutions/thinkreality\nVR Headsets Virtual reality headset creates a virtual environment and provides an immersive experience to the end-users in that environment. It could be a training environment, product demonstrations or a simulation of a real environment.\nAR Capable Smartphone A smartphone will still play a key role in the industry due to its omnipresence, AR applications on phones are the cheapest and easiest way to adapt the extended reality use cases. The applications built on WebXR are also well demonstratable on the phone.\nLook at the more tools such as connected wearables, holographic projections in the attached slides.\n  Think beyond keyboard and screen - dev fest 2019   Use-cases using Extended Reality Tech Entertainment — Make Journey not Destination Currently, most of the travel businesses are focusing on reaching a destination faster and efficient but looking at the future disruptions, the focus would shift towards making the journey interesting.\nA lot of data is collected and used while a vehicle is moving from pickup to drop locations, this data can be used in making the journey interesting with\nARVR technology, sharable cloud AR anchors may be tagged with GPS and can be augmented in the environment when the user watching using the AR-enabled devices. Based on positioning anchors multiple users may also collaborate and participate in social AR networks, where user-specified AR anchors may be managed. So businesses around AR anchors storage would have great potential in the future, it can be monetized with ads etc. PC: https://www.vrnerds.de/google-i-o-2018-cloud-anchors-und-ar-maps/\nFM radio or Video Streaming of a favorite web series will not be the only options\nThe future vehicles may be seen as an embedded VR studio, where travel from your home to the airport may be experienced as a journey of a theme park, or a journey by helicopter, a journey on mars or any journey you may think of. One of the concepts is as Holoride PC: Holoride\nLocate and Map We are talking about self-driving cars and autonomous vehicles, which uses techniques like Simultaneous Localization and Mapping(SLAM) to build the virtual map and locate objects in the environment. A moving vehicle also generates and consumes a lot of data, which can be augmented on the environment just like ARMaps from Google, a virtual positioning system on GPS.\nThe ARMaps can be used for various use-cases for AR localization — Exactly locate the passenger(driver app), plan/auto adjust the routes, locate my car in AR (passenger app), etc. In the ride-sharing platform such as Uber, it is not always easy to find your car in a crowded space, it would be great if we have a feature where we can see our car highlighted in an augmented way, and also driver sees the passenger highlighted (may bigger than usual). PC: https://www.businessinsider.in/tech\nThis can be extended when a passenger is given an option to experience the car, where (s)he can see the 3D model and information of the car \u0026amp; the driver, and even they can try the car by getting inside the car in ARVR before it comes to pick up.\nMore and more AR services for map and location can be built, when we integrate it with other data. Eg. find nearest charging stations, service stations, fuel stations, etc and visualize them on Visual Positioning System.\nAugmented Safety Notifications Using the ARVR tech, we may locate/augment information for signboards, directions, and the way finders, also instruct the users, drivers, and passengers about the safety on their AR-enabled devices such as HUDs on car, or smart glasses. Drivers can see red lights and traffic situations in the HUDs.\nWith advanced Computer Visions and AI/ML techniques, the user may be instructed about potential emergency situations ahead based on the speed, temperature, weather, location, traffic, battery status, etc.\nSee what Nissan unveiled — I2V (Invisible to Visible), uncovering the blind spaces and making the drive safer and smoother.\n Nissan unveils Invisible-to-Visible technology concept at CES YOKOHAMA, Japan - At the upcoming CES trade show, Nissan will unveil its future vision for a vehicle that helps drivers… global.nissannews.com\n Service and Maintenance There are some great uses of ARVR in service and maintenance assistance especially when the worker’s hands are occupied and he/she needs assistance. The travel and transportation industry may also use the technology for the below use cases.\nA stepwise task workflow could be implemented from task assignment to task completion, where a worker gets a task to perform in the Headset with detailed steps in form of text, audio, video, animations or augmented anchors/markers on the real-world objects. It not only guides the worker right in the working context but also may record the worker’s progress. Task completion can be plugged with proof of completion in the form of a checklist and a snapshot. It improves both efficiencies as well as the accuracy of the process. PC: https://sdtimes.com/softwaredev/the-reality-of-augmented-reality/\nIf they still need assistance, they may get remote assistance from the experts and share what they see with the expert (via front camera feed). Experts can assist the worker with voice, and also can draw/annotate on the environment of the worker. A worker may browse detailed annotated augmented manuals right in front of their eyes by scanning the objects/codes or by talking to the devices.\n Hyundai makes owner\u0026rsquo;s manuals more interesting with augmented reality Augmented reality showrooms are one thing, but Hyundai using that tech to make learning about your new car more… www.engadget.com\n  Augmented manuals may provide internals details of the object without getting inside, and may also guide about the possible defects and anomalies just looking at the objects.\nProduct demonstrations and Setup may also utilize the technology at scale. watch the Hyundai\u0026rsquo;s an AR sales tool, demonstrating the features.\nSimulation-based training - Driver training to handle different driving situations in a simulated VR environment may improve safety and efficiency.\nVR Control Centers Control centers gather a lot of data from the fleet they operate, they need to visualize the data in multiple forms to get different aspects of the situations. There are multiple people with different roles interested in different types of data. Multi-View Virtual Desktops — A VR data visualizer could be a great help to create virtual views based on the dynamic need at the control center, with the need for extra hardware. It would help is in taking decisions faster and get more clarity about the situation.\nPrivate Desktop — Virtual visualizer also addresses privacy concerns, as the data is visible only to the user who is wearing the headset.\nConclusion This post covers the use-cases of Extended Reality in the Travel and transportation industry. XR (AR-VR-MR) will be one of the key disruptors as well as enablers for the future businesses of the industry.\nThis article is originally published on XR Practices Publication\n","id":12,"tag":"xr ; travel ; transportation ; usecases ; enterprise","title":"Augmenting the Travel Reality","type":"post","url":"https://thinkuldeep.github.io/post/augmenting_the_travel_reality/"},{"content":"This article is in continuation of Static Code Analysis for Unity3D — Part 1 where we talked about setting up a local sonar server, sonar scanner and running the analysis for a Unity3D project.\nIt this article, we will discuss setting up the Static Code Analysis with SonarCube in IDE — Rider. We are using Rider as the “External Script Editor” in Unity. Configure Rider here in Unity\u0026gt; Preferences \u0026gt; External Tools \u0026gt; External Script Editor.\nInstall SonarCube Plugin For Rider  Go to JetBrains Rider \u0026gt; Preferences \u0026gt; Plugins \u0026gt; Marketplace \u0026gt; Search SonarQube You will find “SonarCube Community Plugin” \u0026gt; Click Install. It will ask you to restart the IDE to complete the installation. On successful restart you should see it installed.   Configure SonarCube Plugin We need to connect to the sonar server, to perform local analysis. Here are the steps to follow.\n  Go to JetBrains Rider \u0026gt; Preferences \u0026gt; SonarQube — Click Add and provide details of the local sonar server. Ref to the previous post for more details.   Click on +icon for SonarQube resources\n  Click Download Resources and Select the Sonar Project that we have added. — UnityFirst   For local analysis, we need to provide local script that will be called when ‘Inspect Code’ is performed on IDE. So create a script as follows covering all 3 steps that we discussed in the last post.\n   Add Local analysis script — give it a name, path of script and output file.   We are now ready to analysis the code.\nStatic Code Analysis in Rider Open the unity project in Rider. We have ButtonController.cs created in last post, let’s analyze that.\n  Go to JetBrains Rider \u0026gt; Code \u0026gt; Run Inspection By Name (Option+Command+Shift+I) \u0026gt; Search for Sonar\n  Select “SonarQube (new Issues)” \u0026gt; Select Inspection Scope as Whole Project   It will run the code analysis. Just like we did in from the command line in the last post.   To analyze the issues inline in the files, Go to JetBrains Rider \u0026gt; Code \u0026gt; Run Inspection By Name (Option+Command+Shift+I) \u0026gt; Select “SonarQube” \u0026gt; Select Inspection Scope as Whole Project   Issues are available in Sonar Inspection windows and inline. We can further configure rules on sonar to include and exclude files and much more. Each of the analysis is also getting pushed to local sonar server   Conclusion In this post, we have learned how to use SonarCube on a unity project in IDE.\nThis article was originally published on XR Practices Publication\n","id":13,"tag":"xr ; unity ; sonarqube ; static code analysis ; ide ; tutorial ; practice","title":"Static Code Analysis for Unity3D — Part 2","type":"post","url":"https://thinkuldeep.github.io/post/static_code_analysis_unity_2/"},{"content":"Static code analysis is a standard practice in software development. There are code scanner tools, which scans the code to find vulnerabilities. There are some nice tools for visualizing and managing code quality. One of the most used tool is SonarQube, supports 25+ languages and flexible configurations of the rules.\nThere are not enough resources talking about static code analysis for Unity3D. This post covers steps to configure SonarQube and use it for scanning Unity projects.\nSonarQube Server Setup SonarQube requires a server setup where it manages code quality analysis, configuring rules and extensions. Follow the below steps to install and configure Sonar for local use. Make sure you have Java 8+ installed on your PC.\n Download SonarQube — https://www.sonarqube.org/downloads/ - Download Community Edition Unpack the zip sonarqube-8.0.zip as Directory SONAR_INSTALLATION/sonarqube OS-specific installations are available in the bin directory  For Unix based OS provide permissions execute permission on chmod +x SONAR_INSTALLATION/sonarqube/bin/\u0026lt;os-specific-folder\u0026gt;  Start the Sonar Server — eg. SONAR_INSTALLATION/sonarqube/bin/macosx-universal-64/sonar.sh console Sonar Server is ready to be used at http://localhost:9000 with credentials admin/admin Set up your first project on Sonar Qube. — Click create +on top right It will ask you for the token which may be used to securely run the analysis on the sonar server. For now, leave it at this step, we will use user credentials admin/admin for simplicity. This project is created with default rules sets and quality gates. Remember the project key.  Sonar Scanner Setup Sonar scanner needed to statically analyze the code against the rules on the sonar server and then push the reports to the sonar server. Follow the steps below to set up Sonar Scanner Ref : https://docs.sonarqube.org/latest/analysis/scan/sonarscanner-for-msbuild/\n  Download Sonar Scanner — https://github.com/SonarSource/sonar-scanner-msbuild/releases/download/4.7.1.2311/sonar-scanner-msbuild-4.7.1.2311-net46.zip\n  Unpack the zip as Directory SONAR_SCANNER_INSTALLATION/sonarscannermsbuild\n  For UNIX based OS give execute permissions —\nchmod +x SONAR_SCANNER_INSTALLATION/sonarscannermsbuild/sonar-scanner-\u0026lt;version\u0026gt;/bin/* Sonar setup is ready, let\u0026rsquo;s analyze a Unity Project.\n  Analyze Unity Project Create a Unity Project. Below is a simple Unity project with button which toggles its color on every click. Let’s statically analyze this project. Follow the below steps :\n  Goto project root —   Start Pre-Processing for with Sonar Scanner — on windows we can directly run SonarScanner.MSBuild.exe begin /k:\u0026quot;project-key\u0026quot; comes with Sonar Scanner, but on Mac we need run it with mono as follows.\nmono /Applications/sonarscannermsbuild/SonarScanner.MSBuild.exe begin /k:”UnityFirst” /d:sonar.host.url=”http://localhost:9000\u0026#34;   Rebuild Project — MSBuild.exe \u0026lt;path to solution.sln\u0026gt; /t:Rebuild\nOn mac :   Post-processing — push report to Sonar Server Windows : SonarScanner.MSBuild.exe end Mac: SONAR_SCANNER_INSTALLATION/sonarscannermsbuild/SonarScanner.MSBuild.exe end   Analyze code on Sonar Server — http://localhost:9000/dashboard?id=UnityFirst Dashboard Analyse the issues\n  Conclusion In this post, we have learned setting up Sonar Server and Sonar Scanner and using it for Unity Projects. Also, see its usage on Mac. The next post talks about setting it up for IDE and perform inline code analysis\nThis article was originally published on XR Practices Publication\n","id":14,"tag":"xr ; unity ; sonarqube ; static code analysis ; tutorial ; practice","title":"Static Code Analysis for Unity3D — Part 1","type":"post","url":"https://thinkuldeep.github.io/post/static_code_analysis_unity_1/"},{"content":"Presented At : Thoutworks\u0026rsquo;s Awayday 2019, where the entire ThoughtWorks India travelled to celebrate togetherness.\nI and my colleague Raju Kandaswamy presented this talk in the breakout sessions in category Seismic Shifts Around 2000 Thoghtworkers get together, and enjoyed fusion of technology showcases, cultural event and more. Glimpse here\n The talk is about  What is SLAM (Simultaneous Localization And Mapping)? The use cases of SLAM? How does it work? ARVR and SLAM?  Video here  Slides here   Slam aware applications  from Kuldeep Singh  ","id":15,"tag":"xr ; slam ; event ; thoughtworks","title":"AwayDay 2019 - SLAM Aware Applications","type":"talk","url":"https://thinkuldeep.github.io/talk/thougthworks_awayday_2019_slam_aware_apps/"},{"content":"Inception exercise is very common in software development, where we gather the business requirements and define the delivery plan for the MVP(Minimum Viable Product) on a shared understanding. There are a set of tools and practices available to define the MVP requirements and its delivery plan. Famous tools are Lean Value Tree, Business Model Canvas, Plane Map, Elevator Pitch, Futurespective, Empathy Maps, Value Proposition Canvas, User Journey Map, Gamestorming, Process Diagram, MoSCoW, Communication Plan, Project Plan etc.\nWe have recently concluded an Inception Workshop at ThoughtWorks, by Akshay Dhawle, Smita Bhat and Pramod Shaik. It was a 3 days workshop, full of exposure to different tools, exercises and role-plays. Thanks to the mentors and participants, for making it so smooth and fun. We learned a lot of different aspects of the inception and situations. The inception may go wrong if we don\u0026rsquo;t care about the intricacies, does not matter how equipped you or your team is.\nHere are my key takeaways from the workshop :\n Choose the tool wisely, the tool should to simply the process and help us uncover the hidden aspects. A wrong tool selection may take the exercise completely off the track. The inception team must be comfortable with the selected tool and practices, it is better to do a rehearsal using the selected tool or practice. It is advisable that the inception team members should work together for atleast a week or so to understand each other and build synergies among themselves. Always go prepared with detailed inception plan and objective on each day, do a rehearsal with the inception team before facing the client. Do retrospection even if you think that things are going well, to understand the team\u0026rsquo;s performance and improvise on time. Have a backup plan for almost everything, from people/resource unavailability to selection of the tools. Be flexible, and get ready to adapt to the new plans. Define drivers in the inception of different exercises, as well as overall inception, who owns the facilitation. Define the roles and expectations upfront, however as stated earlier alway have a backup. If we stuck with tool/situations than driver needs to push the team forward. Inception is a collaborative exercise, the decisions should be taken with common understanding with client\u0026rsquo;s inception team, there should not be any last-minute surprise for the stakeholders. Utilize the client\u0026rsquo;s time optimally, and try to finish it in the agreed time. Do homework, and go with your well-thought understanding of the problem. Have a domain SME in the team. Have a diverse team for inception. Parallelise the inception activities, whenever required. Get the final presentation deck reviewed with the client stakeholders before presenting it to a larger audience. Record meeting notes and build/update the agreed artifacts after the sessions. Don\u0026rsquo;t delay building showcase/artifacts till the end. Divide and conquer. Share the notes with all the involved stakeholders. Have review checkpoints with the client at a different stage of the inception. While presenting the outcome to the client, it is recommended to present the sections which you were part of, otherwise, get a knowledge dump from the authors before the presentation. Don\u0026rsquo;t over commit to the client, be honest and transparent. Clearly call out pre and post inception activities. Don\u0026rsquo;t ignore any inputs from the team, keep it in the parking lot, review it often. Timebox the exercises, don\u0026rsquo;t stick on one exercise. If one exercise does not complete/get optimal output in a reasonable time, then have a plan for alternatives.  Conclusion Inception is planned to bring stakeholders on same understanding of the product and delivery road map. The focus should be on inception goal, rather than on the tool selection. The tool is just a medium, use the simplest tool in which the team is comfortable in. Facilitate the inception as a collaborative exercise, where all the participants can comfortability participate and agree upon.\nThis article was originally published on My LinkedIn Profile\n","id":16,"tag":"thoughtworks ; inception ; workshop ; takeaways","title":"Inception Workshop | Key Takeaways","type":"post","url":"https://thinkuldeep.github.io/post/inception_workshop_key_takaways/"},{"content":"Presented At : Google DevFest 2019, by Google Developer\u0026rsquo;s Group, GDG Cloud Delhi .\nThe talks is about  How the User interactions evolved with time? Why is it important to think beyond the tradition keyboard and screen? Where is the industry heading? How will it impact us?  Intro here  We have built office-explorer #DevFest2019 pic.twitter.com/0yRz7Euo8J\n\u0026mdash; Kuldeep Singh (@thinkuldeep) September 10, 2019  Detailed Slides   Think beyond keyboard and screen - dev fest 2019  from Kuldeep Singh  Feedback It was well recevied the participats.\nWalls have ears Doors have eyes 😂😂 Amazing talk by @thinkuldeep on AR/VR#DevFest19 #DevFest\n\u0026mdash; Lakshya Bansal (@lakshya__bansal) September 29, 2019  ","id":17,"tag":"xr ; fundamentals ; devfest ; google ; general ; talk","title":"Google Devfest 2019 - Think Beyond Keyboard and Screen","type":"talk","url":"https://thinkuldeep.github.io/talk/google_devfest_2019_think_beyond_keyboard_and_screen/"},{"content":"Technology defines our interactions with the ambiance, and the way we want to interact with the ambiance further defines the technology. The evolution of technology and user interactions tightly depends on each other.\n \u0026ldquo;Walls have ears!\u0026quot;, is very much true today, and not just that, now the walls can see you, feel your presence and talk to you.\n In this post, we will discuss how the user interactions evolved with time and what is next!\nEvolution of Technology and User Interactions Technology evolves to provide better user interactions, and the users always expect more from technology. Technology has evolved by thinking the user interactions, beyond the boundaries of traditional technologies. Speed of technology evolution is increasing day by day, and so is the user interactions. See below chart. With all the technological advancements, the user interactions have been evolved from almost no interactions to the immersive interactions. Following are the different stages of interactions evolution.\nNo Interactions We have started our journey with almost no interactions in the Batch Age, where software programs fed as the punch cards into the computer (such as UNIVAC, IBM029), and you get to know the results after a couple of hours or days. It continued till the early 60s.\nAttentive Interactions With little more enhancements in technology, the display screen and keyboard used to provide better user experience, and in this Command Line Interface (CLI) Age, users used to get attention whenever any alert/information to be displayed or input needs to be taken for next set of processing. Apple and Xerox invested heavily, and most of this era\u0026rsquo;s product was not commercially successful, but they have created a path for next technology evolutions. Microsoft\u0026rsquo;s DOS became a great software base in the CLI age.\nWYSIWYG Interactions Graphics User Interface(GUI) Age started from the early 80s when technology was focusing on the window-based interface, and form/editor based UI which is called What You See Is What You Get (WYSIWYG) interactions.\nXerox and Apple tried a few costly attempts as Xerox Star, Apple Lisa. GUI was popularity by Microsoft and Apple in the mid-80s with Windows 1.0 and Macintosh, and the race continued. Software and hardware technologies improved with time and GUI age continued for multiple screen sizes.\nSeamless transition After nearly 1.5 decades of technology enhancements in GUI age, the mobile phone and laptop started taking the shape. Internet Age started, and user interaction started shifting from desktop-based GUI to the web or mobile app based GUI, especially after AJAX, which promised desktop like partial GUI rendering.\nPC : http://www.mynseriesblog.com/category/nseries-site-news/\nA need for seamless transitions of GUI across devices was the increasing focus of this era. The mobile device was getting powerful and became a commodity, so the need for mobile-first GUI became popular. Most of the devices were relying on keypad and display screen. Nokia, Motorola were the pioneers in the cell phones. QWERTY keypad was also quite popular by Blackberry. Laptop and Tablets with external keyboards have almost replaced the PC market.\nTouch and Feel Interactions Touch screen interface was popularized by Apple iPhone in 2007, Samsung followed and race of touch and feel still continued, with lot many players.\nPC: https://www.pastemagazine.com/tech/gadgets/the-20-best-gadgets-of-the-decade-2000-2009/?p=2#7-iphone-2007-\nThe winner was again \u0026ldquo;Ease of doing\u0026rdquo;, touch screen interactions surpassed physical keypads phones, while Nokia and Blackberry were still relying on haptic feeling of a physical button. Internet Age continues with better internet, better devices, better interactions with the help of technology like the Internet Of Thing and Cloud. The phone became a smartphone in this era.\nThe Internet Age was transitioning into Interactions Age, the devices getting closer to human, such that they can wear them and feel them. The smartphone became the enabler to other interactions with wearable and other sensing devices. The smartphone serves as the processing unit, controller and internet gateway to the wearable devices. Lightweight communication protocols are invented (MQTT, BLE, etc) to communicate with these IoT/Wearable devices. We have seen some successful Smart Glass and SmartWatch products.\nIn this Interactions Age, we trust the technology and use it so heavily that all our interactions with devices getting recorded and data is increasing multifold. Data will become the next power. In this age, traveling with unknowns is no more a concern, we trust Uber, OLA more than it was before, as we know data is being recorded somewhere, and we feel technology is inducing transparency in the system. We rely more on the text then on phone calls, social media is getting powerful due to this.\nImmersive Interactions Interactions Age will continue, and interactions are going to be immersive, where we interact with the virtual elements of the ambiance, assuming they are real, we feel immersive in the virtual environment.\n  Conversational UI - Conversational interfaces, where we talk/text to virtual bots, they respond just like a real human. We don\u0026rsquo;t need to go to a website and find our needed services on a bulky portal/ or on an app, rather we just send text or voice to a bot, and the bot would respond appropriate result. Devices like Google Home, Amazon Eco are getting popular with just voice interface. IoT empowers CUI to build a lot of enterprise use cases.\n  Virtual Reality - VR interactions happen in a completely computer-generated environment, which is a real like environment. VR is getting popular in the education and training simulation domain. Travel and Real-estate are also utilizing it for sales and marketing, where users can try the services in the virtual environment before buying them. VR Therapy is getting popular in the healthcare sector. Google, Samsung, Sony, HTC, Facebook are building heavily on it.   Augmented Reality (AR) - Augment Reality, augments the information on the real world. The technology can assist the worker by providing needful information while his/her hands are busy, a worker can talk to the head mounted device/smart glass like Google Glass, and get the assistance, it is called Assisted Reality. When an AR device generates a computer-generated environment on top of the real world, and let us interact with these computer-generated elements in the context of a real word, then it is called Mixed Reality (MR). Microsoft Hololens and Magic Leap are some popular devices MR devices, but these are quite costly. With increasing AR support on the mobile phone, AR mobile apps on are getting popular, it will outpace the normal app development. Future mobile apps will be AR enabled. Google is building VPS (AI powered Virtual Position System) to empower its Google Map with Augmented Reality. PC : Microsoft HoloLens 2\n  Extended Reality - In the Mixed Reality environment, when we interact with the real-world environment then we call it extended reality interactions. For example, look at the switch, and blink your eye to switch it on.\n  Brain-Computer Interface (BCI) - Multiple types of research are going in the area of the brain-computer interfaces, where a computer can directly feed into the brain or vice-versa. Facebook is researching on thought based interfaces. A blind person\u0026rsquo;s mind can be fed with a camera stream to see thru the world and many more. VR and AI will play a great role here.\n  Artificial intelligence is enabling immersive interactions to look and feel more real. Hardware is getting foldable, regeneratable (3D printable), and people will wear the devices, it is getting so small that it can be taken as a pills, and can be controlled from outside. In short, technology is going closer to its context and its application. For example, BLE enabled contact lenses for eyes, printed sticker for monitoring BP, heart rate, smart shoes to direct your foot to move in the target direction, smart glasses to record what you view, smart gloves to help your work, a smart shirt to make you comfortable and control your body temperature, and the list is endless.\nFuture will we age of Artificial Interactions, where even interactions itself can be virtuals. An authorized machine will do virtual interactions on your behalf,\nThoughtWorks has published \u0026ldquo;Evolving Interactions\u0026rdquo; as one of the seismic shift. Do read it.\n We must evolve our thinking—and our capabilities— beyond the keyboard and the screen. Mixed reality will become the norm\n Conclusion We have discussed, how we have evolved our interactions with machines, and how technology is filling the need of the time. A lot of experiments and investments have gone into this journey, every other disruptive technology has killed the previous innovation and investments, but it brings a lot of new opportunities. Industries and individuals must keep experimenting and investing in new technologies, to stay relevant, otherwise, someday you will be abandoned.\nRef and Piture Credits : Microsoft HoloLens 2, and other.\nThis article was originally published on My LinkedIn Profile and XR Practices Publication\n","id":18,"tag":"xr ; evolution ; transformation ; ux ; user-interactions","title":"Evolution of Technology and User Interactions","type":"post","url":"https://thinkuldeep.github.io/post/evolution_of_technology_and_user_interactions/"},{"content":"IT Modernization is one of the key factors of today\u0026rsquo;s digital transformation. Most of the enterprises trying to define digital transformation strategy. IT organizations trying to redesign the organizations to meet the changing business need, and uplift the technology and people. Non-IT organizations are also trying to setup digital department to take care of companies digital assets and modernize them. However, IT modernization does not always result in a profit, it may lead to revenue loss if it does not fit to the organization design.\nHere is an example statement that you may get from your client:\n We have rewamped our old mobile site to new prograssive web app, and we are observing 6% drop in conversion rate, impacting the revenue.\n Assume that the client is a non-IT organization, and they have a digital department taking care of the digital assets (Website, App, Mobile Site etc), and also trying to upgrade assets to the latest technologies.\nHere are the general patterns and observations, which may be the major cause of the revenue drop even after the tech modernization.\nIts a matter of changing the technology IT modernization is generally considered just as a matter of changing technology. But it first requires people who accept the change and take it forward. We have observed missing ownership from the stakeholders, and the modernization was looked as enforced on the teams then it was embraced. Most of the team was new in the digital department and the existing people were holding a lot of history and knowledge, which they do not want to expose, in a fear of devaluing.\nSometimes the organizations try to project itself as an agile organization, aims to change anything at any time, but this becomes the anti-pattern.\nActivity Oriented Teams The teams are structured on activity and not on the outcome; eg - Product Design, Development, Test, and DevOps are working silos. It is hard to sync up on the quality outcome. Teams structure should be based on outcome and business value. Ref to my earlier post.\nFor example, you noticed that 10-15 AWS instances were getting spawned in every 24 hours, and the existing instances were getting killed after heavy memory utilization. It went unnoticed for long because, as per DevOps SLA auto-scaling was working fine and the site never goes down, and the memory utilization issue is a headache of the development team. The development team is not interested in monitoring production health as it comes under the DevOps purview.\nCross-functional knowledge is missing in such teams, and there is a lot of people dependency, which hinders taking a feature from business analysis to the deployment.\nInadequate Development Practices It is a pattern when the standard development practices are missing, then the feedback cycle to developers are too long. Most of the issues are captured in the production. Test automation and CICD pipe are not up to date, so developers do not trust and maintain the test suites. It will become a practice to bye-pass the test suite and deploy directly to pre-production or production. It some times a result from a lot of pressure for quantitive delivery from the top management than on quality delivery.\nYou will see that the client would have a history of uncaught broken functionalities for a longer period of time, which would also be a cause to not trust the web site, and eventually impact the conversion rate and revenue.\nProduct and Business Observations We have noticed the following observations related to business and product perspective.\n No business continuity - It is observed that the application is not stable enough, and there is no mechanism to keep the user engaged if the user has lost the product order journey. User experience - There are some major usability issues on the new app such as; a lot of clicks require to customize the product and order, redundant information placement. Integration Issues - History of issues with 3rd party gateways. It is taking too long to identify such issues. Define ways to measure 3rd party system\u0026rsquo;s performance and held them responsible for revenue loss if they do not follow the agreed SLAs.  Technology Observations Following are kind of technology observations, and these are mainly due to taking technology decisions without proper ownership and knowledge. Technology choices are followed for the sake of changing to a new concept. Eg: Server-Side Rendering on PWA was not well evaluated but applied.\n Memory Leaks - As mentioned in the earlier example, AWS instances are getting killed after getting out of memory. The exceptional increase in NodeJS server memory, which is leading to crashes every 2-5 hours. It is mainly due to, a) Too many global variables declared at the node level, b) Unwanted setTmeouts written to cancel each fetch request. After fixing the leaks the node instances may run in just 300 MB of memory, which earlier may be taking 20GB. Older Tech Stack - NodeJS, NextJS and React are at the older versions. Request Traceability across app is missing. There was a load on API servers due to unnecessary calls from the UI. Incorrect Progress Web App Strategy Issues in Cloud front caching strategy Incorrect Auto-scaling strategy. Instead of fixing the memory leak issue, an unnecessary auto-scaling configuration was done, which gracefully scales a new instance after every 10000 requests to a node. Missing Infra Health Monitoring alerts  Conclusion The success of IT modernization is closely linked to the organization design, it may not always lead to success if the changes it may require are not accepted and owned by people. Just by changing the technology will not lead to IT modernization. The new technology comes with great promises but it also comes with its own challenges. We must always choose a new technology with the right tooling to address the challenges.\nThis article is originally published on My LinkedIn Profile\n","id":19,"tag":"general ; cloud ; digital ; modernization ; technology ; transformation ; experience ; troubleshooting ; agile","title":"Can IT modernization lead to revenue loss?","type":"post","url":"https://thinkuldeep.github.io/post/can_it_modernization_lead_to_revenue_loss/"},{"content":"I just finished a book \u0026ldquo;Life\u0026rsquo;s Amazing Secrets\u0026rdquo; by Gaur Gopal Das. It covers the topic of balance and purpose in life nicely. Few of the concepts from the book I can very well relate to my current organization\u0026rsquo;s focus on cultivation and collaboration culture.\nIt\u0026rsquo;s now more than 6 months of my journey with Thoughtworks, an organization which started as a social experiment more than 25 years ago, and believes in balancing 3 pillars in life ; sustainability, excellence and purpose. It makes the organization as a living entity, and wherever there is life, it has to face the changes and challenges, it\u0026rsquo;s on us how we overcome and excel the art of changing.\nHere are my takeaways from the book, which help us grow through the life, build social capital, and help the people centric organization grow.\n Live by the principle of gratitude, which allow us to see the positivity and believe in the trust-first approach. Start making a gratitude logs. Our attitude towards life affects our social image, the speaking sensitivity is the key while giving or taking feedback. Life can never be perfect, too much corrective feedback may spoil the relationships, if one don\u0026rsquo;t know the art. Feedback without correct motive and purpose has no meaning. Think higher purpose, look beyond the situations and practise forgiveness but we must maintain social decorum of rules and regulations of society/community or organization. Uplift relationship by give and take; exchange of thoughts, values and beliefs Be your own hero, every time you compete with yourself, you will be better than before. Promote culture of healthy competition. Each one is different and not comparable. Go on a journey of introspection, know yourself and find the purpose of life.  Develop good character by belief, actions and conduct. Good character has the ability to change lives. We have 2 ears and 1 mouth, so give them chance in that proportion; Listen before you speak and choose to respond (not react). The book presents a great ideology of the ice-cream, the candle and the oxygen mask, to guide us a journey from selfish to selfless. A view from family first to serving the nation, and how serving others can be Joy of life. It also talks about role of spirituality in our life. Overall it is a great book, and I recommend it.  This article is originally published on My LinkedIn Profile\n","id":20,"tag":"selfhelp ; book-review ; thoughtworks ; takeaways","title":"Embibe purpose and balance in life","type":"post","url":"https://thinkuldeep.github.io/post/embibe_purpose_and_balance_in_life/"},{"content":"Recently got a chance to judge and mentor india\u0026rsquo;s young innovators at Smart India Hackathon 2019, world\u0026rsquo;s largest hackathon with 11000 shortlisted participants, hosted by 48 centers across India. It was organized by AICTE and MHRD, Govt of India. I was invited to Judge the event at Panipat Institute of Engineering \u0026amp; Technology, Panipat. I am delighted to contribute in the journey of India\u0026rsquo;s transformation, and see innovative ideas from the new generation. It was an experience, which I would like to share in this post. Thanks to my friend Suresh K Jangir for introducing me with AICTE, and to all the judges, PIET students and organisers for making my experience memorable.\nAll set for next 36 hours The event was started on time, and followed by a well defined packed schedule. We have been introduced with our next 36 hours duties and responsibilities as Judge and Mentors, by AICTE\u0026rsquo;s Amit Parshetti. There were 4 categories in which participants were trying to solve the problems; Sports and Fitness, Sustainable Environment, Smart Textile and Smart Vehicles. Each of us, needed to do 3 mentoring rounds and 4 evaluation rounds in next 36 hours, day and night. The Judges panel consists of Dietician, Professors, Entrepreneurs, and Industry experts. It was great interacting with such a diverse team, and learning from each other\u0026rsquo;s experience.\nWe started our initial mentoring and judging rounds, and found some interesting raw ideas, but they were far from realisation. These idea needed some polishing and mentoring to make them presentable.\nWe have given our initial suggestions to the teams, and tried to let them think other parameters of making their product/idea successful. Most of the ideas were around software using IoT and AI. I was able to contribute well due to my relevant industry experience. The mentoring and judging round continued, and teams were working for the whole night to make their idea a reality.\nThe Josh moment - Student interaction with PM Modi The young innovators were getting encouraged not only by the mentors, judges and coordinators but also by the Govt of India. It was a Josh moment for students when they get a chance to interact with the Prime Minister of India at 10 PM.\nPM Modi interacted at multiple nodal centers, and discussed and appreciated their ideas. It was a great moment to see india transforming, see such a nice initiatives driven by Govt. Participants were also addressed by Shri Prakash Javadekar, Union Minister, MHRD.\nBack to college days I stayed in the college guest house, and staying there was like going back to college days, year 2K to 2K4 of NIT kurukshetra. I got chance to interact with Prof.(Dr.) Shakti Kumar, Director, PIET, who have taught my college professor, Prof. Jitender Kumar Chhabra.\nWe shared, how Chhabra sir\u0026rsquo;s programming concepts are still deep into my brain. I also met few NITK alumni as PIET faculty. My roll number at college was 2K020 and my friend Deepak Arora, 2K021, partner in crime, is from Panipat. We met there after 14 years, as he was luckily in the same city during this.\nSome of the greatest ideas Next day, remaining mentoring and evaluation rounds continued, and we were at the stage of selecting 8 teams for final round. We have consolidated the scores and point of views on each team, and their progress so far in the hackathon. Here are some interesting ideas that got selected for final round:\n Pot Hole Detection System - IOT, GPS Bike starts only if rider wear helmet - IOT Accident Prevention - Auto adjust beam to low when cars crossing each other - IOT GPS tagged factory licences and pollution control - IOT Virtual Physical Training - The app detects the body posture, ask to correct if not as per the ML model - CV, AI Virtual Fit - Upload your image, and app will predict your body size, then you can order clothings customized to your size, and the tailors will get the exact designs. - CV, AI Detection of Air-filter choking - IOT, AI Create a social network of people works for good causes, build people\u0026rsquo;s social profile. Supply chain portals to promote art and craft from rural areas.  The shortlisted teams were asked to present and demonstrate for the final round.\nThe Final Round Time has come, and the final round was headed by guest Mr. Vinay Kumar Jain, Principal Technology Architect at Infosys Ltd. All the shortlisted teams presented and demonstrated what they have done in the hackathon. We were to select top 3 ideas. Results were locked. Hearts were beating high. It was a tough time for the judges as well to take out only 3 ideas, as students really worked hard to get their ideas implemented in just 30 hours. Concluding Ceremony We are again at Auditorium where the event was started. PIET students entertained the audience by their great dance performances. Judges and guests were also felicitated.\nMr. Rajesh Agarwal, MD Micromax Informatics Ltd, was the chief guest of the concluding ceremony. His speech was really inspiring, he shared some of the challenges he faced as an entrepreneur. He gave a message to the future entrepreneur to not stop, continue.\nEveryone was waiting for the results, and here comes the\n Second runner up - Virtual Physical Training - Rs. 50000 First runner up - Bike starts only if rider wear helmet - Rs. 75000 Winner - Virtual Fit - Rs. 100000  Congratulations to the winners, best of luck to the rest of learners!\nThank you!\nThis article is originally published on My LinkedIn Profile\n","id":21,"tag":"sih ; Hackathon ; experience ; takeaways","title":"Smart India Hackathon 2019 - An Experience","type":"post","url":"https://thinkuldeep.github.io/post/sih_2019_an_experience/"},{"content":"Blockchain or DLT (Distributed Ledger Technology) is getting good traction in the IT world these days. Earlier, this technology was being mostly explored by banks and other finance-related institutions, such as Bitcoin and Ethereum. Now, it is getting explored for other use cases for building distributed applications. Blockchain technology comes with a decentralized and immutable data structure that maintains a connected block of information. Each block is connected using a hash of the previous block, and every new block on the chain is validated (mined) before adding and replicating it. This post is about my learnings and challenges while building an enterprise blockchain platform based on Quorum blockchain technology.\nBlockchain-Based Enterprise Platform We have built a commodity trading platform that matches the trades from different parties and store-related trade data on smart contracts. Trade operations are private to the counterparties; however, packaging and delivery operations are performed privately to all the blockchain network partners. The delivery operation involves multiple delivery partners and approval processes, which are safely recorded in the blockchain environment. The platform acts as a trusted single source of truth and, at the same time, keeping data distributed in the client\u0026rsquo;s autonomy.\nThe platform built on Quorum, which is an Ethereum-based blockchain technology supporting private transactions on top of Ethereum. A React-based GUI is backed by the API layer of Spring Boot + Web3J. Smart contracts are written in Solidity. Read more here to start on a similar technology stack and know the blockchain.\nThe following diagram represents the reference architecture: Blockchain Development Learnings Blockchain comes with a lot of promises to safely perform distributed operations on a peer-to-peer network. It keeps data secure and makes them immutable so that data written on a blockchain can be trusted as the source of truth. However, it comes with its own challenges; we have learned a lot while solving the challenges and making the platform production-ready. These learnings are based on the technology we used; however, it can be co-related any of the similar DLT solutions.\nThe Product, Business, and Technology Alignment Business owners, analysts, and product drives need to understand the technology and its limitation — this will help in proposing a well-aligned solution supported by the technology.\n Not for the real-time system — Blockchain technology supports eventual consistency, which means that data (a block) will be added/available eventually on the network nodes, but it may not be available in real-time. This is because it is an asynchronous system. Products/ applications built using this technology may not be a real-time system where end-users expect the immediate impact of the operation. We may end up building a lot of overhead to make real-time end-user interfaces by implementing polling, web-sockets, time-outs, event-bus, on smart-contract events. The ideal end-user interface would have a request pipeline where the user can see the status of all its requests. Once a request is successful, then only the user will expect the impact. There is no rollback on the blockchain due to its immutability, so atomicity across transactions is not available implicitly. It is a good practice to keep the operation as small as possible and design the end interface accordingly. Blockchain’s transaction order is guaranteed, thus making it more of a sequential system, if a user is submitting multiple requests then they will go in sequentially to the chain. (Private Blockchain) Each user/network node has its own smart contract data for which the node has participated into the transaction on the start contract, so adding new node/user to the contact would not see the past data available on the contract. It may have an implication on business exceptions. Backward compatibility is anti-pattern on the blockchain. It would be better if we may bind business features to the contract/release versions, new features will be only available in the new contract, otherwise implementing backward compatibility takes a huge effort.  Architecture and Technology Learnings  Think multi-tenancy from the start — Blockchain system is mostly about operations/transactions between multiple parties and multiple organizations. Most enterprise platforms have multiple layers of applications, such as end-user client layer (web, mobile, etc.), API layers, authentications and authorizations, indexes, and integrations with other systems. It is wise to think of multi-tenancy across the layers from the start of the project and design the product accordingly, instead of introducing it at the later stage. Security does not come on its own — Blockchain-based systems generally introduce another layer of integration between the API and data layer. We still need to protect all the critical points at multiple network nodes owned by different participants. So, defining the security process and practices are even more important and complex for blockchain-based solutions than that of the classic web application. Make sure these practices are followed by all the participant\u0026rsquo;s node. A hybrid solution — We might need to keep data index/cache (SQL or NoSQL) to meet the need multiple users read, as reading every time from a smart contract may not meet the performance criteria. The index/cache building module may subscribe to the smart contract transaction event and build data index/cache to serve as reading a copy of blockchain data. Each participant\u0026rsquo;s node will have its own index and end-users\u0026rsquo; interface of that participant organization. It will definitely add complexity to maintain the index, but until blockchain technology becomes as fast as reading cache, we have this option to go Hybrid way (blockchain + read indexes). We can replay a smart-contract transaction event as and when required; it helps in rebuilding indexes/cache in case we lost the index. Carefully add business validation in the smart-contract — we may add business data validation in the smart contract itself, but it has a transaction cost (performance cost), and more complex validation may lead to out of gas issues, also getting a detailed exception from the contract is not fully supported. If we are maintaining indexes, then we may do validation before making the contract transitions by reading from indexes, but it is also not a proof solution, as there might be race conditions. The ideal way is to perform business validation before, and if race condition occurs, just override/ignore the operation and choose the approach wisely based on the business impact. Fear of Losing Transactions — What if we can not process a transaction due to an error? Depending on the case, we either need to wait for the problem to be fixed and halt all the further events or just log the error and proceed. As mentioned in the previous section, choose to override/ignore wisely; it may have a significant business impact. Smart Contract Limitation — Solidity has a limitation on a number of parameters in a method, stack depth, string handling, contract size, gas limits. So, design contract methods accordingly. Tracing — Think of application tracing from web/mobile \u0026lt;-\u0026gt; API server \u0026lt;-\u0026gt; blockchain \u0026lt;-\u0026gt; indexes from the start. Each request should be traceable. Quorum doesn’t support any tracing/message header kind of mechanism to send co-relation identifier; however, we may link the application a trace id to the transaction hash. Configurability/Master Data Management — Every enterprise system needs some master data, which can be used across the organizations since participant\u0026rsquo;s nodes are decentralized. So, this data needs to be synchronized across nodes. Device out a mechanism to replicate this data across the nodes. Any inconsistency may result in the failure of transactions. Smart Contract Backward Compatibility — This is the most complex part of the contract. We need to write a wrapper contract on the older contract and delegate a call to the old one. Note that we cannot access the private data of the existing contract, so we need to implement all the private data in the wrapper contract and conditional delegate call to the old contract. Managing event listeners for different versions are also complex; we may need to keep multiple versions in event listeners in the code base to support multiple versions of the contracts. We also need to make sure all the participants are on the same version of contracts. It would be better if we bound business features with this version. In that case, any new transaction operation may not be available on the old contract. Scaling the API/Client Layer — Since the blockchain processes the transactions in a sequential manner, scaling the API/client layer is complex; we need to implement some locking mechanism to avoid the same transaction getting performed from multiple instances of the API layer. Deployment is another challenge here. Feature toggle on the contract side is also quite complex  Testing Learnings  Solidity unit tests take a lot of gas as the functionality grows, so it is better to use JS API-based tests for contract unit tests. Define contract migration testing approach and it\u0026rsquo;s automation up front. Automate environment preparation as it needs multiple tenants\u0026rsquo; nodes to interact to test the functionality. API integration tests need to poll the other participants\u0026rsquo; API to see the expected impact. It increases the API test development times as well as execution time. Define approach for test automation around index/cache rebuilding The version-based feature toggles in tests artifacts are complex to maintain. Automation of meta-data management across the nodes Testing of CI/CD scripts as the scripts grow, so complex with time and impact of any issue is critical.  Continuous Integration and Deployment  Define the blockchain node deployment strategy upfront (private/public cloud); you may not change it once it is deployed without losing data. Securely storing secrets on the cloud. Have a process for access management reviews. Analyze the impact of secret rotation on blockchain node setup and automate the process. Backup and restore strategy for blockchain Making sure all the nodes are on the same version of blockchain and software artifact High availability is a challenge when new deployment has to happen, as we need to stop service completely before deploying the new version to avoid corrupt indexes/blockchain due to the intermediate state of operations (multi-transaction operation).  Project Management  The blockchain is still a growing technology. It is better to have a dedicated sub-team that takes care of blockchain research-related work and define best practices for the project and industry. Dedicated infra team is needed to manage and improve the CI/CD environment. Security testing resources and audits. Legal point of view on GDPR and storing data with blockchain. Coordination with participant’s infra team Support SLA with each participant.  This article was originally published on Dzone\n","id":22,"tag":"blockchain ; java ; experience ; learnings ; micro-services ; architecture ; spring boot","title":"Lessons Learned From Blockchain-Based Development","type":"post","url":"https://thinkuldeep.github.io/post/learnings-from-blockchain-based-development/"},{"content":"The book \u0026ldquo;Agile IT Organization Design - For digital transformation and continuous delivery\u0026rdquo; by Sriram Narayan explains software development as a design process. Following statement from the book means a lot.\n \u0026ldquo;Software development is a design process, and the production environment is the factory where product takes place. IT OPS work to keep the factory running..\u0026rdquo;\n It questions the way we traditionally think of operation support, maintenance, production bugs, rework, their costs and budgets and the focus in software development life.\nThinking software development as a design process helps the organisations, focus on today\u0026rsquo;s need of agile development. Here are some thought points, when anything before production deployment is considered as software product design, and the \u0026ldquo;software product\u0026rdquo; is getting produced from the production environment (factory):\n Dev + OPS - A product design which doesn\u0026rsquo;t fit in the process of factory can not be produced by the factory, in other words A factory which do have sufficient resources needed to produce given design can\u0026rsquo;t produce the product. The product designer, and factory operators needs to be in the close collaborated team, to improvise the design, and do production. Continuous Delivery - There is no point of thinking about factory after the product design is done, we may not be able to build the factory optimally. Think of the production factory while design the product. Have continuous feedback in place by continuous integration and delivery. Value driven and outcome oriented teams - A factory can produce the product on a shop floor/production line with checks, balances and integration at each step. It implies to the software development as well, value driven projects, and outcome oriented teams are more helpful in making product successful over the plan driven projects and activity orientated teams. The book covers it very well. Sorter cycle time - Software product design has no value until it is produced, and reached to the people. Sooner we produce, better we get the value - so cycle time for product design must be as small as possible. Luckily in software development we have tools to simulate factory environment/test labs, and try to produce the models well before the actual production. Measure the product quality more than the design quality - It is important to measure product quality than that of the product design (software before prod environment). So metrics which can really measure product quality (software running in production environment) such as velocity in term of \u0026ldquo;Value\u0026rdquo;. Measuring burn-up/burn-down, bugs counts, defect density, code review quality are all product design metrics, it may not matter how good these numbers are if software is not producing value on the production environment.  Conclusion The book covers an agile organization design with a great breadth and depth on structural, cultural, operational, political and physical aspects. We can relate many of these aspects while thinking the software development as a design process.\nThis article was originally published on My LinkedIn Profile\n","id":23,"tag":"software ; book-review ; process ; design ; organization ; takeaways ; agile","title":"Software Development as a Design Process","type":"post","url":"https://thinkuldeep.github.io/post/software-development-as-design-process/"},{"content":"Most web applications are hosted behind a load balancer or web-server such as Nginx/HTTPD, which intercepts all the requests and directs dynamic content requests to the application server, such as Tomcat. Correlating requests traversing from the front-end server to the backend servers are general requirements. In this post, we will discuss tracing the request in the simplest way in an Nginx and Spring Boot-based application without using an external heavyweight library like Slueth.\nAssign an Identifier to Each Request Coming Into Nginx Nginx keeps request identifier for HTTP request in a variable $request_id, which is a 32 haxadecimal characters string. $request_id can be passed to further downstream with request headers. Following configuration passes the $request_id as X-Request-ID HTTP request header to the application server.\nserver { listen 80; location / { proxy_pass http://apiserver; proxy_set_header X-Request-ID $request_id; } } Log the Request Identifier in Front-end Access Logs Include the $request_id in the log format of the Nginx configuration file as follows.\nlog_format req_id_log \u0026#39;$remote_addr - $remote_user [$time_local] $request_id \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#34;$http_user_agent\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /dev/stdout req_id_log; It will print the access logs in the following format:\n172.13.0.1 - - [28/Sep/2018:05:28:26 +0000] 7f75b81cec7ae4a1d70411fefe5a6ace \u0026#34;GET /v0/status HTTP/1.1\u0026#34; 200 184 \u0026#34;http://localhost:80/\u0026#34; \u0026#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\u0026#34; \u0026#34;-\u0026#34; Intercept the HTTP Request on the Application Server Every HTTP request coming into the application server will now have the header X-Request-ID, which can be intercepted either in the interceptor or servlet filter. From there, it can be logged along with every log we print in the logs, as follows.\n####Define a Request Filter Using MDC Define the following request filter, which reads the request header and puts it in the MDC (read about MDC here). It basically keeps the values in the thread local.\n... @Component public class RegLogger implements Filter { @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { try { MDC.put(\u0026#34;X-Request-ID\u0026#34;, ((HttpServletRequest)servletRequest).getHeader(\u0026#34;X-Request-ID\u0026#34;)); filterChain.doFilter(servletRequest, servletResponse); } finally { MDC.clear(); } } @Override public void init(FilterConfig filterConfig) throws ServletException {} @Override public void destroy() {} } Configure the Logger to Print the Request id I have used logback, which can read MDC variables in the %X{variable_name} pattern. Update the logback pattern as follows:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.classic.encoder.PatternLayoutEncoder\u0026#34;\u0026gt; \u0026lt;Pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %X{X-Request-ID} %-5level %logger{36} - %msg%n\u0026lt;/Pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; It will print the following logs:\n17:28:26.011 [http-nio-8090-exec-7] 7f75b81cec7ae4a1d70411fefe5a6ace INFO c.d.e.controllers.StatusController - received request This way, you can see the request id in all the logs from the origin to the end. We can configure ELK to aggregate the logs and trace them in a nice user interface to help with troubleshooting.\nGet the Generated Request id Back in the Response Nginx can also add the request id in the response header with the following configuration:\nserver { listen 80; add_header X-Request-ID $request_id; # add to response header .... As you see here: Conclusion We have explained a simple way to assign a unique identifier to each request, then trace the request end-to-end. You can get more details here.\nThis article was originally published on Dzone\n","id":24,"tag":"request-tracing ; troubleshooting ; java ; web-server ; micro-services ; spring boot","title":"Request Tracing Using Nginx and Spring Boot","type":"post","url":"https://thinkuldeep.github.io/post/request-tracing/"},{"content":"Agile software development methodology is the key selling point for most of the IT organisations, however many of the organisations have gone by the literal meaning of the word \u0026ldquo;Agile\u0026rdquo;. They follow agile practices without really being agile. If we go by Manifesto for Agile Software Development, it focus more on human factor (people, interaction, collaboration) which produces working software as per the need of time, than on processes, tools and strict planning. As described in the book Agile IT Organization Design, organisation culture plays key role in the in becoming true agile organisation. Agile culture is more around collaboration and cultivation than a controlling and competence culture. This post describe, how the test first paired development can boost organisation agility and culture. This article is also my takeaways from the book.\nThe Test First Pair Development: When a pair of experts think about, how a function will be used before developing the function, is the test first development. The book \u0026lsquo;Extreme programming explained: embrace change\u0026rsquo; [3] talks a lot about TDD(Test Driven Development), pair programming, tools, principles and practices. The term test first pair development is generalised from TDD and Pair Programming, however it is not restricted only to developers but also applicable to other software development roles (BA, QA, TL, TA, etc) and cross roles. Following are the key concepts :\nTest First Development  First-Fail-Test : Think of a very basic test for a business functionality that you want to implement. Implement/define the test first. Just-Pass-Test : Write code/artifact which is necessary to pass the test. Don\u0026rsquo;t write unnecessary code to satisfy your assumptions and intuition. Next-Fail-Test : Keep writing test until next fail test and then perform step 2. Keep doing this until you reach at just sufficient outcome. Refactor/beautify the code/artifact and make sure all tests are passing. Do it in between 2 and 3. Get the outcome reviewed, collect feedback and follow above steps again to improvise the feedback.  Pair Development:  Pair sign up - Two person sign up for one outcome. Pair rotation - Pair should be rotated on an interval. Collaboration - Pair must work together. One person is reviewing, while other is doing the task, and then exchange their position when needed. Development environment and seating should be such that both can work together. Pair with diversity - Make a pair of diverse personality in term of role, experience and skills, so that everyone learn from each other and respect. eg : Pair with QA to write automated acceptance tests, Pair with Infra Expert to fix DevOps issues.  Combining Together: Pair follows the test first development practice for example :\nOne person think and write of a test and other person implement the functionality needed to just pass the test. Other person think and write the next test and the first one will implement the functionality to make it pass. Pair with QA/Tester/PO during development to review the outcome before releasing it to QA.\nBenefits of Test First Pair Development: Following are 5 major boosts for organisation for using the approach.\n1. Fail Early We get feedback well early in the development life cycle. The artifact we produce is getting reviewed at very first place of development in two ways. First, it is getting tested by the test artifacts and second, it is getting reviewed by peer as and when it is written. So it will produce batter quality software. As described in test pyramid [4], we build an organisation practice to strengthen the base to testing pyramid.\nIt is not just in term of product feedback but also we get feedback on people for alignment towards agile.\n2. People and Interaction Test first pair development need a great interaction between the pair, and gives equal opportunity to each one. Pair gets rotated after some time, which helps in building the team bonding. People start believing in the word \u0026ldquo;Team\u0026rdquo; and understand that if one expect support from other then, he/she need to support others. In such a team, people build trust and respect among other. It promotes collaboration culture in organisation, which is the key for any real agile organisation.\n3. Outcome Oriented Teams Test first pair development works well with outcome oriented team, where people can cross pair (pair across roles) to achieve desired outcome efficiently. When people cross pair, the understand each other\u0026rsquo;s pain, and better work for each other\u0026rsquo;s success, eventually lead to better business outcome. Test first methodology promote to build software to fulfil immediate business need, and avoid building unnecessary source code.\n4. Change with Confidence and Satisfaction In traditional way, it is always a feared delivery when changing any existing code, we never know what will break, and sometime we get the feedback from the end user. But here, people are more confident in making changes in the existing code which is well covered by the tests. We get immediate feedback by the failing tests, if all existing tests are working then we are good to go, with passing tests for changed functionality. Another eye is always there to watch you. With this approach, people are more satisfied with what they are doing, as they are more interacting, getting more support from team, and are more focused.\n5. Overall cost effectiveness People feel that pair development is a double effort then the traditional development, as two person are assigned to a task which can be done by one person. It is not true for most of the cases due to following reasons:\n Quick on-boarding - Paired development don\u0026rsquo;t need huge on-boarding cycle, new joiner can start contributing from the day one and will learn on the job, while working with the pair. It is pair\u0026rsquo;s responsibility to make the new comer comfortable, it is for his own advantage. No lengthy review cycle - We don\u0026rsquo;t need special review cycle for the code. Almost 10% of implementation effort is assumed for reviews which is be saved. Less defect rework - Since we get feedback well early, so we can fix the issues as and when they found. Rework is proportional to defect age ( defect detected date - defect induced date). Around 20% overall effort is assumed for defect fixes rework. we may save good amount here. Less testing effort - Test first approach promote more of automation tests, and tries to maintain the test pyramid, thus lessor effort for testing Effectiveness - There are less wastage at various level, team is focus on the delivering right business requirement at right time in iterations, inefficiencies can be removed well early based on the feedback at various levels.  Conclusion We have discussed the test first pair development methodology, which is about marrying TDD and Pair Programming. We described key concepts of the test first and the pair programming, and then we described the key benefits to the organisation.\nReferences :\n[1] - http://agilemanifesto.org/\n[2] - https://info.thoughtworks.com/PS-15-Q1-Agile-IT-Organization-Design-Sriram-Narayan_Staging.html\n[3] http://ptgmedia.pearsoncmg.com/images/9780321278654/samplepages/9780321278654.pdf\n[4] https://martinfowler.com/articles/practical-test-pyramid.html\nThis article was originally published on My LinkedIn Profile\n","id":25,"tag":"tdd ; takeaways ; book-review ; xp ; practice ; agile ; pair-development ; thoughtworks","title":"Boost your organisation agility by test-first-pair development","type":"post","url":"https://thinkuldeep.github.io/post/test-first-pair-development/"},{"content":"Java 11\u0026rsquo;s release candidate is already here, and the industry is still roaming around Java 8. Every six months, we will see a new release. It is good that Java is evolving at a fast speed to catch up the challengers, but at the same time, it is also scary to catch its speed, even the Java ecosystem (build tools, IDE, etc.) is not catching up that fast. It feels like we are losing track. If I can\u0026rsquo;t catch up with my favorite language, then I will probably choose another one, as it is equally as good to adapt to the new one. Below, we will discuss some of the useful features from Java 8, 9 and 10 that you need to know before jumping into Java 11.\nBefore Java 8? Too Late! Anyone before Java 8? Unfortunately, you will need to consider yourself out of the scope of this discussion — you are too late. If you want to learn what\u0026rsquo;s new after Java 7, then Java is just like any new language for you!\nJava 8: A Tradition Shift Java 8 was released four years ago. Everything that was new in Java 8 has become quite old now. The good thing is that it will still be supported for some time in parallel to the future versions. However, Oracle is already planning to make its support a paid one, as it is the most used and preferred version to date. Java 8 was a tradition shift, which made the Java useful for today and future applications. If you need to talk to a developer today, you can\u0026rsquo;t just keep talking about OOP concepts — this is the age of JavaScript, Scala, and Kotlin, and you must know the language of expressions, streams, and functional interfaces. Java 8 came with these functional features, which kept Java in the mainstream. These functional features will stay valuable amongst its functional rivals, Scala and JavaScript.\nA Quick Recap Lambda Expression: (parameters) -\u0026gt; {body} Lambda expressions opened the gates for the functional programming lovers to keep using Java. Lambda expressions expect zero or more parameters, which can be accessed in the expression body and returned with the evaluated result.\nComparator\u0026lt;Integer\u0026gt; comparator = (a, b) -\u0026gt; a-b; System.out.println(comparator.compare(3, 4)); // -1 Functional Interface: an Interface With Only one Method The lambda expression is, itself, treated as a function interface that can be assigned to the functional interface, as shown above. Java 8 has also provided a new functional construct shown below:\nBiFunction\u0026lt;Integer, Integer, Integer\u0026gt; comparator = (a, b) -\u0026gt; a-b; System.out.println(comparator.apply(3, 4)); // -1 Refer to the package java.util.function for more functional constructs: Function, Supplier, Consumer, Predicate, etc. One can also define the functional interface using @FunctionalInterface.\nInterfaces may also have one or more default implementations for a method and may still remain as a functional interface. It helps avoid unnecessary abstract base classes for default implementation.\nStatic and instance methods can be accessed with :: operator, and constructors may be accessed with ::new, and they can be passed as a functional parameter, e.g. System.out::println.\nStreams: Much More Than Iterations Streams are a sequence of objects and operations. A lot of default methods have been added in the interfaces to support forEach, filter, map , and reduce constructs of the streams. Java libraries, which were providing collections, now support the streams. e.g. BufferredReader.lines(). All the collections can be easily converted to streams. Parallel stream operations are also supported, which distributes the operations on the multiple CPUs internally.\nIntermediate Operations: the Lazy Operation For intermediate operations performed lazily, nothing happens until the terminating operation is called.\n map (mapping): Each element is one-to-one and converted into another form. filter (predicate): filter elements for which the given predicate is true. peek () , limit(), and sorted () are the other intermediate operations.  Terminating Operations: the Resulting Operations  forEach (consumer): iterate over the each element and consume the element reduce (initialValue, accumulator): It starts with initialValue and is iterated over each element and kept updating at a value that is eventually returned. collect (collector): this is a lazily evaluated result that needs to be collected using collectors, such as java.util.stream.Collectors, including toList(), joining(), summarizingX(), averagingX(), groupBy(), and partitionBy().  Optional: Get Rid of the Null Programming Null-based programming is considered bad, but there was hardly any option to avoid it earlier. Instead of testing for null, we can now test for isPresent() in the optional object. Read about it — there are multiple constructs and operations for streams as well, which returns optional.\nJVM Changes: PermGen Retired The PermGen has been removed completely and replaced by MetaSpace. Metaspace is no more part of the heap memory, but of the native memory allocated to the process. JVM tuning needs different aspects now, as monitoring is required, not just for the heap, but also for the native memory.\nSome combinations of GCs has deprecated. GC is allocated automatically based on the environment configurations.\nThere were other changes in NIO, DateTime, Security, compact JDK profiles, and tools like jDeps, jjs, the JavaScript Engine, etc.\nJava 9: Continue the Tradition Java 9 has been around us for more than a year now. Its key feature module system is still not well adapted. In my opinion, it will take more time to really adopt such features in the mainstream. It challenges developers in the way they design classes. They now need to think more in terms of application modules than just a group of classes. Anyway, it is a similar challenge to what a traditional developer faces through microservice-based development. Java 9 continued adding functional programming features to keep Java alive and also improved JVM internals.\nJava Platform Module System: Small Is Big The most known feature of Java 9 is the Java Platform Module System (JPMS). It is a great step towards the real encapsulation. Breaking a bigger module in small and clear modules consists of closely related code and data. It is similar to an OSGi bundle, where each bundle defines dependencies it consumes and exposes things on which other modules depend.\nIt introduces an assemble phase between compile and runtime that can build a custom runtime image of JDK and JRE. Now, JDK itself consists of modules.\n~ java --list-modules java.activation@9.0.2 java.base@9.0.2 java.compiler@9.0.2 java.corba@9.0.2 ... These modules are called system modules. A jar loaded without a module information is loaded in an unnamed module. We can define our own application module by providing the following information in file module-info.java:\n requires — dependencies on other modules exports — export public APIs/interfaces of the packages in the module opens — open package for reflection access uses — similar to requires.  To learn more, here is a quick start guide.\nHere are the quick steps in the IntelliJ IDE:\n  Create Module in IntelliJ: Go to File \u0026gt; New \u0026gt; Module - \u0026ldquo;first.module\u0026rdquo;\n  Create a Java class in /first.module/src\npackage com.test.modules.print; public class Printer { public static void print(String input){ System.out.println(input); } }   Add module-info.java : /first.module/src \u0026gt; New \u0026gt; package module first.module { exports com.test.modules.print; // exports public apis of the package. }   Similarly, you need to create another module main.module and Main.java:\nmodule main.module { requires first.module; } package com.test.modules.main; import com.test.modules.print.Printer; public class Main { public static void main(String[] args) { Printer.print(\u0026#34;Hello World\u0026#34;); } }   IntelliJ automatically compiles it and keeps a record of dependencies and --module-source-path\n  To run the Main.java, it needs --module-path or -m:\njava -p /Workspaces/RnD/out/production/main.module:/Workspaces/RnD/out/production/first.module -m main.module/com.test.modules.main.Main Hello World Process finished with exit code 0   So, this way, we can define the modules. Java 9 comes with many additional features. Some of the important ones are listed below\nCatching up With the Rivals   Reacting Programming — Java 9 has introduced reactive-streams, which supports React, like async/await communication between publisher and consumers. It added the standard interfaces in the Flow class.\n  JShell – the Java Shell - Just like any other scripting language, Java can now be used as a scripting language.\n  Stream and Collections enhancement: Java 9 added a few APIs related to \u0026ldquo;ordered\u0026rdquo; and \u0026ldquo;optional\u0026rdquo; stream operations. of() operation is added to ease up creating collections, just like JavaScript.\n  Self-Tuning JVM G1 is made the default GC, and there have been improvements in the self-tuning features in GC. CMS has been deprecated.\nAccess to Stack The StackWalker class is added to lazy access to the stack frames, and we can traverse and filter into it.\nMulti-Release JAR Files: MRJAR One Java program may contain classes compatible with multiple versions. To be honest, I am not sure how useful this feature might be.\nJava 10: Getting Closer to the Functional Languages Java 10 comes with the old favorite var of JavaScript. You can not only declare types of free variables but you can also construct the collection type free. The following are valid in Java:\nvar test = \u0026#34;9\u0026#34;; var set = Set.of(5, \u0026#34;X\u0026#34;, 6.5, new Object()); The code is getting less verbose and the magic of scripting languages is getting added in Java. It will definitely bring the negatives of these features to Java, but it has given a lot of power to the developer.\nMore Powerful JVM This was introduced in parallelism in the case that full GC happens for G1 to improve the overall performance.\nHeap allocation can be allocated on an alternative memory device attached to the system. It will help prioritize Java processes on the system. The low priority one may use a slow memory as compared to the important ones.\njava 10 also Improved thread handling in handshaking the thread locally. Ahead-Of-Time compilation (experimental) was also added. Bytecode generation enhancement for loops was another interesting feature with Java 10.\nEnhanced Language In Java 10, we Improved Optional, unmodifiable collections API’s.\nConclusion We have seen the journey from Java 8 to Java 10 and the influence of other functional and scripting languages in Java. Java is a strong object-oriented programming language, and at the same time, now it supports a lot of functional constructs. Java will not only bring top features from other languages, but it will also keep improving the internals. It is evolving at a great speed, so stay tuned — before it phases you out! Because, Java 11, 12 are on the way!\nThis article was originally published on DZone\n","id":26,"tag":"upgrade ; java","title":"A Quick Catch up Before Java 11","type":"post","url":"https://thinkuldeep.github.io/post/before_java11/"},{"content":"The change is inevitable and constant; it is a part of our life. Sooner or later, we have to accept the change. 13 years ago, I joined a small IT organisation of around 100 people, as a developer. I have grown with the organisation; a 40 times growth journey. I really thank the organisation for giving me opportunity, and transforming me, what I am today. Now, the time has come to accept a change, and start a new journey. I am writing this post to share my point of view about, when to accept the change.\nWhen to change the organisation? Intention behind this post is not to answer this question, but to address, what you get and what you lose while staying long in the same organisation. I have also taken inputs from many senior folks who joined us or left us after the long stay. You may have different opinion. Please ignore this post incase, it hurts your sentiments in any way. When to change is really an individual’s choice. If you are aware of the pros and cons of staying long, then you may probably work on the cons and stay relevant even longer, or don\u0026rsquo;t change at all.\nWhat do you get? When you join a small software organisation and stay long, say more than 10 years, and grow with the organisation\u0026rsquo;s pace, you get following which keeps you attached to the same organisation\n You are tried and tested - You become a tried and tested resource of the organisation, many stakeholders may like to take you in their group. You don’t need to prove every-time to get into any nice opportunity in the organisation. You know the beats - Every organisation grows in its own style and nurture its own culture. You know the beats of the organisation, you know how the X thing is done in a certain way, you know the history. At time you become a consultant for many things in the organisation. People believe in your inputs, you become an encyclopaedia of org information. Since you have participated in almost every things, you see yourself in every part of organisation, be it hiring, training, process or the system. Breadth and Depth - You may get chance to work on different departments and chance to setup groups and lead multiple initiatives. This gives you a chance to gain the breadth and depth, and a rich experience to lead the organisation. Attractive role and appreciations - You may be working on really attracting role at even lessor experience in terms of years. You may be recognised and appreciated well. Emotional connect - After these many years, your relationship with organisation is no more a professional but it becomes an emotional one. Organisation becomes a family, and you will have a lots of friends. Comfort zone - You are in your comfort zone, and can work very confidently in the same zone. Stability - Industry may see you as a stable resource, who don’t change too often.  What do you lose? Staying long will accumulate following, and you may keep building on top of these, unknowingly. You may work to overcome these and stay prepared to go even longer in the journey.\n Lack of diversity - Since you have worked in the same organisation for such a long period, you start thinking that certain things can happen only in a certain way. These certain things could be dealing with processes, people, resource and even technology solutions. You know the things well, which worked well and which not for you in that organisation. Thinking beyond your area of easy imagination does not come obvious. It may start blocking your path and at time may become frustrating. Resistant to the change - After staying so long, you become resistant to the change in the processes, people and the system. It becomes hard to accept the change, if that is not according to you. Out of comfort zone - It becomes difficult to work beyond your comfort zone. You may start running away from the situation, which takes you out the comfort zone. Risk taking capability may also reduced, as you worked in really safe and secure zone for long. You may have not learned to deal with the failures, and have not been exploited and exposed well since long. We learns well when we get exposed time to time. You are for granted - You may be treated for granted by your peers of similar experience and by management, they know all the pluses and minuses of yours, as you have grown in front of them. They may use you the way they want and wherever they want. It will be hard to change the perception of people around you. You may also be a target for the new comers, as they don’t really know the history and achievements that you might have. Energy and satisfaction - After so many years, you may not have the energy to fight against the changes, which may kill the culture you are addicted to. Remember that change is necessary, to scale the organisation, to sustain and to go beyond the barriers, but you might not be aligned with the changes. You may not be satisfied with the situations and with what you get. In such a situation, you start creating a negative environments, which is not good for both you and your organisation. Confidence in Industry - as the years progress, jobs become limited at your level. Market outside may not be ready to accept you, in the way you are, you need to adapt to the need outside. You come to know your value and level, only when you try outside. If you keep trying outside time to time, you gain lot of confidence, and that can help in your current job as well.  Conclusion I have shared pros and cons of a long stay in the same IT organisation, it may help you in identify the losses you are accumulating year by year after certain years. You may plan to overcome the losses, and stay useful to the same organisation you are in, or take the next step.\nIt is originally published at My LinkedIn Profile\n","id":27,"tag":"general ; change ; nagarro ; thoughtworks","title":"Accept the change!","type":"post","url":"https://thinkuldeep.github.io/post/accept_the_change/"},{"content":"Microservices-based development is happening all around the industry; more than 70% are trying development of microservice-based software. Microservices simplify integration of the businesses, processes, technology, and people by breaking down the big-bang monolith problem to a smaller set that can be handled independently. However, it also comes with the problem of managing relations between these smaller sets. We used to manage fewer independent units, so there was less operation and planning effort. We need different processes, tools, training, methodology, and teams to ease microservices development.\nOur Microservices-Based Project We have been developing a highly complex project on microservice architecture, where we import gigs of observation data every day and build statistical models to predict future demand. End users may interact to influence the statistical model and prediction methods. Users may analyze the demand by simulating the impact. There are around 50+ bounded contexts with 100+ independent deployment units communicating over REST and messaging. 200+ process instances are needed to run the whole system. We started this project from scratch with almost no practical experience on microservices and we faced lots of issues in project planning, training, testing, quality management, deployment, and operations.\nLearnings I am sharing the top five lessons from my experience that helped us overcome those problems.\n1. Align Development Methodology and Project Planning Agile development methodology is considered best for microservice development, but only if aligned well. Monolithic development has one deliverable and one process pipeline, but here, we have multiple deliverables, so unless we align the process pipeline for each deliverable, we won\u0026rsquo;t be able to achieve the desired effectiveness of microservice development.\nWe also faced project planning issues, as we could not plan the product and user stories well, which can produce independent products, and we could apply the process pipeline. For seven sprints, we could not demonstrate the business value to the end user, as our product workflow was ready only after that. We used to have very big user stories, which sometimes go beyond multiple sprints and impact the number of microservices.\nConsider the following aspects of project planning:\n Run parallel sprint pipelines for Requirement Definition, Architecture, Development, DevOps, and Infrastructure. Have a Scrum of Scrum for common concerns and integration points. Keep few initial sprints for Architecture and DevOps, and start the Development sprint only after the first stable version of the architecture and DevOps is setup. Architectural PoCs and Decision tasks should be planned a couple of sprints before the actual development script. Define metrics for each sprint to measure project quality quantitatively. Clearly call out architectural changes in the backlog and prioritize them well. Consider their adaptation efforts based on the current size of the project and impact on microservices. Have an infrastructure resource (expert, software, hardware, or tool) plan. Configuration management. Include agile training in the project induction. Include multiple sprint artifact dependencies in the Definition of Ready (DoR) and Definition of Done. Train the product owner and project planner to plan the scrums for requirement definition, architecture, etc such that they fulfill the DoR. Have smaller user stories, making sure the stories selected in a sprint are really of the unit size which will impact very few deployment unit. If a new microservice is getting added in a particular sprint, then consider the effort for CI/CD, Infrastructure, DevOps.  2. Define an Infrastructure Management Strategy In a monolithic world, infrastructure management is not that critical in the start of a project, so infra-related tasks may get delayed until stable deliveries start coming, but, in microservices development, the deployment units are small; thus, they start coming early, and the number of deployment units is also high, so a strong infrastructure management strategy is needed.\nWe delayed defining the infrastructure management strategy and faced a lot of issues getting to know the appropriate capacity of the infrastructure and getting it on time. We had not tracked the deployment/uses of infra components well, which caused a delay in adapting the infra, and we ended up having less knowledge of the infrastructure. We had to put lot of effort into streamlining the infra components in the middle of the project, and that had a lot of side effects on the functional scope getting implemented.\nInfrastructure here includes cross-cutting components, supporting tools, and hardware/software needed for running the system. Things like service registry, discovery, API management, configurations, tracing, log management, monitoring, and service health checks may need separate tools. Consider at least the following in infrastructure management:\n Capacity planning – Do capacity planning from the start of the project, and then review/adjust it periodically. Get the required infrastructure (software/hardware/tools) ahead of time and test them well before the team adopts them. Define a Hardware/Software/Service onboarding plan which covers details of the tools in different physical environments, like development testing, QA testing, performance testing, staging, UAT, Prod, etc. Consider multiple extended development testing/integration environments, as multiple developers need to test their artifacts, and their development machine may not be capable of holding required services. Onboard an infrastructure management expert to accelerate the project setup. Define a deployment strategy and plan its implementation in the early stages of the project. Don’t go for intermediate deployment methodology. If you want to go for Docker and Kubernetes-based deployment, then do it from the start of the project — don’t wait and delay its implementation. Define access management and resource provisioning policies. Have automated, proactive monitoring on your infrastructure. Track infrastructure development in parallel to the project scope.  3. Define Microservices-Based Architecture and Its Evolutions Microservices can be developed and deployed independently, but in the end, it is hard to maintain standards and practices throughout development across the services. A base architecture that needs to be followed by the microservices and then let the architecture evolve may help here.\nWe had defined a very basic architecture with a core platform covering logging, boot, and a few common aspects. However, we considered lot of things to come in evolutions such as messaging, database, caching, folder structures, compression/decompression, etc. and it resulted in the platform being changed heavily in parallel to the functional scope in microservices. We had not given enough time to the core platform before jumping to the functional scope sprints.\nConsider the following in the base architecture, and implement it well before the functional scope implementation. Don’t rely too much on the statement “Learn from the system and then improvise.” Define the architecture in advance, stay ahead of the situation, and gain knowledge as soon as possible.\n  Define a core platform covering cross-cutting concerns and abstractions. The core platform may cover logging, tracing, boot, compression/decompression, encryption/decryption, common aspects, interceptors, request filters, configurations, exceptions, etc. Abstractions of messaging, caching, and database may also be included in the platform.\n  Microservice structure – Define a folder and code structure with naming conversions. Don’t delay it. Late introduction will cost a lot.\n  Build a mechanism for CI/CD – Define a CD strategy, even for the local QA environment, to avoid facing issues directly in the UAT/pre-UAT environment.\n  Define an architecture change strategy – how architecture changes will be delivered and how they will be adapted.\n  A version strategy for Source Code, API, Builds, Configurations, and documents.\n  Keep validating the design against NFRs.\n  Define a Test Architecture to cover the testing strategy.\n  Document the module architecture with clearly defined bounded contexts and data isolations.\n  4. Team Management The microservice world needs a different mindset than the monolithic one. Each microservice may be considered independent, so developers of different microservices are independent. It brings a different kind of challenge: we want our developers to manage code consistency across units, follow the same coding standards, and build on the top of the core platform, and at the same time, we want them not to trust other microservices\u0026rsquo; code, as it was developed by some other company’s developer.\nConsider the following in your team management:\n Define the responsibility of “Configuration Management” to a few team members who are responsible for maintaining the configuration and dependencies information. They are more of an information aggregator, but can be considered a source of truth when it comes to configuration. Define a “Contract Management” team consisting of developers/architects who are responsible for defining the interaction between microservices. Assign module owners and teams based on bounded context. They are responsible for everything related to their assigned module, and informing the “Configuration Management” team of public concerns. Team seating may be considered module-wise; developers should talk to each other only via contract, otherwise they are a completely separate team. If any change is needed in the contract, then it should come via “Contract Management.” Define the DevOps team from development team. One may rotate people so everybody gets the knowledge of Ops. Encourage multi-skilling in the team. Self-motivated team. Continuous Training Programs.  5. Keep Sharing the Knowledge Microservices are evolving day by day, and a lot of new tools and concepts are being introduced. Teams need to be up to date; due to microservice architecture, you may change the technology stack of a microservice if needed. Since teams are independent, we need to keep sharing the learning and knowledge across teams.\nWe faced issues where the same/similar issues were being replicated by different teams and they tried to fix them in different ways. Teams faced issues in understanding bounded context, data isolationss etc.\nConsider the following:\n  Educate teams on domain-driven design, bounded context, data isolation, integration patterns, event design, continuous deployment, etc.\n  Create a learning database where each team may submit entries in the sprint retrospection.\n  Train teams to follow unit testing, mock, and integration testing. Most of the time, the definition of a “unit” is misunderstood by developers. “Integration testing” is given the lowest priority. It must be followed; if taken correctly, it should be the simplest thing to adhere to.\n  Share knowledge of performance engineering — for example:\n Don’t over loop Use cache efficiently Use RabbitMQ messaging as a flow, not as data storage Concurrent consumer and publishers Database partitioning and clustering Do not repeat    Conclusion Microservices are being adopted at a good pace and things are getting more mature with time. I have shared a few of the hard lessons that we experienced in our microservice-based project. I hope this will be beneficial for your project to avoid mistakes.\nIt was originally published at DZone and also shared on LinkedIn\n","id":28,"tag":"micro-services ; learnings ; experience ; java ; architecture ; spring boot","title":"5 Hard Lessons From Microservices Development","type":"post","url":"https://thinkuldeep.github.io/post/lessons_from_microservices_development/"},{"content":"  IOT 101 A Primer on Internet of Things  from Kuldeep Singh  The IoT can be described as “Connecting the Things to internet”.\nA comprehensive IoT ecosystem consists of many different parts such as electronic circuitry, sensing and acting capability, embedded systems, edge computing, network protocols, communication networks, cloud computing, big data management and analytics, business rules etcetera. This maze of varied parts can be better classified into 4 broad categories:\nDevices IoT devices are capable of sensing the environment and then act upon the instructions that they receive.\nThese devices consist of sensors and actuators connected to the machines and electronic environment. The electronic environment of device may pre-process data sensed from the sensor and then send it to IoT platform. This electronic environment can often also post-process the data or instruction received from the IoT platform before passing them to actuators for further action.\nConnectivity The second key part of the IoT system is connectivity. This involves connecting the devices to the IoT platform to send data sensed by the devices and receive instructions from the platform.\nElectronic environment of the device has capability to connect over internet directly or via internet gateways. For connecting to the internet directly there are multiple wired and wireless communication protocols, including some that use low powered communication networks. The devices which connect via internet gateway, generally communicate over short range radio frequency protocols or wired protocols. The internet gateway in turn further communicates with IoT platform over long range radio frequency protocols.\nOne of the key elements \u0026amp; challenge of connectivity is security. IoT system introduces lot of data exchange interfaces between IoT devices, gateways, IoT platform, integrated enterprise solutions, and visualization tools. Connection between these interfaces must safeguard the input and output data in transit.\nPlatform IoT platform is the brain of an IoT system. It is responsible for efficiently receiving the data ingested from the devices, then analysing that data in real-time and storing it for history building and for further processing in future. It also provides services to remotely monitor, control and manage the devices.\nThe Platform routes the data to other integrated enterprise systems based on the business rules available in the system and provides the services to visualize the data on multiple connected tools such as web interfaces, mobile and wearables. Finally, it aggregates the information to the context of the users so that the user gets the right information at right time.\nBusiness Model The advent of IoT has the potential to redefine the business models that would open new opportunities for new sources of revenue, improved margins and higher customer satisfaction.\nThere are broadly 5 trends in business model innovation: product \u0026amp; service bundling, assured performance, pay as you go, process optimization, predictive and prescriptive maintenance.\n#Conclusion IoT systems are complex due to the heterogeneity of technology and business needs. We expect this complexity to continue to increase driven by continuous proliferation of more IoT platforms that will seek to provide technology and business use case specific value proposition.\nIrrespective of the nature of the IoT system we believe that a holistic IoT system can be explained as a sum of 4 parts: Devices, Connectivity, Platform and Business Model.\nIt was originally published at Nagarro Blogs and LinkedIn \n","id":29,"tag":"guide ; iot ; cloud ; fundamentals ; nagarro ; introduction","title":"IOT 101: A primer on Internet of Things","type":"post","url":"https://thinkuldeep.github.io/post/iot_simplified/"},{"content":"Technological evolution causes disruption. It replaces traditional, less optimal, complex, lengthy, and costly technology, people, and processes with economical, innovative, optimal, and simpler alternatives. We have seen disruption by mobile phones, and up next is disruption from IoT, wearables, AR-VR, machine Learning, AI, and other innovations. Software development methodology, tools, and people will also face disruption. I expect that the traditional developer will be replaced by the multi-skilled or full-stack developers.\nIoT Development Challenges Heterogeneous connectivity IoT doesn\u0026rsquo;t just connect Things but also a variety of Internet-enabled systems, processes, and people. IoT solutions involve integrating hardware with software. IoT development requires knowledge of the entire connected environment.\nHuge ecosystem IoT solutions involve multiple technologies ranging from embedded to front end, wearables, and connected enterprise solutions. IoT solution implementation needs multiple specialized skills at different levels, such as native developers (C, C++, embedded), gateway developers (Arduino, C, C++, Python, Node.js), network developers, cloud developers, web developers (.NET, Java, PHP, Python), mobile app developers (Android, iOS, Windows), IoT platform developers (Azure, AWS, Xively, Predix), AR-VR developers (Smart Glass, HoloLens, Unity), Big Data developers, enterprise solutions developers (ERP,CRM, SAP, Salesforce), business analysts, graphics designers, build engineers, architects, project managers, etc.\nDevelopment cost The cost of building IoT solutions is high due to the involvement of multiple people from multiple skillsets. Looking at the huge ecosystem, it is a difficult and costly affair to coordinate and maintain consistency among multiple people from different backgrounds and experience levels. With the traditional developer mindset, we would need at least 20 people to build an end-to-end IoT PoC, which is a huge cost. Global development is also difficult due to unavailability of real environments, hardware, and extreme coordination needs. IoT solutions require stakeholders to be more connected to each other, which results in higher costs as more and more people are needed.\nSolving the Chaos The traditional developer mindset, which binds people to Java or .NET or an otherwise specific technology will be discouraged in the near future. People with multiple skills or full-stack knowledge—who work with multiple technologies, tools, and processes—will reduce the cost of IoT development, and thus, they will replace the traditional workers.\nIt was originally published at Dzone and LinkedIn \n","id":30,"tag":"transformation ; iot ; disruption ; multi-skill","title":"Another IoT Disruption: A Need of Multi-Skilled Devs","type":"post","url":"https://thinkuldeep.github.io/post/iot-disruption-multi-skilled-people/"},{"content":"Introduction The vision of IoT can be seen from two perspectives— ‘Internet’ centric and ‘Thing’ centric. The Internet centric architecture will involve internet services being the main focus while data is contributed by the objects. In the object centric architecture, the smart objects take the center stage.\nIn order to realize the full potential of cloud computing as well as ubiquitous sensing, a combined framework with a cloud at the center seems to be most viable. This not only gives the flexibility of dividing associated costs in the most logical manner but is also highly scalable. Sensing service providers can join the network and offer their data using a storage cloud; analytic tool developers can provide their software tools; artificial intelligence experts can provide their data mining and machine learning tools useful in converting information to knowledge and finally computer graphics designers can offer a variety of visualization tools.\nCloud computing can offer these services as Infrastructures, Platforms or Software where the full potential of human creativity can be tapped using them as services. The data generated, tools used and the visualization created disappears into the background, tapping the full potential of the Internet of Things in various application domains. The Cloud integrates all ends by providing scalable storage, computation time and other tools to build new businesses.\nMajor Platforms – A Quick Snapshot Below are given the quick snapshot of major IoT Cloud platforms with their main key features:\nAWS IoT  Supports HTTP, WebSockets, and MQTT Rules Engine: A rule can apply to data from one or many devices, and it can take one or many actions in parallel. It can route messages to AWS endpoints including AWS Lambda, Amazon Kinesis, Amazon S3, Amazon Machine Learning, Amazon DynamoDB, Amazon CloudWatch, and Amazon Elasticsearch Service with built-in Kibana integration (Kibana is an open source data visualization plugin for Elasticsearch.) Device Shadows: Create a persistent, virtual version, or “shadow,” of each device that includes the device’s latest state.  https://developer.amazon.com/blogs/post/Tx3828JHC7O9GZ9/Using-Alexa-Skills-Kit-and-AWS-IoT-to-Voice-Control-Connected-Devices\nAzure IoT Suite  Easily integrate Azure IoT Suite with your systems and applications, including Salesforce, SAP, Oracle Database, and Microsoft Dynamics Azure IoT Suite packages together Azure IoT services with preconfigured solutions. Supports HTTP, Advanced Message Queuing Protocol (AMQP), and MQ Telemetry Transport (MQTT). Gateway SDK – a framework to create extensible gateway solutions, code which sends data from multiple devices over gateway to cloud connection  https://azure.microsoft.com/en-in/blog/microsoft-azure-iot-suite-connecting-your-things-to-the-cloud/\nGoogle Cloud IoT  Take advantage of Google’s heritage of web-scale processing, analytics, and machine intelligence. Utilizes Google\u0026rsquo;s global fiber network (70 points of presence across 33 countries) for ultra-low latency  https://cloud.google.com/iot-core/ IBM Watson IoT  Machine Learning - Automate data processing and rank data based on learned priorities. Raspberry Pi Support - Develop IoT apps that leverage Raspberry Pi, cognitive capabilities and APIs Real-Time Insights - Contextualize and analyze real-time IoT data  https://cloud.ibm.com/catalog/services/internet-of-things-platform\nGE Predix  Designed mainly for IIoT platforms. Supports over 60 regulatory frameworks worldwide. Based on Pivotal Cloud Foundry (Cloud Foundry is an open source cloud computing platform as a service (PaaS))  https://www.ge.com/digital/iiot-platform\nBosch IoT Suite  Bosch IoT Analytics: Our analytics services make analyzing field data much simpler. The anomaly detection service helps investigate problems that occur in connected devices. The usage profiling service can determine typical usage patterns within a group of devices. Bosch IoT Hub: Messaging backbone for device related communication as attach point for various protocol connectors Bosch IoT Integrations: Integration with third-party services and systems  https://www.bosch-iot-suite.com/capabilities-bosch-iot-suite/\nCisco Jasper IoT  Focus on services. Control Center: Providing a vast array of flexible ways to automate your IoT services.  https://www.cisco.com/c/en/us/solutions/internet-of-things/iot-control-center.html\nXively  The messaging broker supports connections using native MQTT and WebSockets MQTT. Xively provides a C client library for use on devices Xively provides an application for integrating connected products into the Salesforce Service Cloud.  https://xively.com/\nComparative Analysis We have done extensive study and trials and at this moment here is our findings, below is given the matrix of parameters vs different cloud platforms.\nThis paper was also supported by Ram Chauhan\n","id":31,"tag":"framework ; IOT ; platform ; comparision ; Analysis ; Cloud ; Azure ; Google ; IBM ; GE ; Bosch","title":"IOT Cloud Platforms -  A Comparative Study","type":"post","url":"https://thinkuldeep.github.io/post/iot_cloud_platform_comparision/"},{"content":"The ‘Internet of Things’ (IoT) presents tremendous opportunity in all the industry verticals and business domains. Specifically, the ‘Industrial Internet of Things’(IIoT) promises to increase the value proposition by making self-optimizing business processes. As discussed in the post “The Driving Forces Behind IoT”, there are several challenges to be addressed to realize the full IoT potentials, but following steps will help organization to systemically make their products participate in the IoT journey and stay in the IoT race. These steps will help in modernize their existing products or to define strategy to build futuristic products.\n5 Steps of the IoT race 1. Preparation Analyze the product and services for their strengths and weaknesses. Analyze the sensing and acting capabilites of the products, or in other word see what all ambient information the product can sense and how it can be actuated, or how it can listen to the instructions. Analyze the integrated, embedded services/components of the product and benchmark the product on usability, self-service capability, optimizations, minimal human interference etc. Research the competitive products are offering, and the customer experience.\nDefine a clear IoT vision for your organization and address where do you want to stand, what are your targets, whom do you want to compete with and then define IoT vision for the products and services aligned to your organization’s IoT vision.\nPlan the ROI in term of projected financials, reductions in –ve ROI (human trainings, involvement etc.), and innovation. Consider complete eco-system for the products and services provided internally or externally by partners, suppliers and dealers. Plan the roadmap for achieving the IoT vision.\n2. Registration Once preparation is over, you have a clear vision and roadmap. Now it’s time to register for the IoT race by engaging each of the stakeholders (internal as well as external) to the IoT program. Declare your participation in the IoT race by letting your employees, customers, and partners know about benefits derived from the new vision. Collect views from the stakeholder and adjust the IoT program such that it also meets expectations of the stakeholders.\n3. Warm-up During warm-up, you should be able to complete the technology exploration and feasibility studies. Define a common framework to generate consistent output and incorporate feedbacks. The Framework should include processes for building various proof of concepts for the integrated product with potential sensory architecture, cloud platforms, data storage, communication protocols and networks. The Framework should also have processes to plan the development of pilot projects and get feedback on them. If needed new devices (such as mobile phone, smart glasses, wearables or BYOD) may be introduced here to enhance the customer experiences.\n4. Participation Once you are done with warm-up, you know the potential approaches to be followed, and the devices to be bought into the game. Now you need to plan for the step-by-step development of the product features with a highly agile and flexible methodology, keeping the deployment as small as possible such that we derive the benefits inclemently, and also incorporating the feedback at the same time. Implementation process also need to be optimized time to time by building accelerator, monitors and tools which may help in speeding up the implementation. Eg, building reusable components, frameworks, standards, guidelines, best practices and checklists.\n5. Stay ahead While delivering the product features, also plan for their scaling. Develop SDKs to implement extensions and plugins on the product features. Call for the new/existing partners and service integrators to customize and enrich your product. Let the partner eco-system exploit the product capability.\nHope, these five steps will jump start your IoT journey, and keep you in the race, as a front runner. At every steps feedback is really important, every investment need to be well validated against ROI and then well-rehearsed in by pilot implementation and well exploited by partners. At the end it will be a win-win situation for all the stakeholders.\nIt was originally published at LinkedIn \n","id":32,"tag":"race ; IOT ; disruption ; product","title":"5 Steps of the IoT race","type":"post","url":"https://thinkuldeep.github.io/post/5-steps-of-the-iot-race/"},{"content":" Your house will remain clean for longer duration if you follow certain rules strictly such as put things at right place after use, clear any mesh just after doing it, repair/upgrade things on time, daily dusting, vacuum cleaning etc. We may avoid a massive cleanup if we apply a series of small efforts daily.\n Let for the same while writing the code –  Your code will remain maintainable for longer duration if you follow certain rules strictly such as follow the coding standards and guidelines, clean the code just after it, fix/refactor on time, periodic design review and refactoring. We may avoid complete rewrite if we apply a series of small effort daily.\n This article was originally published on My LinkedIn Profile\n","id":33,"tag":"clean-code ; practice ; maintainability","title":"Writing maintainable code is like house cleaning","type":"post","url":"https://thinkuldeep.github.io/post/clean-code/"},{"content":"Everybody in the software industry is talking about IoT in terms of billions of devices, their growth in coming years, changing business models, and adaptation of the IoT in the market. Connecting the things has become so prevalent nowadays, that every software company wants to expand in IoT by building IoT-centric products and services.\nThere are many industrial applications which connect to sensors and actuators, and can be controlled remotely. They have been around for a long time.\nWhy Is There so Much Hype About IoT? Yes, the connected things were already there, but with time, the technology used in connecting the things has been enhanced. IoT is about more than just connecting ordinary things and making them accessible remotely. The “Connected Things” becomes the “Internet of Things” when they are connected to people and their processes. Connected things produce huge amounts of data which can be monitored and visualized remotely, but in the IoT era, this data is analyzed to generate useful insights, build patterns, predict situations, prescribe solutions, and instruct ordinary things to make them self-optimizing.\nThe IoT is a package of:\n The things with the capability to sense and act. Communication protocols to connect the things. A platform to collect and store the data from the things, then analyze the data and instruct the connected things to perform optimally. A network to connect all the things with the platform. Interactive user interface to visualize the data and monitor/control/track the things.  Supporting Forces The \u0026ldquo;Connected Things\u0026rdquo; of past was converted to the \u0026ldquo;Internet of Things\u0026rdquo; due to following supportive forces:\n Reliance on software: Software usage is increasing for making the hardware better. Software plays a critical role in a lot of mission critical applications. Many hardware vendors are building embedded software pieces which can be upgraded/enriched later, without really changing the hardware. Technology commoditization: Technology is reaching the hand of the common people. We are now living with technology, our basic devices such as phones, watches, tv, washing machines, shoes, etc. are getting smarter every day. Technology is becoming more affordable. Hardware is getting cheaper due to mass production and process enhancement. Connection everywhere: Network speed and coverage is increasing. The world is getting closer every day by connecting to the Internet. The Internet is getting cheaper and more accessible. Communication overhead is also getting reduced by using the better protocols, thus data access speed is also increasing. More data and more science: Necessity is the mother of invention. The focus on data analytics and science is increasing, as more data is getting generated. Data storage capacity is also increasing with time. Rapid development: Companies are investing in frameworks and platforms to build, deploy, and produce the software faster. Cloud services are getting cheaper and easily accessible. Increase the revenue by reducing the cost: Enterprises are targeting to increase revenue by reducing cost through predictive maintenance and the use of self-optimizing machines. Stay in the race: Based on the predictions of IoT growth by 2020 or so, everybody wants to stay in the race.  Obstacles for IoT Growth  Lack of standards: Current IoT development is more consensus-based standards. Sets of companies come together and define their own standards, and this leads to the interoperability issues. Security tradeoff: IoT devices are smaller, less capable and may not perform well when high-security standards are required. Investment: A lot of companies are talking about IoT but very few are really investing. Most companies playing safe by waiting and watching. Huge ecosystem: IoT’s technical ecosystem is huge. It involves everything including hardware, network, protocol, software, data science, data storage, mobility, IoT platform, cloud infrastructure, maintenance and integration services. It is really difficult for companies to build such as a huge ecosystem. Companies need to partner with specialists and share their customers and revenue. Integration to existing infrastructure: Integrating the IoT tech stack to traditional communication infrastructure is challenging. For example connecting over HTTPS, SSL, SOAP, RDBMS, SFTP for CRM, ERP, ECM portal.  Conclusion IoT is not new; it has been there for a long time. The “Connected Things/M2M\u0026rdquo; of the past is today’s IoT with a new set of communication protocols, improved hardware, better data collection, and analytics capability with nice visualization to monitor and interact with IoT devices. There are a lot of forces to keep IoT growing in future, but there are some obstacles too, which need to be crossed by the IoT solution providers.\nIt was originally published at Dzone and LinkedIn \n","id":34,"tag":"guide ; iot ; fundamentals ; connected things ; forces","title":"The Driving Forces Behind IoT","type":"post","url":"https://thinkuldeep.github.io/post/the-driving-forces-iot/"},{"content":"##Introduction SIGFOX is providing a communication solution dedicated to the Internet of Things\nDedicated to the IOT means:\n Simplicity: No configuration, no pairing, no signaling Autonomy: Very low energy consumption, allowing years of autonomy on battery without maintenance Small messages: No large assets or multimedia, only small messages  It is a LPWA (Low-Power Wide-Area) network, currently operating in 20 countries in Europe, Americas and Asia/Pacific. Communications over the SIGFOX network are bi-directional: uplink from device \u0026amp; downlink to the device. Specifically,\nCharacteristics of SigFox Network  SigFox sets up antennas on towers (like a cell phone company), and receives data transmissions from devices like parking sensors or water meters. These transmissions use frequencies that are unlicensed. SigFox deploys Low-Power Wide Area Networks (LPWAN) that work in concert with hardware that manufacturers can integrate into their products. Any device with integrated SigFox hardware can connect to the internet – in regions where a SigFox network has been deployed – without any external hardware, like a Wi-Fi or ZigBee router. SigFox wireless systems send very small amounts of data (12 bytes) very slowly, at just 100 bits per second so it can reach farther distances with fewer base stations. Up to 140 messages per object per day Low Battery consumption as sensors can \u0026ldquo;go to sleep\u0026rdquo; when not transmitting data, consuming energy only when they need to. The focus on low-power, low-bandwidth communications also makes the SigFox network relatively easy to deploy. While adding new SigFox node, reconfiguration to existing nodes is not required. Data transportation becomes very long range (distances up to 40km in open field) and communication with buried, underground equipment becomes possible, all this being achieved with high reliability and minimal power consumption. Furthermore, the narrow throughput transmission combined with sophisticated signal processing provides effective protection against interference. This also ensures that the integrity of the data transmitted is respected. This technology is a good fit for any application that needs to send small, infrequent bursts of data.  Frequencies  The SIGFOX network is relying on Ultra-Narrow Band(UNB) modulation, and operating in unlicensed sub-GHz frequency bands. This protocol offers a great resistance to jamming \u0026amp; standard interferers, as well as a great capacity per receiving base stations SIGFOX complies with local regulations, adjusting central frequency, power output and duty cycles  SIGFOX Requirements  A SIGFOX-ready module or transceiver (SIGFOX solution) Ex- SI446x A valid subscription. Development kits \u0026amp; evaluation boards come with an included one-year subscription Be in a covered area (In SIGFOX Network).  SIGFOX Network SIGFOX’s network is designed around a hierarchical structure:\n UNB modems communicate with base stations, or cells, covering large areas of several hundred square kilometers. UNB - Ultra Narrow Band, technology uses free frequency radio bands (no license needed) to transmit data over a very narrow spectrum to and from connected objects. Base stations route messages to server. Servers check data integrity and route the messages to your information system  Messaging Sending a message through SIGFOX –\n There is no signaling, nor negotiation between a device and a receiving station. The device decides when to send its message, picking up a pseudo-random frequency. It\u0026rsquo;s up to the network to detect the incoming messages, as well as validating \u0026amp; reduplicating them. The message is then available in the SIGFOX cloud, and forwarded to any 3rd party cloud platform chosen by the user.  Security Data security provided by SIGFOX –\n Every message is signed, with information proper to the device (incl. a unique private key) and to the message itself. This prevent spoofing, alteration or replay of genuine messages. Encryption \u0026amp; scrambling of the data are supported, with the choice of the more appropriate solution up to the consumer.  Hardware solutions:  SIGFOX makes its IP available at no cost to silicon and module vendors. This strategy has encouraged leading silicon and module vendors to integrate SIGFOX in their existing assets, giving solution enablers a wide choice of very competitively priced components. SIGFOX enables bi-directional as well as mono-directional communications and can co-exist with other communication protocols, both short and long range. High energy consumption has been a major obstacle with regards to unleashing the potential of the Internet of Things, which is why one of the key elements of the SIGFOX strategy is to continue to push the boundaries for energy consumption lower and low.  SIGFOX Web Application Web application provided by SIGFOX system will allow users to access application and perform their desired tasks for devices. There are number of REST end points exposed by the server.\nThis research was supported by my colleagues at IoT Center of Excellence and Nagarro and SIGFOX\n","id":35,"tag":"sigfox ; IOT ; platform ; introduction ; guide ; nagarro","title":"SIGFOX - An Introduction","type":"post","url":"https://thinkuldeep.github.io/post/sigfox-an-introduction/"},{"content":"We have recently migrated source code from Hibernate ORM to JDBC (Spring JDBC template) based implementation. Performance has been improved 10 times.\nUser case (Oracle 11g, JBoss 6, JDK 6, Hibernate, Spring 3) : A tree structure in database is getting populated from a deep file system (directory structure) having around 75000 nodes. Each node (directory) contains text files, which get parsed based on business rules and then populate the database ( BRANCHs representing a node, tables referring to branch, tree_nodes). The database tables was well mapped to Hibernate JPA entries and on saving Branch object, its relevant entities were automatically getting saved. Whole operation was performed in recursive manner by traversing over directory tree. Each table’s primary key is auto generated from a separate sequence.\nAs per development level performance testing, it was estimated that initial tree will take 30 hours to load whole tree. This was not acceptable, as UAT cannot be started without this migration.\nWe have tried batching,flushing in hibernate, and seen the improvement but Spring JDBC is 10 times faster then that of Hibernate based approaches.\nWhile migrating to Spring JDBC based implementation, the biggest issue was to resolve the generated ID referred in other queries. Since ID is getting generated by a sequence and Spring JDBC template’s ‘batchUpdate’ do not have provision to fetch generated IDs. Hibernate was doing this automatically by updating ID field of the entity object.\n We fetched bulk ids from the sequence, in a single query (select customer_id_seq.nextval from (select level from dual connect by LEVEL \u0026lt;=?size)) . Set ids in entity object while iterating BatchPreparedStatementSetter.setValues method.  This way entity object get populated in the same way as it is done in hibernate, without any special iteration/processing. Once entity object is populated, all the dependent batches can be fired so that entity.getId returns the correct value.\nThis way we were able to migrate Hibernate based code-base to Spring JDBC with minimal changes in source code.\nThis article was originally published on My LinkedIn Profile\n","id":36,"tag":"orm ; java ; hibernate ; spring","title":"Choose ORM carefully!","type":"post","url":"https://thinkuldeep.github.io/post/choose-orm-carefully/"},{"content":"I define software effectiveness as, doing the objective effectively, I mean correctly. Efficiency can be defined as, using the resources optimally where resources could be memory, CPU, time, files, connections, databases etc.\nFrom my experience, in most (should I call many) of the software projects, efficiency/performance is not much accentuated during the system design and in earlier phases(requirement and estimation) as compared to the emphasis given late in the game, coding and testing and mostly in maintenance.\nStressing on efficiency, during the early SDLC phases, can eliminate lot of problems. If we consider the efficiency in say coding phase, then we probably able to develop an optimal system in which 90% of the code using just 1% of CPU in peak load, but 10% of code is using 99% of CPU. If we worry about the performance only after the system is built then we are in the worst situation, we probably could not reach 90% optimal code level.\nComing back to effectiveness, usually this is the most emphasized topic in all the SDLC phases, we always try to make the system understandable, testable, and maintainable.\nEfficiency is generally against the code quality measures that were considered to improve effectiveness, more efficient code is usually more difficult to understand, hard to maintain, sometime very hard to test.\nSo based on project, we should benchmark/strengthen the SDLC process to balance-out the efficiency and effectiveness in each phases. Keep in mind that there are always some modules where efficiency is more concerned than the understandability, maintainability. We may change our mind setup when understanding a highly efficient module that this will require more effort to understand, maintain and test.\nThis post is not meant to allow you writing less effective code, saying that you are writing efficient code so; it will be less understandable, not testable and not maintainable. Use better design pattern, prepare approach and discuss it, design the efficient module vary carefully\nThis article was originally published on My LinkedIn Profile\n","id":37,"tag":"effectiveness ; software ; efficiency ; general","title":"Software Effectiveness vs Software Efficiency","type":"post","url":"https://thinkuldeep.github.io/post/software-effectiveness-vs-efficiency/"},{"content":"##IoT Platform As we understand “IoT Platform” is an essential building block of IoT Ecosystem . A platform essentially decouples the business application from low level details of the technology stack and required services. Thus, it makes more sense to go for an off-the-shelf platform that provide all the relevant features and required flexibility, instead of developing the whole IoT stack from scratch. Selection of an IoT Platform is a key to develop a scalable and robust IoT Solution. Choice of IoT Platform is also important in reducing the solution’s time to market-readiness.\nChallenges Since IoT is not a single technology but a complex mix of varying technologies, its relevance to business verticals is not uniform. Choosing a platform, that suits to specific needs or the one that suits most of the generic IoT needs, is a cumbersome task. A simple web search on Google for IoT Platforms results in more than 200 IoT Platforms, ranging from market leaders like Microsoft Azure, Amazon Web Services to open-source platform like SiteWhere \u0026amp; Kaa and established ones like PTC Thingworx, Bosch IoT Suite. These platforms not only vary in features and services they provide, but also in the terminology they use for similar features.\nTo tackle these challenges of selecting an IoT Platform, we have devised a strategic approach that compares and analyzes multiple platforms by mapping them against a Common Framework.\nThe Common Framework Below image shows an IoT reference architecture and depicts a Common Framework for IoT Platform. IoT reference architecture shows three major components:\n IoT Nodes: Devices composed of sensors and / or actuators on one part, a communication module on another. Data sensed by these devices is either utilized in computation at the edge gateways or exchanged with IoT Platform for further analysis. IoT Platform: Facilitates communication with devices, data-pipelining, device management, analytics and application development. Business and external systems: Such systems leverage IoT in business functions like SAP ERP etc. and visualization systems like Augmented Reality, Virtual Reality, Mobile, Web Browsers etc.  The Common Framework defines features of IoT Platform under following categories, each of which is further divided in factors:\n  Connectivity: connectivity enables easy and reliable integration of devices with platform by providing standard protocols. Connectivity can be evaluated on following factors:\n Data Ingestion - How reliable and scalable consumption of device data in the platform? Integration SDKs - How is the support for multiple languages, how does the platform gives more control to application developers. Key Protocols - does the platform supports for key protocols and ensure decoupling the business applications from underlying communication.    Device Management: Provides an easy and reliable way for operators to manage or monitor collection of devices. Following factors impacts Device Management:\n Data Identity \u0026amp; Registry - The platform should have mechanism to maintain a device registry to store the Device Identity and security credentials. Device State Storage - Easy asynchronous update of device latest state \u0026amp; capabilities in device twin or shadow. Device Security - Authenticate connected devices using security credentials Remote Software Upgrade - Remote update to collection or individual IoT Node.    Analytics \u0026amp; Visualization: Device data analysis to gain insights for business profitability and visualizing in user friendly way. Following analytics features are expected in the platform:\n Batch Analytics - An efficient way of processing high volumes of historical data Stream Processing - Analyze events and data on the fly. Predictive/ Preventive Maintenance - Deep machine learning, which leads to predictive or prevent analysis. Visualization - Displaying result of analysis (historical or real-time) on multiple visualization means    Data Routing: Ease of defining data routing rules to execute complex use cases that consumes device and sensor data. Rule engine capabilities are factored as:\n GUI Based Rules - Ease for non-technical users to create or modify rules. Nested Conditions - Support for complex use cases Routing Control - Have a control on routing of data to other services. Rule Repository - Version and maintain multiple rules.    Storage: Valuable data generated by the devices shall be securely persisted and backed up regularly to prevent loss from any disaster. Following are important decision factor for storage and backup:\n Data Store Types - Multiple types of data stores provides flexibility in designing application Backup \u0026amp; Recovery - Platform should provide means to back up the data and perform recovery actions if needed Disaster Recovery - Disaster recovery requires that data redundancy is maintained at multiple sites    Security: Security is the biggest concern in any IoT solution and needs to be taken care at all layers. Following highlights the key security considerations in platform:\n IT compliances - deploying services in hybrid cloud behind the organization firewall \u0026amp; within organization IT compliance. Identity \u0026amp; Access Mgmt - Ensure only the right individuals access the right resources at the right times for the right reasons Key Management - Encrypt keys and small secrets like passwords using keys stored in hardware security modules    MARS: Maintainability, Availability, Reliability and Scalability, these are important aspects for cost optimization and to prevent business losses from downtime. Factors:\n Administration - Service and Application logging and monitoring Elasticity - On demand scale-up and scale-down. Enterprise Messaging - prevent leakage or queue overflows when data flows through services. SLA - prevent downtime losses    Enterprise Integration, API Gateway, Application Development: platform’s integration capabilities are critical to leverage IoT in existing business systems. Support for application development and concept of an API Gateway allows easy integration with external visualization systems like Google Glass, HoloLens, Mobile \u0026amp; Web.\n  Conclusion The Common Framework makes it easier to evaluate multiple IoT Platforms. A simple process of evaluation starts with breaking down of an IoT Platform’s features and then mapping these features to the Common Framework (categories and factors within categories). After doing a similar mapping for all platforms, an apple to apple comparison of features in different platforms is possible. One can remove and add the categories or factors as per relevance to their evaluation requirements. Read our next white paper on IoT Platform evaluation in details to understand how to score the features and complete the evaluation exercise to find a best fit for your IoT Platform needs.\nContributors : This paper was also supported by Umang Garg and Manish Asija\n","id":38,"tag":"framework ; IOT ; platform ; comparision ; analysis ; cloud ; security","title":"Framework for choosing an IoT Platform","type":"post","url":"https://thinkuldeep.github.io/post/choosing_iot_platform/"},{"content":"##Introduction On a usual day at office, if an employee wishes to book a meeting room, he or she first has to open their outlook account, check the calendar for its availability and then send a booking invitation. If they directly go to a meeting room, they have no way of knowing whether it is booked or not without checking the calendar.\nSmart Meeting Room is a step forward in automating the availability and booking procedure of a meeting room.\nThe main idea behind this app is to avoid the hassle of opening outlook, checking for room availability and then booking the room in which a user is already in. The user will just have to give a voice command to check the availability of room and another one to book the room. The application will recognize the user’s command and give a speech output. In order to confirm the identity of person, a camera is initiated, capturing the user’s image and recognizing it using the face detection API.\nTo fully automate a meeting room, an AC control module and a TV control module have been integrated into the app which allows the user to control the room’s air conditioning unit and the TV unit through simple voice commands.\nSolution Concept The application targets controlling the meeting rooms of the company using a simple natural interface. The solution is divided into four modules.  Checking Room Availability - A user can directly go to a meeting room and ask for its availability using simple voice commands. The application will recognize the user’s command and give a speech output. Room Booking - If the room is available, we initiate a camera, capture the user’s image and recognize it using the face detection API in order to confirm the identity of person. Once the user is recognised, a meeting request is sent on behalf of the user and the room gets booked. Controlling the AC- The air conditioning unit of the room is controlled using simple voice commands. The application sends the user’s commands to a device attached to the AC which then transmits appropriate Infrared signals. Controlling the TV - Controlling the television unit of the room using voice commands works much the same way as the AC.  Benefits The Smart Meeting Room project eases the way in which an employee can interact with a meeting room.\n Using the Speech Recognition and Face Recognition APIs, it provides for very rich and natural interaction between the user and the application. It provides a single interface through which a user can control all the aspects of a meeting room. Whether it is checking for room availability and its booking or controlling the room’s AC and TV, everything can be done using simple voice commands. It mitigates the need for finding and using multiple remote controls for the AC and the TV. A simple voice command does it all. It removes the hassle of manually checking the calendar on outlook and then creating a booking.  Design and Architecture The architecture of the Smart Meeting Room system was designed to provide a stable foundation, both for current functionality and for future requirements.\n Universal Windows Application: Universal Windows Platform (UWP) provides a common app platform available on every device that runs Windows 10. The Universal windows app written for the Smart Meeting Room will run on Raspberry Pi 3 installed with windows IoT Core operating system. UWP provides a large set of APIs to work with which makes it easy to integrate richer experiences with your devices such as natural user interfaces, searching, online storage and cloud based services.  User Interface: A user interface created using XAML provides users to interact with the system directly. Media Control: The Media Control component in the universal apps enables us to use the webcam attached with our system and show a live camera feed to capture the image. Bluetooth Low Energy (BLE): The power-efficiency of Bluetooth with low energy functionality makes it perfect for devices that run for long periods on limited power sources. We use the Bluetooth GATT profile to connect with the Arduino board in order to send the commands for the AC and the TV operations.   Microsoft Speech Platform: The Microsoft Speech Platform provides a comprehensive Speech Platform Runtime management in voice-enabled applications. It provides the ability to recognize spoken words (speech recognition) and to generate synthesized speech (text-to-speech or TTS) to enhance users\u0026rsquo; interaction. Microsoft Exchange Web Service: The Microsoft’s Exchange Web Service allows us to connect to the Office 365 account and access the public folders and calendars and retrieve the free/busy status and availability of the meeting rooms. Microsoft Face API: The Project Oxford’s Face API for windows universal apps allows for programmatic access to the cognitive service subscription. We use the API to detect faces in the picture captured, identify the faces and retrieve their stored information. Microsoft Office 365 Web API: The Office 365 Managed APIs provides a managed interface for developing the application that allow programmatic access to public folders and calendars. Microsoft Project Oxford Face Detection API: The Microsoft cognitive services Face API Detect one or more human faces in an image, organize people into groups according to visual similarity, and identify previously tagged people in images. Arduino Application: The application to control the AC and the TV is run on a single board microcontroller such as Arduino Uno. Smart Meeting Room Web Application: A separate web application running on Microsoft Azure Platform is made for users to register themselves.  Constraints and Challenges  The Arduino application is written for a specific model of air conditioner and television. Smart Meeting Room application will not work for any AC or TV. We had to manually retrieve the IR commands to be sent using the IR receiver sensor. Every permutation of the AC operation was generated manually, which was a very tedious work. While writing the Arduino application, we constantly had to keep in mind the size of the code. Due to limited memory, the number of Serial. Write() were to be kept in check which made logging and debugging a challenge. We had to use the Exchange Web Service, writing soap requests and parsing soap responses manually. This was due to the fact that the EWS Managed API generated a popup which cannot be handled in Raspberry Pi. We have implemented the Speech Interpretation in low confidence. This might create a problem in proper interpretation of commands due to different voice accents. We generated the Bluetooth GATT profile on our own with its services and characteristics exposed. No particular standard was followed. For the IR emitter sensor to properly work, it was to be positioned in such a way that it was in a direct line of sight of both the AC and the TV. This became a challenge depending on the how and where the AC and the TV were installed with respect to each other.  Conclusion The Smart Meeting Room application is a good experiment, it can be extended to implement more features in future such as\n Implementing meeting check in functionality on Smart Display Controlling room condition of specific meeting room using a web based dashboard Controlling AC and TV of specific meeting room remotely using a web dashboard Turning the air conditioner on/off by sensing the presence of person  References  Microsoft Cognitive Services Face API Microsoft Azure Blob Storage Universal Windows Platform Speech Recognition https://msdn.microsoft.com/en-us/windows/uwp/input-and-devices/speech-interactions https://blogs.msdn.microsoft.com/cdndevs/2015/05/25/universal-windows-platform-speech-recognition-part-2/ Universal Windows Platform Bluetooth GATT https://developer.microsoft.com/en-us/windows/iot/samples/blegatt2 Microsoft Exchange Web Service Office 365 OAuth https://github.com/OfficeDev/O365-WebApp-OAuthController  This concept was supported by my colleagues at IoT Center of Excellence at Nagarro\n","id":39,"tag":"smart meeting room ; IOT ; azure ; cloud ; concept ; enterprise ; Arduino ; Raspberry PI ; BLE ; Microsoft","title":"Building a smart meeting room concept","type":"post","url":"https://thinkuldeep.github.io/post/building-smart-meeting-room-concept/"}]
